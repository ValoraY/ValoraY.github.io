<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"valoray.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="FasterRCNN代码分析项目源码：https:&#x2F;&#x2F;github.com&#x2F;chenyuntc&#x2F;simple-faster-rcnn-pytorch 对源码增加注释后的代码（代码2）： simple-faster-rcnn-pytorch-master https:&#x2F;&#x2F;www.alipan.com&#x2F;s&#x2F;faJGPR261aG 提取码: ry92 点击链接保存，或者复制本段内容，打开「阿里云盘」AP">
<meta property="og:type" content="article">
<meta property="og:title" content="Faster RCNN代码分析（二）">
<meta property="og:url" content="https://valoray.github.io/2023/12/29/Faster-RCNN%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/index.html">
<meta property="og:site_name" content="DeepRookie">
<meta property="og:description" content="FasterRCNN代码分析项目源码：https:&#x2F;&#x2F;github.com&#x2F;chenyuntc&#x2F;simple-faster-rcnn-pytorch 对源码增加注释后的代码（代码2）： simple-faster-rcnn-pytorch-master https:&#x2F;&#x2F;www.alipan.com&#x2F;s&#x2F;faJGPR261aG 提取码: ry92 点击链接保存，或者复制本段内容，打开「阿里云盘」AP">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ooo.0x0.ooo/2023/12/29/OKYXOt.png">
<meta property="article:published_time" content="2023-12-29T06:53:28.000Z">
<meta property="article:modified_time" content="2024-01-02T01:39:14.649Z">
<meta property="article:author" content="deeprookie">
<meta property="article:tag" content="代码复现">
<meta property="article:tag" content="Faster RCNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ooo.0x0.ooo/2023/12/29/OKYXOt.png">


<link rel="canonical" href="https://valoray.github.io/2023/12/29/Faster-RCNN%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://valoray.github.io/2023/12/29/Faster-RCNN%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/","path":"2023/12/29/Faster-RCNN代码分析（二）/","title":"Faster RCNN代码分析（二）"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Faster RCNN代码分析（二） | DeepRookie</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">DeepRookie</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">想到，就去做，无非一朝还是一生</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#FasterRCNN%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90"><span class="nav-number">1.</span> <span class="nav-text">FasterRCNN代码分析</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="deeprookie"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">deeprookie</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/ValoraY" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;ValoraY" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:1432843916@qq.com" title="E-Mail → mailto:1432843916@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/m0_51619560/category_12535222.html" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;m0_51619560&#x2F;category_12535222.html" rel="noopener me" target="_blank">CSDN</a>
      </span>
  </div>

    <div class="links-of-blogroll motion-element links-of-blogroll-block">
      <div class="links-of-blogroll-title">
        <!-- modify icon to fire by szw -->
        <i class="fa fa-history fa-" aria-hidden="true"></i>
        近期文章
      </div>
      <ul class="links-of-blogroll-list">
        
        
          <li>
            <a href="/2024/01/04/Django%E6%90%AD%E5%BB%BA%E6%95%8F%E6%84%9F%E5%9B%BE%E7%89%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%BA%8C%EF%BC%89/" title="Django搭建敏感图片检测系统（二）" target="_blank">Django搭建敏感图片检测系统（二）</a>
          </li>
        
          <li>
            <a href="/2024/01/03/Django%E5%88%9D%E5%AD%A6%E6%95%99%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89/" title="Django初学教程（一）" target="_blank">Django初学教程（一）</a>
          </li>
        
          <li>
            <a href="/2023/12/29/Pycharm%E8%BF%9E%E6%8E%A5%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%AD%E7%BB%83/" title="Pycharm连接云服务器训练" target="_blank">Pycharm连接云服务器训练</a>
          </li>
        
          <li>
            <a href="/2023/12/29/Faster-RCNN%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/" title="Faster RCNN代码分析（二）" target="_blank">Faster RCNN代码分析（二）</a>
          </li>
        
          <li>
            <a href="/2023/12/29/Faster-RCNN%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%EF%BC%88%E4%B8%80%EF%BC%89/" title="Faster RCNN项目部署（一）" target="_blank">Faster RCNN项目部署（一）</a>
          </li>
        
      </ul>
    </div>


        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="返回顶部">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://valoray.github.io/2023/12/29/Faster-RCNN%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="deeprookie">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="DeepRookie">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Faster RCNN代码分析（二） | DeepRookie">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Faster RCNN代码分析（二）
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-12-29 14:53:28" itemprop="dateCreated datePublished" datetime="2023-12-29T14:53:28+08:00">2023-12-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-01-02 09:39:14" itemprop="dateModified" datetime="2024-01-02T09:39:14+08:00">2024-01-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" itemprop="url" rel="index"><span itemprop="name">目标检测</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="FasterRCNN代码分析"><a href="#FasterRCNN代码分析" class="headerlink" title="FasterRCNN代码分析"></a>FasterRCNN代码分析</h1><p><strong>项目源码</strong>：<a target="_blank" rel="noopener" href="https://github.com/chenyuntc/simple-faster-rcnn-pytorch">https://github.com/chenyuntc/simple-faster-rcnn-pytorch</a></p>
<p><strong>对源码增加注释后的代码（代码2）：</strong></p>
<p><code>simple-faster-rcnn-pytorch-master</code> <a target="_blank" rel="noopener" href="https://www.alipan.com/s/faJGPR261aG">https://www.alipan.com/s/faJGPR261aG</a> 提取码: ry92 点击链接保存，或者复制本段内容，打开「阿里云盘」APP ，无需下载极速在线查看，视频原画倍速播放。<br><strong>代码2</strong>只要将VOCdevkit数据集放到dataset目录下即可运行</p>
<p>这个项目是一个基于Faster R-CNN模型的目标检测项目，主要包含以下几个部分：</p>
<span id="more"></span>

<ol>
<li><p><code>utils/config.py</code>：这个文件包含了项目的配置选项，例如数据集路径、学习率、优化器类型、预训练模型的路径等。</p>
</li>
<li><p><code>data/dataset.py</code>：这个文件包含了处理PASCAL VOC数据集的类，例如<code>Dataset</code>、<code>TestDataset</code>。这些类用于加载数据集（这里会调用<code>data/voc_dataset.py</code>中的<code>VOCBboxDataset</code>），对图像和标签进行预处理，并提供了用于训练和测试模型的接口。</p>
</li>
<li><p><code>model/faster_rcnn.py</code>：这个文件包含了Faster R-CNN模型的实现。这个模型由三个主要部分组成：特征提取器、RPN网络和头部网络。特征提取器用于从图像中提取特征，RPN网络用于生成目标的候选区域，头部网络用于在这些候选区域上进行分类和回归。</p>
</li>
<li><p><code>model/faster_rcnn_vgg16.py</code>：这个文件包含了基于VGG-16的Faster R-CNN模型<code>FasterRCNNVGG16</code>（继承了<code>model/faster_rcnn.py</code>中的<code>FasterRCNN</code>）。这个模型由三个主要部分组成：基于VGG-16的特征提取器、RPN网络和<code>VGG16RoIHead</code>头部网络。特征提取器用于从图像中提取特征，RPN网络用于生成目标的候选区域，头部网络用于在这些候选区域上进行分类和回归。</p>
</li>
<li><p><code>model/region_proposal_network.py</code>：这个文件包含了Region Proposal Network（RPN）的实现。RPN是Faster R-CNN模型的一个关键组件，它用于生成目标的候选区域。</p>
</li>
<li><p><code>model/utils/creator_tool.py</code>：这个文件包含了一些用于生成训练Faster R-CNN模型所需的目标的工具类，例如<code>AnchorTargetCreator</code>和<code>ProposalTargetCreator</code>。</p>
</li>
<li><p><code>trainer.py</code>：这个文件包含了一个用于训练Faster R-CNN模型的类<code>FasterRCNNTrainer</code>。这个类提供了一些方法，例如<code>train_step</code>用于执行一步训练，<code>save</code>和<code>load</code>用于保存和加载模型，<code>update_meters</code>和<code>reset_meters</code>用于更新和重置度量等。</p>
</li>
<li><p><code>train.py</code>：这个文件是项目的主程序，它首先加载数据集，然后创建Faster R-CNN模型和训练器，接着进入一个循环，每个循环代表一个训练周期，在每个训练周期中，它会遍历数据集中的所有图像，并使用训练器的<code>train_step</code>方法来更新模型的参数。</p>
</li>
</ol>
<p>这些文件之间的关系主要是通过数据和模型的流动来实现的。首先，<code>train.py</code>会加载<code>dataset.py</code>中的数据集，然后使用<code>model/faster_rcnn.py</code>中的模型对数据进行处理，接着使用<code>trainer.py</code>中的训练器对模型进行训练。在训练过程中，<code>model/utils/creator_tool.py</code>中的工具类会被用来生成训练所需的目标，<code>model/region_proposal_network.py</code>中的RPN会被用来生成目标的候选区域。</p>
<p>1.<code>train.py</code></p>
<p>在<code>main</code>函数中调用<code>train()</code>方法，<code>train()</code>方法的主要步骤为：</p>
<p>（1）加载数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dataset = Dataset(opt)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;load data&#x27;</span>)</span><br><span class="line">dataloader = data_.DataLoader(dataset, \</span><br><span class="line">                              batch_size=<span class="number">1</span>, \</span><br><span class="line">                              shuffle=<span class="literal">True</span>, \</span><br><span class="line">                              <span class="comment"># pin_memory=True,</span></span><br><span class="line">                              num_workers=opt.num_workers)</span><br><span class="line">testset = TestDataset(opt)</span><br><span class="line">test_dataloader = data_.DataLoader(testset,</span><br><span class="line">                                   batch_size=<span class="number">1</span>,</span><br><span class="line">                                   num_workers=opt.test_num_workers,</span><br><span class="line">                                   shuffle=<span class="literal">False</span>, \</span><br><span class="line">                                   pin_memory=<span class="literal">True</span></span><br><span class="line">                                  )</span><br></pre></td></tr></table></figure>

<p>（2）创建Faster RCNN模型及其训练器</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">faster_rcnn = FasterRCNNVGG16()<span class="comment"># 创建Faster R-CNN模型对象</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;model construct completed&#x27;</span>)</span><br><span class="line">trainer = FasterRCNNTrainer(faster_rcnn).cuda() <span class="comment"># 创建Faster R-CNN模型的训练器</span></span><br><span class="line"><span class="keyword">if</span> opt.load_path:<span class="comment"># 如果指定了预训练模型的路径</span></span><br><span class="line">   trainer.load(opt.load_path)<span class="comment"># 加载预训练模型</span></span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;load pretrained model from %s&#x27;</span> % opt.load_path)</span><br></pre></td></tr></table></figure>

<p>（3）开启训练</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">best_map = <span class="number">0</span> <span class="comment"># 初始化最佳mAP为0</span></span><br><span class="line">lr_ = opt.lr <span class="comment"># 获取初始学习率 lr=0.001</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(opt.epoch):</span><br><span class="line">   trainer.reset_meters() <span class="comment"># 重置训练器的度量计数器</span></span><br><span class="line">   <span class="keyword">for</span> ii, (img, bbox_, label_, scale) <span class="keyword">in</span> tqdm(<span class="built_in">enumerate</span>(dataloader)): <span class="comment"># 对数据加载器中的每个batch进行循环 ii为批次索引 img==tensor(1,3,800,600) bbox_==tensor(1,1,4) label_==tensor(1,1) scale==(1,)</span></span><br><span class="line">        scale = at.scalar(scale) <span class="comment"># 获取缩放因子</span></span><br><span class="line">        img, bbox, label = img.cuda().<span class="built_in">float</span>(), bbox_.cuda(), label_.cuda() <span class="comment"># 将图像、边界框（ground_truth）和标签移动到GPU上，并将图像转换为浮点类型</span></span><br><span class="line">        trainer.train_step(img, bbox, label, scale) <span class="comment"># 执行一个训练步骤</span></span><br></pre></td></tr></table></figure>

<p>（4）评估训练结果并在visdom中可视化展示</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">eval_result = <span class="built_in">eval</span>(test_dataloader, faster_rcnn, test_num=opt.test_num)<span class="comment"># 对测试数据集进行评估</span></span><br><span class="line">trainer.vis.plot(<span class="string">&#x27;test_map&#x27;</span>, eval_result[<span class="string">&#x27;map&#x27;</span>])<span class="comment"># 在visdom中绘制mAP</span></span><br><span class="line">lr_ = trainer.faster_rcnn.optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]<span class="comment"># 获取当前的学习率</span></span><br><span class="line">log_info = <span class="string">&#x27;lr:&#123;&#125;, map:&#123;&#125;,loss:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(lr_),</span><br><span class="line">                                          <span class="built_in">str</span>(eval_result[<span class="string">&#x27;map&#x27;</span>]),</span><br><span class="line">                                          <span class="built_in">str</span>(trainer.get_meter_data()))<span class="comment"># 生成日志信息</span></span><br><span class="line">trainer.vis.log(log_info)<span class="comment"># 在visdom中显示日志信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> eval_result[<span class="string">&#x27;map&#x27;</span>] &gt; best_map:<span class="comment"># 如果当前的mAP大于最佳mAP</span></span><br><span class="line">    best_map = eval_result[<span class="string">&#x27;map&#x27;</span>]<span class="comment"># 更新最佳mAP</span></span><br><span class="line">    best_path = trainer.save(best_map=best_map)<span class="comment"># 保存当前的模型，并获取保存路径</span></span><br><span class="line">    <span class="keyword">if</span> epoch == <span class="number">9</span>:<span class="comment"># 如果当前是第10个训练周期</span></span><br><span class="line">        trainer.load(best_path)<span class="comment"># 加载最佳模型</span></span><br><span class="line">        trainer.faster_rcnn.scale_lr(opt.lr_decay)<span class="comment"># 调整学习率</span></span><br><span class="line">        lr_ = lr_ * opt.lr_decay <span class="comment"># 更新当前的学习率</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch == <span class="number">13</span>: <span class="comment"># 如果当前是第14个训练周期</span></span><br><span class="line">            <span class="keyword">break</span><span class="comment"># 结束训练</span></span><br></pre></td></tr></table></figure>

<p>2.<code>trainer.py</code></p>
<p>在<code>train.py</code>的<code>train()</code>开启训练后，<code>trainer.train_step(img, bbox, label, scale)</code> 会执行一个训练步骤，即进入<code>trainer.py</code>的<code>train_step()</code>方法，进而通过内部的<code>losses = self.forward(imgs, bboxes, labels, scale)</code>进行前向传播，前向传播的主要步骤为：</p>
<p>（1）使用<code>Faster R-CNN</code>的特征提取器提取特征</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">features = self.faster_rcnn.extractor(imgs)  <span class="comment"># 使用Faster R-CNN的特征提取器提取特征</span></span><br></pre></td></tr></table></figure>

<p>（2）使用RPN生成RoIs(初步筛选后得到每张图片约2000个RoI)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RPN</span></span><br><span class="line"><span class="comment"># rpn_locs代表所有偏移锚框的位置，形状为(1, hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># rpn_scores代表所有偏移锚框的得分下，形状为(1, hh*ww*9, 2)</span></span><br><span class="line"><span class="comment"># rois代表所有的RoIs(感兴趣区域)，形状约为(2000, 4)</span></span><br><span class="line"><span class="comment"># roi_indices代表RoIs对应的图像索引，形状约为(2000, ) 表明rois中的每个RoI都对应于哪张图片（这里batch=1，每次都来自第0张图片）</span></span><br><span class="line">rpn_locs, rpn_scores, rois, roi_indices, anchor = \</span><br><span class="line">	self.faster_rcnn.rpn(features, img_size, scale) <span class="comment"># 使用RPN生成RoIs</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RegionProposalNetwork</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self, in_channels=<span class="number">512</span>, mid_channels=<span class="number">512</span>, ratios=[<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>],</span></span><br><span class="line"><span class="params">            anchor_scales=[<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>], feat_stride=<span class="number">16</span>,</span></span><br><span class="line"><span class="params">            proposal_creator_params=<span class="built_in">dict</span>(<span class="params"></span>),</span></span><br><span class="line"><span class="params">    </span>):  <span class="comment"># 初始化方法，接受输入通道数、中间通道数、长宽比、锚框尺度、特征步长和proposal创建器参数作为参数</span></span><br><span class="line">        <span class="built_in">super</span>(RegionProposalNetwork, self).__init__()</span><br><span class="line">        self.anchor_base = generate_anchor_base(</span><br><span class="line">            anchor_scales=anchor_scales, ratios=ratios)<span class="comment"># 生成基础参考框anchor_base==&gt;shape(9,4)</span></span><br><span class="line">        self.feat_stride = feat_stride <span class="comment"># 设置特征步长</span></span><br><span class="line">        self.proposal_layer = ProposalCreator(self, **proposal_creator_params)  <span class="comment"># 创建proposal创建器</span></span><br><span class="line">        n_anchor = self.anchor_base.shape[<span class="number">0</span>]  <span class="comment"># 获取锚框数量 n_anchor ==&gt; 9</span></span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, mid_channels, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>) <span class="comment"># 创建一个卷积层，用于特征提取 ==&gt; shape(512,512,3,1,1) kernel_size=(3,3), stride=(1,1), padding=(1,1)</span></span><br><span class="line">        self.score = nn.Conv2d(mid_channels, n_anchor * <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>) <span class="comment"># 创建一个卷积层，用于计算锚框的得分 ==&gt; shape(512,9*2,1,1,0)</span></span><br><span class="line">        self.loc = nn.Conv2d(mid_channels, n_anchor * <span class="number">4</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>) <span class="comment"># 创建一个卷积层，用于计算锚框的位置 ==&gt; shape(512,9*4,1,1,0)</span></span><br><span class="line">        normal_init(self.conv1, <span class="number">0</span>, <span class="number">0.01</span>) <span class="comment"># 初始化conv1的权重</span></span><br><span class="line">        normal_init(self.score, <span class="number">0</span>, <span class="number">0.01</span>) <span class="comment"># 初始化score的权重</span></span><br><span class="line">        normal_init(self.loc, <span class="number">0</span>, <span class="number">0.01</span>) <span class="comment"># 初始化loc的权重</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, img_size, scale=<span class="number">1.</span></span>):<span class="comment"># 定义前向传播方法，接受FasterRCNN特征提取得到的(也是vgg16的)特征图features、图像尺寸和缩放因子作为参数 img_size==(800,600) scale==1</span></span><br><span class="line">      </span><br><span class="line">        n, _, hh, ww = x.shape <span class="comment"># 获取输入特征图x的形状</span></span><br><span class="line">        anchor = _enumerate_shifted_anchor(</span><br><span class="line">            np.array(self.anchor_base),</span><br><span class="line">            self.feat_stride, hh, ww) <span class="comment"># 枚举所有的偏移锚框，数量为特征图的像素数每个像素的锚框数==&gt;(hh*ww)*9</span></span><br><span class="line"></span><br><span class="line">        n_anchor = anchor.shape[<span class="number">0</span>] // (hh * ww) <span class="comment"># 计算每个像素的锚框数量</span></span><br><span class="line">        h = F.relu(self.conv1(x)) <span class="comment"># 对输入进行卷积操作并通过ReLU激活函数</span></span><br><span class="line"></span><br><span class="line">        rpn_locs = self.loc(h) <span class="comment"># 计算锚框的位置</span></span><br><span class="line">        <span class="comment"># UN<span class="doctag">NOTE:</span> check whether need contiguous</span></span><br><span class="line">        <span class="comment"># A: Yes</span></span><br><span class="line">        rpn_locs = rpn_locs.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).contiguous().view(n, -<span class="number">1</span>, <span class="number">4</span>) <span class="comment"># 调整rpn_locs的形状  rpn_locs代表所有偏移锚框的位置，形状为(1, hh*ww*9, 4)</span></span><br><span class="line">        rpn_scores = self.score(h) <span class="comment"># 计算锚框的得分 rpn_scores代表所有偏移锚框的得分</span></span><br><span class="line">        rpn_scores = rpn_scores.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).contiguous() <span class="comment"># 调整rpn_scores的形状</span></span><br><span class="line">        rpn_softmax_scores = F.softmax(rpn_scores.view(n, hh, ww, n_anchor, <span class="number">2</span>), dim=<span class="number">4</span>)  <span class="comment"># (1,hh,ww,9,2)# 对得分进行softmax操作，得到每个类别的概率  rpn_softmax_scores代表所有偏移锚框的得分，形状为(1, hh, ww, 9, 2)</span></span><br><span class="line">        rpn_fg_scores = rpn_softmax_scores[:, :, :, :, <span class="number">1</span>].contiguous()  <span class="comment"># 获取前景的得分</span></span><br><span class="line">        rpn_fg_scores = rpn_fg_scores.view(n, -<span class="number">1</span>)  <span class="comment"># 调整rpn_fg_scores的形状 rpn_fg_scores代表所有偏移锚框的前景得分，形状为(1, hh*ww*9)</span></span><br><span class="line">        rpn_scores = rpn_scores.view(n, -<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># 调整rpn_scores的形状 (1, hh*ww*9, 2)</span></span><br><span class="line"></span><br><span class="line">        rois = <span class="built_in">list</span>() <span class="comment"># 创建一个列表，用于存储RoIs</span></span><br><span class="line">        roi_indices = <span class="built_in">list</span>() <span class="comment"># 创建一个列表，用于存储RoIs的索引</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n): <span class="comment"># 对每个图像进行循环</span></span><br><span class="line">            roi = self.proposal_layer(</span><br><span class="line">                rpn_locs[i].cpu().data.numpy(),</span><br><span class="line">                rpn_fg_scores[i].cpu().data.numpy(),</span><br><span class="line">                anchor, img_size,</span><br><span class="line">                scale=scale) <span class="comment"># 使用proposal创建器生成RoIs roi==&gt;(1944,4)</span></span><br><span class="line">            batch_index = i * np.ones((<span class="built_in">len</span>(roi),), dtype=np.int32) <span class="comment"># 创建一个数组，用于存储RoIs的索引</span></span><br><span class="line">            rois.append(roi) <span class="comment"># 将RoIs添加到列表中</span></span><br><span class="line">            roi_indices.append(batch_index) <span class="comment"># 将RoIs的索引添加到列表中</span></span><br><span class="line"></span><br><span class="line">        rois = np.concatenate(rois, axis=<span class="number">0</span>) <span class="comment"># 将所有图像的RoIs合并</span></span><br><span class="line">        roi_indices = np.concatenate(roi_indices, axis=<span class="number">0</span>) <span class="comment"># 将所有图像的RoIs的索引合并</span></span><br><span class="line">        <span class="keyword">return</span> rpn_locs, rpn_scores, rois, roi_indices, anchor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用处：获取偏移后的锚框</span></span><br><span class="line"><span class="comment"># 在Faster R-CNN中，我们首先在图像中生成一系列的锚点（也称为锚框或参考框）</span></span><br><span class="line"><span class="comment"># 这些锚点通常是在不同的位置、尺度和长宽比下生成的（称为基础锚点：3*3=9——特征图的每个像素处都会有9个锚点——即下文代码中的A=9）</span></span><br><span class="line"><span class="comment"># 然后，我们会预测每个锚点需要偏移多少，才能更好地匹配到真实的目标边界框，这个偏移的过程就是所谓的偏移锚点</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为什么需要偏移?</span></span><br><span class="line"><span class="comment"># 因为我们希望在特征图的每个位置都有一组锚点，这样可以更全面地覆盖到图像中的所有可能的目标。</span></span><br><span class="line"><span class="comment"># 如果只使用基础锚点，那么锚点的位置就只能在参考窗口的位置，这样可能会漏掉一些位于其他位置的目标。</span></span><br><span class="line"><span class="comment"># 通过偏移，我们可以让锚点覆盖到特征图的每个位置，从而更好地检测到所有的目标。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_enumerate_shifted_anchor</span>(<span class="params">anchor_base, feat_stride, height, width</span>):</span><br><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> xp</span><br><span class="line">    shift_y = xp.arange(<span class="number">0</span>, height * feat_stride, feat_stride) <span class="comment"># 计算y方向上的所有偏移</span></span><br><span class="line">    shift_x = xp.arange(<span class="number">0</span>, width * feat_stride, feat_stride) <span class="comment"># 计算x方向上的所有偏移</span></span><br><span class="line">    shift_x, shift_y = xp.meshgrid(shift_x, shift_y)  <span class="comment"># 生成网格坐标</span></span><br><span class="line">    shift = xp.stack((shift_y.ravel(), shift_x.ravel(),</span><br><span class="line">                      shift_y.ravel(), shift_x.ravel()), axis=<span class="number">1</span>) <span class="comment"># 将偏移堆叠成一个数组</span></span><br><span class="line"></span><br><span class="line">    A = anchor_base.shape[<span class="number">0</span>] <span class="comment"># 每个像素处会有A个锚点（A=9）</span></span><br><span class="line">    K = shift.shape[<span class="number">0</span>] <span class="comment"># 特征图的像素数量（K=hh*ww）==&gt; 整张特征图总的偏移量的数量=K*A</span></span><br><span class="line">    anchor = anchor_base.reshape((<span class="number">1</span>, A, <span class="number">4</span>)) + \</span><br><span class="line">             shift.reshape((<span class="number">1</span>, K, <span class="number">4</span>)).transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)) <span class="comment"># 将基础锚点和偏移相加，得到所有的偏移后的锚点</span></span><br><span class="line">    anchor = anchor.reshape((K * A, <span class="number">4</span>)).astype(np.float32) <span class="comment"># 调整偏移锚点的形状，并转换为浮点类型</span></span><br><span class="line">    <span class="keyword">return</span> anchor</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（3）生成用于训练<code>Faster R-CNN</code>的head网络（即RoI网络）所需的目标：经IoU阈值筛选后得到128个ROIs(<code>sample_roi</code>)，使用<code>ProposalTargetCreator</code>为<code>sample_roi</code>分配真实边界框<code>gt_roi_loc</code>和真实标签<code>gt_roi_label</code>，此时就生成了用于训练<code>Faster R-CNN</code>的head网络（即RoI网络）所需的目标。这些目标包括每个RoI对应的ground truth边界框的偏移和比例（用于边界框回归任务），以及每个RoI对应的ground truth边界框的类别标签（用于分类任务）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sample_roi代表经过IoU阈值筛选后的RoIs，由前景roi和背景roi组成，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># gt_roi_loc代表sample_roi与其对应的真实边界框（其实是与它IoU最大的真实边界框）之间的偏移和比例，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># gt_roi_label代表sample_roi对应的真实标签（其实是与它IoU最大的真实边界框的标签），形状为(128,)</span></span><br><span class="line">sample_roi, gt_roi_loc, gt_roi_label = self.proposal_target_creator(</span><br><span class="line">            roi,</span><br><span class="line">            at.tonumpy(bbox),</span><br><span class="line">            at.tonumpy(label),</span><br><span class="line">            self.loc_normalize_mean,</span><br><span class="line">            self.loc_normalize_std)<span class="comment"># 使用ProposalTargetCreator生成训练目标</span></span><br></pre></td></tr></table></figure>

<p><code>utils/creator_tool.py</code>中的类<code>ProposalTargetCreator</code>的代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用处：为给定的RoIs分配ground truth边界框</span></span><br><span class="line"><span class="comment"># 1.计算RoIs和边界框的IoU</span></span><br><span class="line"><span class="comment"># 2.找出每个RoI与哪个边界框的IoU最大</span></span><br><span class="line"><span class="comment"># 3.将每个RoI分配给与其IoU最大的边界框</span></span><br><span class="line"><span class="comment"># 4.计算这些RoI与其对应的边界框的偏移和比例</span></span><br><span class="line"><span class="comment"># 5.对偏移和比例进行归一化</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProposalTargetCreator</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 n_sample=<span class="number">128</span>,</span></span><br><span class="line"><span class="params">                 pos_ratio=<span class="number">0.25</span>, pos_iou_thresh=<span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">                 neg_iou_thresh_hi=<span class="number">0.5</span>, neg_iou_thresh_lo=<span class="number">0.0</span></span></span><br><span class="line"><span class="params">                 </span>):<span class="comment"># 初始化方法，接受一系列参数，包括采样区域的数量、前景的比例、前景的IoU阈值、背景的IoU阈值等</span></span><br><span class="line">        self.n_sample = n_sample  <span class="comment"># 采样区域的数量</span></span><br><span class="line">        self.pos_ratio = pos_ratio  <span class="comment"># 前景的比例</span></span><br><span class="line">        self.pos_iou_thresh = pos_iou_thresh  <span class="comment"># 前景的IoU阈值</span></span><br><span class="line">        self.neg_iou_thresh_hi = neg_iou_thresh_hi  <span class="comment"># 背景的IoU阈值上限</span></span><br><span class="line">        self.neg_iou_thresh_lo = neg_iou_thresh_lo  <span class="comment"># 背景的IoU阈值下限 <span class="doctag">NOTE:</span>default 0.1 in py-faster-rcnn</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, roi, bbox, label,</span></span><br><span class="line"><span class="params">        loc_normalize_mean=(<span class="params"><span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span></span>),</span></span><br><span class="line"><span class="params">        loc_normalize_std=(<span class="params"><span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span></span>)</span>):<span class="comment"># 定义__call__方法，接受RoIs、边界框、标签、位置归一化的均值和标准差作为参数</span></span><br><span class="line">        n_bbox, _ = bbox.shape <span class="comment"># 获取边界框的数量</span></span><br><span class="line"></span><br><span class="line">        roi = np.concatenate((roi, bbox), axis=<span class="number">0</span>)  <span class="comment"># 将RoIs和边界框合并</span></span><br><span class="line"></span><br><span class="line">        pos_roi_per_image = np.<span class="built_in">round</span>(self.n_sample * self.pos_ratio)  <span class="comment"># 计算每个图像的前景RoI数量</span></span><br><span class="line">        iou = bbox_iou(roi, bbox)  <span class="comment"># 计算RoIs和边界框的IoU</span></span><br><span class="line">        gt_assignment = iou.argmax(axis=<span class="number">1</span>)  <span class="comment"># 找出每个RoI与哪个边界框的IoU最大</span></span><br><span class="line">        max_iou = iou.<span class="built_in">max</span>(axis=<span class="number">1</span>)  <span class="comment"># 找出每个RoI的最大IoU</span></span><br><span class="line">        <span class="comment"># Offset range of classes from [0, n_fg_class - 1] to [1, n_fg_class].</span></span><br><span class="line">        <span class="comment"># The label with value 0 is the background.</span></span><br><span class="line">        gt_roi_label = label[gt_assignment] + <span class="number">1</span> <span class="comment"># 将每个RoI分配给与其IoU最大的边界框的标签</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Select foreground RoIs as those with &gt;= pos_iou_thresh IoU.</span></span><br><span class="line">        pos_index = np.where(max_iou &gt;= self.pos_iou_thresh)[<span class="number">0</span>]  <span class="comment"># 找出IoU大于等于前景阈值的RoIs</span></span><br><span class="line">        pos_roi_per_this_image = <span class="built_in">int</span>(<span class="built_in">min</span>(pos_roi_per_image, pos_index.size)) <span class="comment"># 计算这个图像的前景RoI数量</span></span><br><span class="line">        <span class="keyword">if</span> pos_index.size &gt; <span class="number">0</span>:  <span class="comment"># 如果存在前景RoI</span></span><br><span class="line">            pos_index = np.random.choice(</span><br><span class="line">                pos_index, size=pos_roi_per_this_image, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Select background RoIs as those within</span></span><br><span class="line">        <span class="comment"># [neg_iou_thresh_lo, neg_iou_thresh_hi).</span></span><br><span class="line">        neg_index = np.where((max_iou &lt; self.neg_iou_thresh_hi) &amp;</span><br><span class="line">                             (max_iou &gt;= self.neg_iou_thresh_lo))[<span class="number">0</span>]  <span class="comment"># 找出IoU在背景阈值范围内的RoIs</span></span><br><span class="line">        neg_roi_per_this_image = self.n_sample - pos_roi_per_this_image  <span class="comment"># 计算这个图像的背景RoI数量</span></span><br><span class="line">        neg_roi_per_this_image = <span class="built_in">int</span>(<span class="built_in">min</span>(neg_roi_per_this_image,</span><br><span class="line">                                         neg_index.size)) <span class="comment"># 计算这个图像的背景RoI数量</span></span><br><span class="line">        <span class="keyword">if</span> neg_index.size &gt; <span class="number">0</span>:  <span class="comment"># 如果存在背景RoI</span></span><br><span class="line">            neg_index = np.random.choice(</span><br><span class="line">                neg_index, size=neg_roi_per_this_image, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The indices that we&#x27;re selecting (both positive and negative).</span></span><br><span class="line">        keep_index = np.append(pos_index, neg_index)  <span class="comment"># 将前景和背景的索引合并</span></span><br><span class="line">        gt_roi_label = gt_roi_label[keep_index]  <span class="comment"># 保留这些RoI的标签</span></span><br><span class="line">        gt_roi_label[pos_roi_per_this_image:] = <span class="number">0</span>  <span class="comment"># negative labels --&gt; 0  # 将背景RoI的标签设置为0</span></span><br><span class="line">        sample_roi = roi[keep_index] <span class="comment"># 保留这些RoI</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute offsets and scales to match sampled RoIs to the GTs.</span></span><br><span class="line">        gt_roi_loc = bbox2loc(sample_roi, bbox[gt_assignment[keep_index]]) <span class="comment"># 计算这些RoI与其对应的边界框的偏移和比例</span></span><br><span class="line">        gt_roi_loc = ((gt_roi_loc - np.array(loc_normalize_mean, np.float32)</span><br><span class="line">                       ) / np.array(loc_normalize_std, np.float32))<span class="comment"># 对偏移和比例进行归一化</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sample_roi, gt_roi_loc, gt_roi_label</span><br><span class="line">    <span class="comment">#sample_roi代表经过IoU阈值筛选后的RoIs，由前景roi和背景roi组成，形状为(128, 4)</span></span><br><span class="line">    <span class="comment">#gt_roi_loc代表sample_roi与其对应的真实边界框（其实是与它IoU最大的真实边界框）之间的偏移和比例，形状为(128, 4)</span></span><br><span class="line">    <span class="comment">#gt_roi_label代表sample_roi对应的真实标签（其实是与它IoU最大的真实边界框的标签），形状为(128,)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（4）生成用于训练<code>Faster R-CNN</code>的RPN网络所需的目标：这些目标包括每个锚点对应的ground truth边界框的偏移和比例（用于边界框回归任务），以及每个锚点是否包含物体的标签（用于前景&#x2F;背景分类任务）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rpn_loc代表偏移后的锚框的位置</span></span><br><span class="line"><span class="comment"># gt_rpn_loc代表每个anchor与其对应的真实边界框之间的偏移和比例 (hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># gt_rpn_label代表每个anchor对应的真实边界框的标签 (hh*ww*9,)</span></span><br><span class="line">gt_rpn_loc, gt_rpn_label = self.anchor_target_creator(</span><br><span class="line">            at.tonumpy(bbox),</span><br><span class="line">            anchor,</span><br><span class="line">            img_size)  <span class="comment"># 使用AnchorTargetCreator生成训练目标</span></span><br></pre></td></tr></table></figure>

<p><code>utils/creator_tool.py</code>中的类<code>AnchorTargetCreator</code>的代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AnchorTargetCreator</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 n_sample=<span class="number">256</span>,</span></span><br><span class="line"><span class="params">                 pos_iou_thresh=<span class="number">0.7</span>, neg_iou_thresh=<span class="number">0.3</span>,</span></span><br><span class="line"><span class="params">                 pos_ratio=<span class="number">0.5</span></span>):  <span class="comment"># 初始化方法，接受一系列参数，包括采样区域的数量、前景的IoU阈值、背景的IoU阈值、前景的比例等</span></span><br><span class="line">        self.n_sample = n_sample <span class="comment"># 采样区域的数量</span></span><br><span class="line">        self.pos_iou_thresh = pos_iou_thresh  <span class="comment"># 前景的IoU阈值</span></span><br><span class="line">        self.neg_iou_thresh = neg_iou_thresh  <span class="comment"># 背景的IoU阈值</span></span><br><span class="line">        self.pos_ratio = pos_ratio   <span class="comment"># 前景的比例</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, bbox, anchor, img_size</span>):   <span class="comment"># 定义__call__方法，接受边界框、锚点和图像尺寸作为参数</span></span><br><span class="line"></span><br><span class="line">        img_H, img_W = img_size  <span class="comment"># 获取图像的尺寸</span></span><br><span class="line"></span><br><span class="line">        n_anchor = <span class="built_in">len</span>(anchor)  <span class="comment"># 获取锚点的数量</span></span><br><span class="line">        inside_index = _get_inside_index(anchor, img_H, img_W) <span class="comment"># 获取在图像内部的锚点的索引</span></span><br><span class="line">        anchor = anchor[inside_index]   <span class="comment"># 获取在图像内部的锚点</span></span><br><span class="line">        argmax_ious, label = self._create_label(</span><br><span class="line">            inside_index, anchor, bbox)  <span class="comment"># 创建标签</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute bounding box regression targets</span></span><br><span class="line">        loc = bbox2loc(anchor, bbox[argmax_ious])  <span class="comment"># 计算anchor和ground truth边界框之间的偏移和缩放</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># map up to original set of anchors</span></span><br><span class="line">        label = _unmap(label, n_anchor, inside_index, fill=-<span class="number">1</span>)  <span class="comment"># 将标签映射回原始的锚点集</span></span><br><span class="line">        loc = _unmap(loc, n_anchor, inside_index, fill=<span class="number">0</span>)  <span class="comment"># 将位置映射回原始的锚点集</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loc, label  <span class="comment"># 返回位置和标签</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_create_label</span>(<span class="params">self, inside_index, anchor, bbox</span>):</span><br><span class="line">        <span class="comment"># label: 1 is positive, 0 is negative, -1 is dont care</span></span><br><span class="line">        label = np.empty((<span class="built_in">len</span>(inside_index),), dtype=np.int32)  <span class="comment"># 创建一个空的标签数组</span></span><br><span class="line">        label.fill(-<span class="number">1</span>)  <span class="comment"># 将标签数组填充为-1</span></span><br><span class="line"></span><br><span class="line">        argmax_ious, max_ious, gt_argmax_ious = \</span><br><span class="line">            self._calc_ious(anchor, bbox, inside_index)  <span class="comment"># 计算IoU</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># assign negative labels first so that positive labels can clobber them</span></span><br><span class="line">        label[max_ious &lt; self.neg_iou_thresh] = <span class="number">0</span>  <span class="comment"># 将IoU小于背景阈值的锚点标记为背景</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># positive label: for each gt, anchor with highest iou</span></span><br><span class="line">        label[gt_argmax_ious] = <span class="number">1</span>  <span class="comment"># 将每个ground truth对应的IoU最大的锚点标记为前景</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># positive label: above threshold IOU</span></span><br><span class="line">        label[max_ious &gt;= self.pos_iou_thresh] = <span class="number">1</span>  <span class="comment"># 将IoU大于前景阈值的锚点标记为前景</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># subsample positive labels if we have too many</span></span><br><span class="line">        n_pos = <span class="built_in">int</span>(self.pos_ratio * self.n_sample)   <span class="comment"># 计算前景的数量</span></span><br><span class="line">        pos_index = np.where(label == <span class="number">1</span>)[<span class="number">0</span>]   <span class="comment"># 获取前景的索引</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(pos_index) &gt; n_pos:   <span class="comment"># 如果前景的数量过多</span></span><br><span class="line">            disable_index = np.random.choice(</span><br><span class="line">                pos_index, size=(<span class="built_in">len</span>(pos_index) - n_pos), replace=<span class="literal">False</span>)   <span class="comment"># 随机选择一部分前景</span></span><br><span class="line">            label[disable_index] = -<span class="number">1</span>   <span class="comment"># 将这部分前景标记为不关心</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># subsample negative labels if we have too many</span></span><br><span class="line">        n_neg = self.n_sample - np.<span class="built_in">sum</span>(label == <span class="number">1</span>)  <span class="comment"># 计算背景的数量</span></span><br><span class="line">        neg_index = np.where(label == <span class="number">0</span>)[<span class="number">0</span>] <span class="comment"># 获取背景的索引</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(neg_index) &gt; n_neg:  <span class="comment"># 如果背景的数量过多</span></span><br><span class="line">            disable_index = np.random.choice(</span><br><span class="line">                neg_index, size=(<span class="built_in">len</span>(neg_index) - n_neg), replace=<span class="literal">False</span>) <span class="comment"># 随机选择一部分背景</span></span><br><span class="line">            label[disable_index] = -<span class="number">1</span> <span class="comment"># 将这部分背景标记为不关心</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> argmax_ious, label  <span class="comment"># 返回最大IoU的索引和标签</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_calc_ious</span>(<span class="params">self, anchor, bbox, inside_index</span>):</span><br><span class="line">        <span class="comment"># ious between the anchors and the gt boxes</span></span><br><span class="line">        ious = bbox_iou(anchor, bbox) <span class="comment"># 计算锚点和ground truth边界框之间的IoU</span></span><br><span class="line">        argmax_ious = ious.argmax(axis=<span class="number">1</span>)  <span class="comment"># 获取每个锚点对应的最大IoU的索引</span></span><br><span class="line">        max_ious = ious[np.arange(<span class="built_in">len</span>(inside_index)), argmax_ious]  <span class="comment"># 获取每个锚点的最大IoU</span></span><br><span class="line">        gt_argmax_ious = ious.argmax(axis=<span class="number">0</span>) <span class="comment"># 获取每个ground truth边界框对应的最大IoU的索引</span></span><br><span class="line">        gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[<span class="number">1</span>])]  <span class="comment"># 获取每个ground truth边界框的最大IoU</span></span><br><span class="line">        gt_argmax_ious = np.where(ious == gt_max_ious)[<span class="number">0</span>] <span class="comment"># 获取最大IoU的索引</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> argmax_ious, max_ious, gt_argmax_ious   <span class="comment"># 返回最大IoU的索引、最大IoU和ground truth边界框的最大IoU的索引</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（5）使用<code>Faster R-CNN</code>的头部网络（即RoI网络）对<code>sample_roi</code>进行前向传播，返回<code>roi_cls_locs</code>、<code>roi_scores</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sample_roi代表经过IoU阈值筛选后的RoIs，由前景roi和背景roi组成，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># sample_roi_index：一个全零的数组，用于存储RoIs的索引</span></span><br><span class="line"><span class="comment"># roi_cls_locs代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的边界框位置 (128,21*4)，128为RPN得出的sample_roi的数量</span></span><br><span class="line"><span class="comment"># roi_scores代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的得分 (128,21)</span></span><br><span class="line">roi_cls_loc, roi_score = self.faster_rcnn.head(</span><br><span class="line">    features,</span><br><span class="line">    sample_roi,</span><br><span class="line">    sample_roi_index) <span class="comment"># 使用Faster R-CNN的头部网络进行前向传播</span></span><br></pre></td></tr></table></figure>

<p>（6）计算<code>RPN losses</code></p>
<p>RPN的定位损失：偏移后的锚框位置和真实边界框位置之间的平滑L1损失</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ------------------ RPN losses -------------------#</span></span><br><span class="line"><span class="comment"># rpn_loc代表偏移后的锚框的位置 (hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># gt_rpn_loc代表每个anchor与其对应的真实边界框之间的偏移和比例 (hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># gt_rpn_label代表每个anchor对应的真实边界框的标签 (hh*ww*9,)</span></span><br><span class="line">rpn_loc_loss = _fast_rcnn_loc_loss(</span><br><span class="line">rpn_loc,</span><br><span class="line">gt_rpn_loc,</span><br><span class="line">gt_rpn_label.data,</span><br><span class="line">self.rpn_sigma)  <span class="comment"># 计算RPN的定位损失：偏移后的锚框位置和真实边界框位置之间的平滑L1损失</span></span><br></pre></td></tr></table></figure>

<p>RPN的分类损失</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rpn_score代表偏移后的锚框的得分 (hh*ww*9, 2)</span></span><br><span class="line">rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_label.cuda(), ignore_index=-<span class="number">1</span>)  <span class="comment"># 计算RPN的分类损失</span></span><br></pre></td></tr></table></figure>

<p>（7）计算<code>ROI losses</code>（fast rcnn loss）</p>
<p>ROI的定位损失</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ------------------ ROI losses (fast rcnn loss) -------------------#</span></span><br><span class="line"><span class="comment"># roi_cls_loc代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的边界框位置 (128,21,4)，128为RPN得出的sample_roi的数量</span></span><br><span class="line"><span class="comment"># roi_score代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的得分 (128,21)</span></span><br><span class="line"><span class="comment"># gt_roi_loc代表sample_roi与其对应的真实边界框（其实是与它IoU最大的真实边界框）之间的偏移和比例，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># gt_roi_label代表sample_roi对应的真实标签（其实是与它IoU最大的真实边界框的标签），形状为(128,)</span></span><br><span class="line">roi_loc_loss = _fast_rcnn_loc_loss(</span><br><span class="line">roi_loc.contiguous(),</span><br><span class="line">gt_roi_loc,</span><br><span class="line">gt_roi_label.data,</span><br><span class="line">self.roi_sigma)  <span class="comment"># 计算RoI的定位损失</span></span><br></pre></td></tr></table></figure>

<p>ROI的分类损失</p>
<p>（8）计算总损失</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 总损失 = rpn定位损失+rpn分类损失+roi定位损失+roi分类损失</span></span><br><span class="line">losses = [rpn_loc_loss, rpn_cls_loss, roi_loc_loss, roi_cls_loss]  <span class="comment"># 创建一个列表，用于存储所有的损失</span></span><br><span class="line">losses = losses + [<span class="built_in">sum</span>(losses)]  <span class="comment"># 计算总损失</span></span><br></pre></td></tr></table></figure>

<p>（9）前向传播返回总损失后，执行反向传播、参数更新等操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">self, imgs, bboxes, labels, scale</span>): <span class="comment"># 定义训练步骤方法，接受图像、边界框、标签和缩放因子作为参数</span></span><br><span class="line">    self.optimizer.zero_grad() <span class="comment"># 清零优化器的梯度缓存</span></span><br><span class="line">    losses = self.forward(imgs, bboxes, labels, scale) <span class="comment"># 调用forward方法，计算损失 imgs==tensor(1,3,800,600) bboxes==tensor(1,1,4) labels==tensor(1,1) scale==(1,)</span></span><br><span class="line">    losses.total_loss.backward()<span class="comment"># 对总损失进行反向传播</span></span><br><span class="line">    self.optimizer.step()  <span class="comment"># 执行一步优化（参数更新）</span></span><br><span class="line">    self.update_meters(losses)  <span class="comment"># 更新度量</span></span><br><span class="line">    <span class="keyword">return</span> losses <span class="comment"># 返回损失</span></span><br></pre></td></tr></table></figure>

<p>（10）一个训练步骤<code>trainer.train_step(img, bbox, label, scale)</code>完成后，评估训练结果并在<code>visdom</code>中可视化展示<br><img src="https://ooo.0x0.ooo/2023/12/29/OKYXOt.png" alt="OKYXOt.png"></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/" rel="tag"># 代码复现</a>
              <a href="/tags/Faster-RCNN/" rel="tag"># Faster RCNN</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2023/12/29/Faster-RCNN%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%EF%BC%88%E4%B8%80%EF%BC%89/" rel="prev" title="Faster RCNN项目部署（一）">
                  <i class="fa fa-angle-left"></i> Faster RCNN项目部署（一）
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2023/12/29/Pycharm%E8%BF%9E%E6%8E%A5%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%AD%E7%BB%83/" rel="next" title="Pycharm连接云服务器训练">
                  Pycharm连接云服务器训练 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
<!--
  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">deeprookie</span>
  </div>
-->

    </div>
  </footer>

  

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  





</body>
</html>
