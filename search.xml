<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Django初学教程（一）</title>
    <url>/2024/01/03/Django%E5%88%9D%E5%AD%A6%E6%95%99%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="创建项目">创建项目</h1>
<ol type="1">
<li>创建虚拟环境</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n testDjango python=3.8</span><br><span class="line">conda activate testDjango</span><br><span class="line">pip install Django # 注意这里Django首字母大写</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>创建项目</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd D:\PythonCode</span><br><span class="line">django-admin startproject mysite</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>创建成功的项目结构为：</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysite/</span><br><span class="line">    manage.py</span><br><span class="line">    mysite/</span><br><span class="line">        __init__.py</span><br><span class="line">        settings.py</span><br><span class="line">        urls.py</span><br><span class="line">        asgi.py</span><br><span class="line">        wsgi.py</span><br></pre></td></tr></table></figure>
</blockquote>
<p>启动服务器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd mysite</span><br><span class="line">python manage.py runserver</span><br></pre></td></tr></table></figure>
<h1 id="创建应用">创建应用</h1>
<p>项目=（一个及以上的）应用程序 + 配置</p>
<h2 id="创建应用-1">创建应用</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 项目名称为&quot;polls&quot;</span><br><span class="line">python manage.py startapp polls</span><br></pre></td></tr></table></figure>
<p>创建成功的应用结构为：</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">polls/</span><br><span class="line">    __init__.py</span><br><span class="line">    admin.py</span><br><span class="line">    apps.py</span><br><span class="line">    migrations/</span><br><span class="line">        __init__.py</span><br><span class="line">    models.py</span><br><span class="line">    tests.py</span><br><span class="line">    views.py</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="创建首页">创建首页</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改polls/views.py，创建index view</span><br><span class="line"></span><br><span class="line">from django.http import HttpResponse</span><br><span class="line"></span><br><span class="line">def index(request):</span><br><span class="line">    return HttpResponse(&quot;Hello, world. You&#x27;re at the polls index.&quot;)</span><br></pre></td></tr></table></figure>
<h2 id="配置url">配置url</h2>
<h3 id="应用的url配置文件">应用的url配置文件</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新增polls/urls.py, 用于配置应用&quot;polls&quot;下的url</span><br><span class="line"></span><br><span class="line">from django.urls import path</span><br><span class="line"></span><br><span class="line">from . import views</span><br><span class="line"></span><br><span class="line"># 设置应用程序命名空间</span><br><span class="line"># 在真正的 Django 项目中，可能有五个、十个、二十个或更多应用程序。Django 如何区分它们之间的 URL 名称？——即将命名空间app_name = &quot;polls&quot;添加到 URLconf 中</span><br><span class="line"></span><br><span class="line">app_name = &quot;polls&quot;</span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(&quot;&quot;, views.index, name=&quot;index&quot;),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h3 id="项目的url配置文件">项目的url配置文件</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改mysite/urls.py，将应用&quot;polls&quot;下的urls.py引入</span><br><span class="line"></span><br><span class="line">from django.contrib import admin</span><br><span class="line">from django.urls import include, path</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(&quot;polls/&quot;, include(&quot;polls.urls&quot;)),</span><br><span class="line">    path(&quot;admin/&quot;, admin.site.urls),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>启动服务器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py runserver</span><br></pre></td></tr></table></figure>
<p>启动服务器后访问链接：http://127.0.0.1:8000/polls/，即可访问到index
view</p>
<h1 id="连接database">连接Database</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在项目的settings.py(即mysite/settings.py)中修改数据库配置</span><br><span class="line"></span><br><span class="line"># 修改数据库配置——更改为mysql数据库</span><br><span class="line">DATABASES = &#123;</span><br><span class="line">    &#x27;default&#x27;: &#123;</span><br><span class="line">        &#x27;ENGINE&#x27;: &#x27;django.db.backends.mysql&#x27;,</span><br><span class="line">        &#x27;NAME&#x27;: &#x27;db_test&#x27;,</span><br><span class="line">        &quot;USER&quot;: &quot;root&quot;,</span><br><span class="line">        &quot;PASSWORD&quot;: &quot;123456xjy&quot;,</span><br><span class="line">        &quot;HOST&quot;: &quot;127.0.0.1&quot;,</span><br><span class="line">        &quot;PORT&quot;: &quot;3306&quot;,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 首次连接mysql数据库需要在虚拟环境导入以下2个包</span><br><span class="line">pip install pymysql</span><br><span class="line">pip install mysqlclient</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 执行数据迁移——将&quot;mysite/settings.py&quot;中INSTALLED_APPS对应的数据表都创建出来（创建到上述的&quot;db_test&quot;数据库中）</span><br><span class="line">python manage.py migrate</span><br></pre></td></tr></table></figure>
<h1 id="建立model">建立Model</h1>
<h2 id="步骤">步骤</h2>
<ul>
<li>Change your models (in <code>models.py</code>).</li>
<li>Run <code>python manage.py makemigrations</code>to create migrations
for those changes</li>
<li>Run <code>python manage.py migrate</code>to apply those changes to
the database.</li>
</ul>
<h2 id="change-your-models">Change your models</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改polls/models.py，创建类</span><br><span class="line"> </span><br><span class="line">from django.db import models</span><br><span class="line"></span><br><span class="line">class Question(models.Model):</span><br><span class="line">    question_text = models.CharField(max_length=200)</span><br><span class="line">    pub_date = models.DateTimeField(&quot;date published&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Choice(models.Model):</span><br><span class="line">    question = models.ForeignKey(Question, on_delete=models.CASCADE)</span><br><span class="line">    choice_text = models.CharField(max_length=200)</span><br><span class="line">    votes = models.IntegerField(default=0)</span><br></pre></td></tr></table></figure>
<h2 id="make-migrations">make migrations</h2>
<ol type="1">
<li>将应用"polls"放到项目的setting.py（即mysite/settings.py）的INSTALLED_APPS中</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改mysite/settings.py，增加一行&quot;polls.apps.PollsConfig&quot;,</span><br><span class="line"></span><br><span class="line">INSTALLED_APPS = [</span><br><span class="line">    &quot;polls.apps.PollsConfig&quot;,</span><br><span class="line">    &quot;django.contrib.admin&quot;,</span><br><span class="line">    &quot;django.contrib.auth&quot;,</span><br><span class="line">    &quot;django.contrib.contenttypes&quot;,</span><br><span class="line">    &quot;django.contrib.sessions&quot;,</span><br><span class="line">    &quot;django.contrib.messages&quot;,</span><br><span class="line">    &quot;django.contrib.staticfiles&quot;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>make migrations</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py makemigrations polls</span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>migrate</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 运行以下代码，即可将models.py中新创建的类Question和类Choice，在数据库中创建出对应的数据表</span><br><span class="line">python manage.py migrate</span><br></pre></td></tr></table></figure>
<ol start="4" type="1">
<li>进入Python环境</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py shell</span><br></pre></td></tr></table></figure>
<p>We’re using this instead of simply typing “python”, because
<code>manage.py</code> sets the <a
href="https://docs.djangoproject.com/en/4.2/topics/settings/#envvar-DJANGO_SETTINGS_MODULE"><code>DJANGO_SETTINGS_MODULE</code></a>
environment variable, which gives Django the Python import path to your
<code>mysite/settings.py</code> file.</p>
<h1 id="管理后台">管理后台</h1>
<ol type="1">
<li>创建超级管理员</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py createsuperuser</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>运行服务器</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py runserver</span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>将自定义的类注册到管理后台</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改polls/admin.py，将新注册的类Question注册到管理后台</span><br><span class="line"></span><br><span class="line">from django.contrib import admin</span><br><span class="line">from .models import Question</span><br><span class="line"></span><br><span class="line">admin.site.register(Question)</span><br></pre></td></tr></table></figure>
<h1 id="增加views">增加Views</h1>
<ol type="1">
<li>新增视图</li>
</ol>
<p>每一个View就干两件事中的一件：要么返回一个HttpResponse，要么返回一个Exception（如Http404）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在polls/views.py新增以下函数（视图）</span><br><span class="line"># 以下均为虚拟实现</span><br><span class="line"></span><br><span class="line">def detail(request, question_id):</span><br><span class="line">    return HttpResponse(&quot;You&#x27;re looking at question %s.&quot; % question_id)</span><br><span class="line"></span><br><span class="line">def results(request, question_id):</span><br><span class="line">    response = &quot;You&#x27;re looking at the results of question %s.&quot;</span><br><span class="line">    return HttpResponse(response % question_id)</span><br><span class="line"></span><br><span class="line">def vote(request, question_id):</span><br><span class="line">    return HttpResponse(&quot;You&#x27;re voting on question %s.&quot; % question_id)</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>配置应用url</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 将新增的view写入pools/urls.py</span><br><span class="line"></span><br><span class="line">from django.urls import path</span><br><span class="line"></span><br><span class="line">from . import views</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    # ex: /polls/</span><br><span class="line">    path(&quot;&quot;, views.index, name=&quot;index&quot;),</span><br><span class="line">    # ex: /polls/5/</span><br><span class="line">    path(&quot;&lt;int:question_id&gt;/&quot;, views.detail, name=&quot;detail&quot;),</span><br><span class="line">    # ex: /polls/5/results/</span><br><span class="line">    path(&quot;&lt;int:question_id&gt;/results/&quot;, views.results, name=&quot;results&quot;),</span><br><span class="line">    # ex: /polls/5/vote/</span><br><span class="line">    path(&quot;&lt;int:question_id&gt;/vote/&quot;, views.vote, name=&quot;vote&quot;),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>用户访问视图的运行流程</li>
</ol>
<p>请求页面"/polls/6/"=&gt;加载mysite.urls=&gt;找到变量"polls/"命名的urlpatterns，即<code>path("polls/", include("polls.urls"))</code>=&gt;去掉"polls/"，剩余"6/"=&gt;把剩余的"6/"发送给"<code>polls.urls</code>"
URLconf=&gt;匹配到了<code>path("&lt;int:question_id&gt;/", views.detail, name="detail")</code>=&gt;导致调用了<code>detail()</code>
视图(<code>views.py中的detail()</code>)，具体调用如<code>detail(request=&lt;HttpRequest object&gt;, question_id=34)</code></p>
<h1 id="修改views">修改Views</h1>
<h2 id="index-view">index view</h2>
<p>上述增加视图中的视图使用了虚拟实现，并没有从数据库中读取记录，或完成其他有实际意义的任务，因此在这一板块将编写实际执行某些操作的视图。</p>
<ol type="1">
<li>修改视图(index view)</li>
</ol>
<p>法1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># polls/views.py</span><br><span class="line"># 修改index view (index函数)，使用模板(利用HttpResponse和loader)，读取数据库数据</span><br><span class="line"># 加载调用的模板 polls/index.html并向其传递context。context是将模板变量名称映射到 Python 对象的字典。</span><br><span class="line">from django.http import HttpResponse</span><br><span class="line">from django.template import loader</span><br><span class="line"></span><br><span class="line">from .models import Question</span><br><span class="line"></span><br><span class="line">def index(request):</span><br><span class="line">    latest_question_list = Question.objects.order_by(&quot;-pub_date&quot;)[:5]</span><br><span class="line">    template = loader.get_template(&quot;polls/index.html&quot;)</span><br><span class="line">    context = &#123;</span><br><span class="line">        &quot;latest_question_list&quot;: latest_question_list,</span><br><span class="line">    &#125;</span><br><span class="line">    return HttpResponse(template.render(context, request))</span><br></pre></td></tr></table></figure>
<p>法2：</p>
<p>利用render()函数代替HttpResponse和loader，简化代码</p>
<p><code>render()</code>函数第一个参数是请求对象，第二个参数是模板名称，第三个参数是可选的字典。它返回一个<code>HttpResponse</code>对象，这是一个使用给定context的模板对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># polls/views.py</span><br><span class="line"></span><br><span class="line">from django.shortcuts import render</span><br><span class="line"></span><br><span class="line">from .models import Question</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def index(request):</span><br><span class="line">    latest_question_list = Question.objects.order_by(&quot;-pub_date&quot;)[:5]</span><br><span class="line">    context = &#123;&quot;latest_question_list&quot;: latest_question_list&#125;</span><br><span class="line">    return render(request, &quot;polls/index.html&quot;, context)</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>创建模板(index.html)</li>
</ol>
<p>如果页面的设计硬编码在视图中，那么当我们想要更改页面的外观时，必须编辑此
Python
代码（即views.py中的函数）。因此我们使用Django的模板系统，通过创建模板，使得页面设计与Python代码分离。</p>
<p>在应用的目录下创建templates目录（即polls/templates/），Django会默认在这个目录下寻找模板。</p>
<p>创建好模板文件后的目录结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 这里还在templates目录下创建了一个polls子目录，在子目录下才放置了模板文件index.html</span><br><span class="line"># 这里新建的polls子目录起到划分命名空间的作用。因为如果在不同的应用程序中具有相同名称的模板，Django 将无法区分它们，所以需要设置命名空间。</span><br><span class="line"></span><br><span class="line">polls/</span><br><span class="line">    __init__.py</span><br><span class="line">    admin.py</span><br><span class="line">    models.py</span><br><span class="line">    views.py</span><br><span class="line">    templates</span><br><span class="line">    	polls</span><br><span class="line">    		index.html</span><br></pre></td></tr></table></figure>
<p>index.html的文件内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># polls/templates/polls/index.html</span><br><span class="line"></span><br><span class="line">&#123;% if latest_question_list %&#125;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">    &#123;% for question in latest_question_list %&#125;</span><br><span class="line">        &lt;li&gt;&lt;a href=&quot;/polls/&#123;&#123; question.id &#125;&#125;/&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">    &lt;/ul&gt;</span><br><span class="line">&#123;% else %&#125;</span><br><span class="line">    &lt;p&gt;No polls are available.&lt;/p&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>移除模板文件中的硬编码URL</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改前</span><br><span class="line">&lt;li&gt;&lt;a href=&quot;/polls/&#123;&#123; question.id &#125;&#125;/&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt;</span><br><span class="line"></span><br><span class="line"># 修改后</span><br><span class="line">&lt;li&gt;&lt;a href=&quot;&#123;% url &#x27;detail&#x27; question.id %&#125;&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt;</span><br><span class="line"></span><br><span class="line"># 修改原因：在polls/urls.py中，views.py的detail()函数路径被注册为</span><br><span class="line">path(&quot;&lt;int:question_id&gt;/&quot;, views.detail, name=&quot;detail&quot;),其中name属性为&quot;detail&quot;</span><br><span class="line"></span><br><span class="line"># 继续修改：在polls/urls.py中设置应用程序命名空间(app_name = &quot;polls&quot;)后,继续修改为指向命名空间的详细视图</span><br><span class="line">&lt;li&gt;&lt;a href=&quot;&#123;% url &#x27;polls:detail&#x27; question.id %&#125;&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt;</span><br></pre></td></tr></table></figure>
<h2 id="detail-view">detail view</h2>
<ol type="1">
<li>修改视图(detail view)</li>
</ol>
<p>使用get方法特别容易产生404错误，因此产生了一个快捷方式，即使用<code>get_object_or_404()</code>来进行查询。<code>get_object_or_404()</code>第一个参数是a
Django
model，第二个参数是任意数量的关键词参数。如果查询对象存在，则返回该模型对象；如果对象不存在，则返回Http404。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># polls/views.py</span><br><span class="line"></span><br><span class="line">from django.shortcuts import get_object_or_404, render</span><br><span class="line"></span><br><span class="line">from .models import Question</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def detail(request, question_id):</span><br><span class="line">    question = get_object_or_404(Question, pk=question_id)</span><br><span class="line">    return render(request, &quot;polls/detail.html&quot;, &#123;&quot;question&quot;: question&#125;)</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>创建模板(detail.html)</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;form action=&quot;&#123;% url &#x27;polls:vote&#x27; question.id %&#125;&quot; method=&quot;post&quot;&gt;</span><br><span class="line">&#123;% csrf_token %&#125;</span><br><span class="line">&lt;fieldset&gt;</span><br><span class="line">    &lt;legend&gt;&lt;h1&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/h1&gt;&lt;/legend&gt;</span><br><span class="line">    &#123;% if error_message %&#125;&lt;p&gt;&lt;strong&gt;&#123;&#123; error_message &#125;&#125;&lt;/strong&gt;&lt;/p&gt;&#123;% endif %&#125;</span><br><span class="line">    &#123;% for choice in question.choice_set.all %&#125;</span><br><span class="line">        &lt;input type=&quot;radio&quot; name=&quot;choice&quot; id=&quot;choice&#123;&#123; forloop.counter &#125;&#125;&quot; value=&quot;&#123;&#123; choice.id &#125;&#125;&quot;&gt;</span><br><span class="line">        &lt;label for=&quot;choice&#123;&#123; forloop.counter &#125;&#125;&quot;&gt;&#123;&#123; choice.choice_text &#125;&#125;&lt;/label&gt;&lt;br&gt;</span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">&lt;/fieldset&gt;</span><br><span class="line">&lt;input type=&quot;submit&quot; value=&quot;Vote&quot;&gt;</span><br><span class="line">&lt;/form&gt;</span><br></pre></td></tr></table></figure>
<ol start="3" type="1">
<li>2中的vote()函数还需要具体实现</li>
</ol>
<p>后续内容可以参考官方文档https://docs.djangoproject.com/en/5.0/intro/tutorial04/</p>
]]></content>
      <categories>
        <category>开发技能</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title>Django搭建敏感图片检测系统（二）</title>
    <url>/2024/01/04/Django%E6%90%AD%E5%BB%BA%E6%95%8F%E6%84%9F%E5%9B%BE%E7%89%87%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="项目需求">项目需求</h1>
<p>目前，我已经实现了一个函数<code>detect_sensitive(img_path)</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def detect_sensitive(img_path):</span><br><span class="line">	# 1.加载训练好的检测和识别模型，获取图片中的文字，保存在sentence中，并设置初始敏感概率为0.12</span><br><span class="line">	# 2.初始化trie树，检查sentence中是否包含敏感词，若包含，将敏感概率设置为0.4592</span><br><span class="line">	# 3.加载TextCNN模型，获取textCNN模型得出的sentence的预测结果，若预测为敏感信息，将敏感概率增加0.3</span><br><span class="line">	# 3.1加载 word_2_index 字典和词嵌入层</span><br><span class="line">	# 3.2加载 TextCNN 模型</span><br><span class="line">	# 3.3对文本进行预处理，并使用 TextCNN 模型进行预测</span><br><span class="line">	# 4.最终判断该图片包含的文本是否为敏感信息isSensitive</span><br><span class="line">	# 5.返回sentence，isSensitive</span><br><span class="line">	return sentence, isSensitive</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p>它的作用是：传入一张图片，先利用训练好的检测和识别模型识别出图片中的文字，再判断文字是否为敏感信息。最终的返回值有2个，分别为<code>sentence</code>和<code>isSensitive</code>，<code>sentence</code>代表图片中的文字，<code>isSensitive</code>代表这张图片所含的文字是否为敏感信息。</p>
<p>我希望借助这个函数搭建一个”敏感图片检测系统“，系统的需求为</p>
<ul>
<li>上传一张图片</li>
<li>首先，在”白名单表“中查询这张图片是否存在，如果存在，直接将”白名单表“中的<code>statement</code>和<code>isSensitive</code>字段返回；如果不存在，就将图片传入<code>detect_sensitive()</code>进行检查，得到返回值<code>statement</code>和<code>isSensitive</code></li>
<li>其次，如果<code>isSensitive</code>为True，返回告警信息，并将告警信息存入一张”告警信息表“，同时将这张图片和它对应的敏感类型存入”白名单表“中；如果<code>isSensitive</code>为False，返回正常信息，并将这张图片和它对应的敏感类型存入”白名单表“中。</li>
</ul>
<p>数据库的物理结构设计如下：</p>
<p>”白名单表“用于存储用户上传的图片，白名单里的图片无需通过敏感信息检测模块，表内容包含编号、图片MD5值、<code>statement</code>、<code>isSensitive</code>。</p>
<p>表1 白名单表结构</p>
<table>
<thead>
<tr class="header">
<th>列名</th>
<th>数据类型</th>
<th>主键</th>
<th>注释</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>id</td>
<td>bigint</td>
<td>Primary Key</td>
<td>记录ID</td>
</tr>
<tr class="even">
<td>img_md5</td>
<td>varchar(32)</td>
<td></td>
<td>图片MD5值</td>
</tr>
<tr class="odd">
<td>isSensitive</td>
<td>tinyint(1)</td>
<td></td>
<td>图片是否敏感</td>
</tr>
<tr class="even">
<td>statement</td>
<td>longtext</td>
<td></td>
<td>图片中的文字</td>
</tr>
</tbody>
</table>
<p>”告警信息表“包含以下字段：信息编号、图片路径、图片MD5值、<code>statement</code>、<code>isSensitive</code>。</p>
<p>表2 告警信息表结构</p>
<table>
<thead>
<tr class="header">
<th>列名</th>
<th>数据类型</th>
<th>主键</th>
<th>注释</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>id</td>
<td>bigint</td>
<td>Primary Key</td>
<td>信息ID</td>
</tr>
<tr class="even">
<td>img_path</td>
<td>varchar(255)</td>
<td></td>
<td>图片路径</td>
</tr>
<tr class="odd">
<td>img_md5</td>
<td>varchar(32)</td>
<td></td>
<td>图片MD5值</td>
</tr>
<tr class="even">
<td>statement</td>
<td>longtext</td>
<td></td>
<td>图片中的文字</td>
</tr>
<tr class="odd">
<td>isSensitive</td>
<td>tinyint(1)</td>
<td></td>
<td>图片是否敏感</td>
</tr>
</tbody>
</table>
<p>我计划后端使用Django框架实现，前端使用html、css及JavaScript实现。</p>
<h1 id="创建项目">创建项目</h1>
<ol type="1">
<li>创建虚拟环境</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n sensitiveFilter python=3.8</span><br><span class="line">conda activate sensitiveFilter</span><br><span class="line">pip install Django # 注意这里Django首字母大写</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>创建项目</li>
</ol>
<p>项目名为<code>sensi_img_filter</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd D:\PythonCode</span><br><span class="line">django-admin startproject sensi_img_filter</span><br></pre></td></tr></table></figure>
<p>创建成功的项目结构为：</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sensi_img_filter/</span><br><span class="line"> manage.py</span><br><span class="line"> sensi_img_filter/</span><br><span class="line">     __init__.py</span><br><span class="line">     settings.py</span><br><span class="line">     urls.py</span><br><span class="line">     asgi.py</span><br><span class="line">     wsgi.py</span><br></pre></td></tr></table></figure>
</blockquote>
<p>启动服务器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd sensi_img_filter # cd到外层的项目文件夹下</span><br><span class="line">python manage.py runserver # 启动服务器</span><br></pre></td></tr></table></figure>
<p>项目=（一个及以上的）应用程序 + 配置</p>
<h1 id="创建应用">创建应用</h1>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 应用名称为&quot;detector&quot;</span><br><span class="line">python manage.py startapp detector</span><br></pre></td></tr></table></figure>
<p>创建成功的应用结构为：</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">detector/</span><br><span class="line"> __init__.py</span><br><span class="line"> admin.py</span><br><span class="line"> apps.py</span><br><span class="line"> migrations/</span><br><span class="line">     __init__.py</span><br><span class="line"> models.py</span><br><span class="line"> tests.py</span><br><span class="line"> views.py</span><br></pre></td></tr></table></figure>
</blockquote>
<h1 id="注册应用">注册应用</h1>
<p>在创建应用之后，我们需要将应用注册到项目中，让项目知道自己又多了一个应用，同时方便后期的数据迁移。将应用”<code>detector</code>”放到项目的setting.py（即<code>sensi_img_filter/settings.py</code>）的<code>INSTALLED_APPS</code>中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改mysite/settings.py，增加一行&#x27;detector.apps.DetectorConfig&#x27;,完成注册</span><br><span class="line"></span><br><span class="line">INSTALLED_APPS = [</span><br><span class="line">    &#x27;detector.apps.DetectorConfig&#x27;,</span><br><span class="line">    &#x27;django.contrib.admin&#x27;,</span><br><span class="line">    &#x27;django.contrib.auth&#x27;,</span><br><span class="line">    &#x27;django.contrib.contenttypes&#x27;,</span><br><span class="line">    &#x27;django.contrib.sessions&#x27;,</span><br><span class="line">    &#x27;django.contrib.messages&#x27;,</span><br><span class="line">    &#x27;django.contrib.staticfiles&#x27;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h1 id="初始配置">初始配置</h1>
<h2
id="引入应用配置文件到项目配置文件中">引入应用配置文件到项目配置文件中</h2>
<h3
id="新建应用配置文件用于配置应用detector下的url">新建应用配置文件，用于配置应用"detector"下的url</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新增detector/urls.py, 用于配置应用&quot;detector&quot;下的url</span><br><span class="line"></span><br><span class="line">from django.urls import path</span><br><span class="line"></span><br><span class="line"># 设置应用程序命名空间</span><br><span class="line"># 在真正的 Django 项目中，可能有五个、十个、二十个或更多应用程序。Django 如何区分它们之间的 URL 名称？——即将命名空间app_name = &quot;detector&quot;添加到 URLconf 中</span><br><span class="line"></span><br><span class="line">app_name = &quot;detector&quot;</span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h3
id="修改项目配置文件引入应用配置文件">修改项目配置文件，引入应用配置文件</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改sensi_img_filter/urls.py，将应用&quot;polls&quot;下的urls.py引入</span><br><span class="line"></span><br><span class="line">from django.contrib import admin</span><br><span class="line">from django.urls import include, path</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(&quot;detector/&quot;, include(&quot;detector.urls&quot;)),</span><br><span class="line">    path(&quot;admin/&quot;, admin.site.urls),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<h3 id="测试配置文件是否正确引入">测试配置文件是否正确引入</h3>
<ol type="1">
<li><p>创建index view</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改detecor/views.py，创建index view(仅为虚拟实现)</span><br><span class="line"></span><br><span class="line">from django.http import HttpResponse</span><br><span class="line"></span><br><span class="line">def index(request):</span><br><span class="line">    return HttpResponse(&quot;Hello, world. You&#x27;re at the polls index.&quot;)</span><br></pre></td></tr></table></figure></li>
<li><p>在应用配置文件<code>detector/urls.py</code>中添加url配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在detector/urls.py中配置index view的url</span><br><span class="line"></span><br><span class="line">from django.urls import path</span><br><span class="line"></span><br><span class="line">from . import views</span><br><span class="line"></span><br><span class="line">app_name = &quot;detector&quot;</span><br><span class="line">urlpatterns = [</span><br><span class="line">    # ex:/detector/</span><br><span class="line">    # path(&quot;&quot;, views.index, name=&quot;index&quot;),</span><br><span class="line">]</span><br></pre></td></tr></table></figure></li>
<li><p>启动服务器后访问链接：http://127.0.0.1:8000/detector/，即可访问到index
view，说明应用的配置文件已经正确引入到项目配置文件中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py runserver # 启动服务器</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="连接mysql数据库">连接MySQL数据库</h2>
<ol type="1">
<li><p>导入依赖</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 首次连接mysql数据库需要在虚拟环境导入以下2个包</span><br><span class="line">pip install pymysql</span><br><span class="line">pip install mysqlclient</span><br></pre></td></tr></table></figure></li>
<li><p>修改项目的数据库配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在项目的settings.py(即sensi_img_filter/settings.py)中修改数据库配置</span><br><span class="line"></span><br><span class="line"># 修改数据库配置——更改为mysql数据库</span><br><span class="line">DATABASES = &#123;</span><br><span class="line">    &#x27;default&#x27;: &#123;</span><br><span class="line">        &#x27;ENGINE&#x27;: &#x27;django.db.backends.mysql&#x27;,</span><br><span class="line">        &#x27;NAME&#x27;: &#x27;info_filter&#x27;, # 修改为数据库的名字</span><br><span class="line">        &quot;USER&quot;: &quot;root&quot;,</span><br><span class="line">        &quot;PASSWORD&quot;: &quot;123456xjy&quot;,</span><br><span class="line">        &quot;HOST&quot;: &quot;127.0.0.1&quot;,</span><br><span class="line">        &quot;PORT&quot;: &quot;3306&quot;,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>数据迁移</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 执行数据迁移——将&quot;sensi_img_filter/settings.py&quot;中INSTALLED_APPS对应的数据表都创建出来（创建到上述的&quot;info_filter&quot;数据库中）</span><br><span class="line">python manage.py migrate</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="修改静态文件默认位置">修改静态文件默认位置</h2>
<p>默认我们会将整个项目（可能包含多个应用）的静态文件（如css、js、images等）都放到项目路径下的static目录下，因此修改项目的<code>setting.py</code>（即<code>sensi_img_filter/setting.py</code>）中对静态文件默认路径的配置.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改前</span><br><span class="line"># STATIC_URL = &#x27;static/&#x27;</span><br><span class="line"></span><br><span class="line"># 修改后</span><br><span class="line">STATIC_URL = &#x27;/static/&#x27;</span><br><span class="line">STATICFILES_DIRS = [BASE_DIR / &#x27;static&#x27;]</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZoQ7a.png" alt="OZoQ7a.png" />
<figcaption aria-hidden="true">OZoQ7a.png</figcaption>
</figure>
<h1 id="具体实现">具体实现</h1>
<h2 id="创建模型">创建模型</h2>
<h3 id="创建模型-1">创建模型</h3>
<p>在<code>detector/models.py</code>中创建模型</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from django.db import models</span><br><span class="line"></span><br><span class="line"># Create your models here.</span><br><span class="line">class WhiteTableModel(models.Model):</span><br><span class="line">    img_md5 = models.CharField(max_length=32)</span><br><span class="line">    isSensitive = models.BooleanField()</span><br><span class="line">    statement = models.TextField(max_length=500)</span><br><span class="line"></span><br><span class="line">class InfoTableModel(models.Model):</span><br><span class="line">    img_path = models.CharField(max_length=255)</span><br><span class="line">    img_md5 = models.CharField(max_length=32)</span><br><span class="line">    statement = models.TextField(max_length=500)</span><br><span class="line">    isSensitive = models.BooleanField()</span><br></pre></td></tr></table></figure>
<h3 id="数据迁移">数据迁移</h3>
<ol type="1">
<li><p>产生迁移文件（可以类比为生成SQL代码）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py makemigrations detector # 这里能执行成功多亏已经在项目的setting.py的INSTALLED_APPS中注册了新应用detector</span><br></pre></td></tr></table></figure></li>
<li><p>执行迁移（类比为执行SQL代码）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 运行以下代码，即可将models.py中新创建的类，在数据库中创建出对应的数据表</span><br><span class="line">python manage.py migrate</span><br></pre></td></tr></table></figure></li>
<li><p>如果在后期某张数据表需要发生变动，那么直接修改models.py中该类的定义，再次执行步骤1和2即可在数据表同步这一变动</p></li>
</ol>
<h2 id="创建视图">创建视图</h2>
<h3 id="创建视图函数">创建视图函数</h3>
<p>在这里创建了<code>form_view()</code>和<code>handle_upload()</code>两个视图函数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from django.shortcuts import render</span><br><span class="line">from django.http import JsonResponse</span><br><span class="line">from .models import ImageModel, WhiteTableModel, InfoTableModel</span><br><span class="line">from .utils.utils import detect_sensitive, calculate_md5, save_image</span><br><span class="line"></span><br><span class="line">def form_view(request):</span><br><span class="line">    return render(request, &#x27;detector/form.html&#x27;)</span><br><span class="line"></span><br><span class="line">def handle_upload(request):</span><br><span class="line">    if request.method == &quot;POST&quot;:</span><br><span class="line">        img_file = request.FILES[&#x27;image&#x27;]</span><br><span class="line">        if img_file:</span><br><span class="line">            img_md5 = calculate_md5(img_file)</span><br><span class="line"></span><br><span class="line">            white_obj = WhiteTableModel.objects.filter(img_md5=img_md5).first()</span><br><span class="line">            if white_obj:</span><br><span class="line">                context = &#123;&#x27;message&#x27;: white_obj.statement, &#x27;isSensitive&#x27;: white_obj.isSensitive&#125;</span><br><span class="line">                # return render(request, &quot;detector/upload.html&quot;, &#123;&#x27;context&#x27;: context&#125;)</span><br><span class="line">            else:</span><br><span class="line">                # 将图片保存至某个路径供detect_sensitive使用</span><br><span class="line">                img_path = save_image(img_file, img_md5)</span><br><span class="line"></span><br><span class="line">                statement, isSensitive = detect_sensitive(img_path)</span><br><span class="line"></span><br><span class="line">                # 如果被识别为敏感图片</span><br><span class="line">                if isSensitive == True:</span><br><span class="line">                    # 创建一个信息记录并保存</span><br><span class="line">                    InfoTableModel.objects.create(</span><br><span class="line">                        img_path=img_path,</span><br><span class="line">                        img_md5=img_md5,</span><br><span class="line">                        statement=statement,</span><br><span class="line">                        isSensitive=isSensitive</span><br><span class="line">                    )</span><br><span class="line"></span><br><span class="line">                # 不论是敏感图片还是非敏感图片，都要加入白名单</span><br><span class="line">                WhiteTableModel.objects.create(</span><br><span class="line">                    img_md5=img_md5,</span><br><span class="line">                    isSensitive=isSensitive,</span><br><span class="line">                    statement=statement</span><br><span class="line">                )</span><br><span class="line"></span><br><span class="line">                # 如果被识别为敏感图片，则返回告警信息，否则返回正常信息</span><br><span class="line">                # if isSensitive == True:</span><br><span class="line">                #     context = &#123;&#x27;message&#x27;: statement, &#x27;isSensitive&#x27;: isSensitive&#125;</span><br><span class="line">                # else:</span><br><span class="line">                #     context = &#123;&#x27;message&#x27;: statement, &#x27;isSensitive&#x27;: isSensitive&#125;</span><br><span class="line">                # return JsonResponse(context)</span><br><span class="line">                context = &#123;&#x27;message&#x27;: statement, &#x27;isSensitive&#x27;: isSensitive&#125;</span><br><span class="line">            return render(request, &quot;detector/upload.html&quot;, &#123;&#x27;context&#x27;: context&#125;)</span><br><span class="line">        else:</span><br><span class="line">            error_message = &#x27;图片上传出错啦！&#x27;</span><br><span class="line">            return render(request, &#x27;detector/error.html&#x27;, &#123;&#x27;error_message&#x27;: error_message&#125;)</span><br><span class="line">    else:</span><br><span class="line">        error_message = &#x27;只接受POST请求！&#x27;</span><br><span class="line">        return render(request, &#x27;detector/error.html&#x27;, &#123;&#x27;error_message&#x27;: error_message&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># test index view</span><br><span class="line"># from django.http import HttpResponse</span><br><span class="line"># # 访问链接：http://127.0.0.1:8000/detector/</span><br><span class="line"># def index(request):</span><br><span class="line">#     return HttpResponse(&quot;Hello, world. You&#x27;re at the polls index.&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>上述函数中用到的三个工具函数detect_sensitive, calculate_md5,
save_image在utils目录下的utils.py文件夹。该文件夹内容较多，此处不做赘述。</p>
<h3 id="配置视图url">配置视图url</h3>
<p>要想请求上述创建的两个视图函数，需要现在应用的<code>urls.py(detector/urls.py)</code>中配置这两个视图的url</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># detector/settings.py</span><br><span class="line"></span><br><span class="line">from django.urls import path</span><br><span class="line"></span><br><span class="line">from . import views</span><br><span class="line"></span><br><span class="line">app_name = &quot;detector&quot;</span><br><span class="line">urlpatterns = [</span><br><span class="line">    # /detector/</span><br><span class="line">    # path(&quot;&quot;, views.index, name=&quot;index&quot;),</span><br><span class="line">    # /detector/handle_upload/</span><br><span class="line">    path(&quot;handle_upload/&quot;, views.handle_upload, name=&quot;handle_upload&quot;),</span><br><span class="line">    # /detector/form/</span><br><span class="line">    path(&quot;form/&quot;, views.form_view, name=&quot;form&quot;),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>要想访问<code>form_view()</code>函数，在启动服务器后访问链接
http://127.0.0.1:8000/detector/form/，同理要想访问<code>handle_upload()</code>函数，只需访问http://127.0.0.1:8000/detector/handle_upload/（不过handle_upload()要求使用POST请求访问，直接采取GET请求访问会返回一条错误信息，因此我们会在访问form_view()后渲染出<code>detector/form.html</code>，在这个表单上传文件，就可以采用POST请求正确访问<code>handle_upload()</code>函数，获得对应的响应）</p>
<h3 id="渲染模板文件">渲染模板文件</h3>
<p>我们会将一个应用使用的模板文件全部放入应用目录下的<code>templates</code>目录下（即<code>detector/templates/</code>），Django会默认在这个目录下寻找模板。</p>
<p>创建好模板文件后的目录结构如下：</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZoGMK.png" alt="OZoGMK.png" />
<figcaption aria-hidden="true">OZoGMK.png</figcaption>
</figure>
<blockquote>
<p>这里还在templates目录下创建了一个detector子目录，在子目录下才放置了模板文件<code>form.html</code>
这里新建的detector子目录起到划分命名空间的作用。因为如果在不同的应用程序中具有相同名称的模板，Django
将无法区分它们，所以需要设置命名空间。</p>
</blockquote>
<p>那么，模板文件form.html的内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!-- form.html --&gt;</span><br><span class="line">&#123;% load static %&#125;</span><br><span class="line">&lt;html lang=&quot;en&quot;&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;title&gt;Upload Image&lt;/title&gt;</span><br><span class="line">    &lt;link rel=&quot;stylesheet&quot; href=&quot;&#123;% static &#x27;css/form_style.css&#x27; %&#125;&quot;&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line"></span><br><span class="line">    &lt;form method=&quot;POST&quot; action=&quot;&#123;% url &#x27;detector:handle_upload&#x27; %&#125;&quot;  enctype=&quot;multipart/form-data&quot;&gt;</span><br><span class="line">      &#123;% csrf_token %&#125;</span><br><span class="line">      &lt;label for=&quot;imageUpload&quot;&gt;上传图片&lt;/label&gt;&lt;br&gt;</span><br><span class="line">      &lt;input type=&quot;file&quot; id=&quot;imageUpload&quot; name=&quot;image&quot;&gt;</span><br><span class="line">      &lt;input type=&quot;submit&quot; value=&quot;上传&quot;&gt;</span><br><span class="line">    &lt;/form&gt;</span><br><span class="line"></span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意：</p>
<ol type="1">
<li>需要在<code>&lt;form&gt;</code>表单内部增加这行代码：<code>&#123;% csrf_token %&#125;</code>，否则会报错<code>Forbidden (CSRF token missing.): /detector/form/</code></li>
<li><code>action</code>属性值表示点击<code>submit</code>时会将表单提交到什么位置，这里用了软编码<code>"&#123;% url 'detector:handle_upload' %&#125;"</code>，其中detector:表示程序命名空间，与<code>detector/urls.py</code>中的(<code>app_name="detector"</code>)相对应；<code>handle_upload</code>表示要将提交到<code>handle_upload</code>这个url路径，与<code>detector/urls.py</code>中的
<code>path("handle_upload/", views.handle_upload, name="handle_upload"),</code>中的<code>name</code>相对应</li>
<li>最头部的<code>&#123;% load static %&#125;</code>需要添加上，只有这样才能加载到项目的setting.py中配置的static默认路径，才能加载到我们的css和images静态文件</li>
</ol>
</blockquote>
<p>当通过<code>form.html</code>提交表单后，表单信息被正确提交到<code>upload_handle()</code>视图，经过<code>handle_upload()</code>函数处理，会将响应的<code>context</code>传递给模板文件<code>upload.html</code>进行渲染，这部分的对应代码为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">context = &#123;&#x27;message&#x27;: statement, &#x27;isSensitive&#x27;: isSensitive&#125;</span><br><span class="line">return render(request, &quot;detector/upload.html&quot;, &#123;&#x27;context&#x27;: context&#125;)</span><br></pre></td></tr></table></figure>
<p>模板文件<code>upload.html</code>的内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;% load static %&#125;</span><br><span class="line">&lt;html lang=&quot;en&quot;&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset=&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;title&gt;Upload Image&lt;/title&gt;</span><br><span class="line">    &lt;link rel=&quot;stylesheet&quot; href=&quot;&#123;% static &#x27;css/upload_style.css&#x27; %&#125;&quot;&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line"></span><br><span class="line">    &#123;% if context.isSensitive %&#125;</span><br><span class="line">        &lt;p class=&quot;sensitive&quot;&gt;图片中的文字为:&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;sensitive&quot;&gt;&#123;&#123; context.message &#125;&#125;&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;sensitive&quot;&gt;检查结果为：&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;sensitive&quot;&gt;敏感信息，需要屏蔽&lt;/p&gt;</span><br><span class="line">    &#123;% else %&#125;</span><br><span class="line">        &lt;p class=&quot;normal&quot;&gt;图片中的文字为: &lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;normal&quot;&gt;&#123;&#123; context.message &#125;&#125;&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;normal&quot;&gt;检查结果为：&lt;/p&gt;</span><br><span class="line">        &lt;p class=&quot;normal&quot;&gt;正常信息，允许通过&lt;/p&gt;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line"></span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>
<p>至此，项目的主体内容就已经完成。</p>
<h1 id="项目演示">项目演示</h1>
<p>上传图片：</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZodxC.png" alt="OZodxC.png" />
<figcaption aria-hidden="true">OZodxC.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZo0XN.png" alt="OZo0XN.png" />
<figcaption aria-hidden="true">OZo0XN.png</figcaption>
</figure>
<p>结果展示：</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZosJL.png" alt="OZosJL.png" />
<figcaption aria-hidden="true">OZosJL.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZoVli.png" alt="OZoVli.png" />
<figcaption aria-hidden="true">OZoVli.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZofBX.png" alt="OZofBX.png" />
<figcaption aria-hidden="true">OZofBX.png</figcaption>
</figure>
<p>查看告警信息表</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZoSHS.png" alt="OZoSHS.png" />
<figcaption aria-hidden="true">OZoSHS.png</figcaption>
</figure>
]]></content>
      <categories>
        <category>开发技能</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title>Fast RCNN论文理解</title>
    <url>/2023/12/29/Fast-RCNN%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="fast-rcnn论文理解">Fast RCNN论文理解</h1>
<p>在Fast
RCNN提出前，目标检测领域效果较好的算法是RCNN和SPPnet，因此本文主要将Fast
RCNN的改进与这两种算法进行对比。</p>
<h2 id="rcnn和sppnet的缺点">RCNN和SPPnet的缺点</h2>
<h3 id="rcnn的缺点">RCNN的缺点</h3>
<ol type="1">
<li><p>训练是多阶段的</p>
<span id="more"></span>
<ol type="1">
<li>首先，在候选区域上微调ConvNet</li>
<li>然后，对ConvNet产生的特征训练SVMs分类器，用来代替微调的CNN网络学到的softmax分类器</li>
<li>最后，学习边界框回归网络</li>
</ol></li>
<li><p>训练耗费时间和空间</p>
<ol type="1">
<li>为了训练SVM分类器和边界框回归网络，从ConvNet抽取到的候选区域的特征要先被写入磁盘</li>
<li>耗时：<strong>RCNN对每个候选区域都执行ConvNet前向传播来提取特征，没有共享计算</strong></li>
</ol></li>
<li><p>测试很慢</p>
<ol type="1">
<li>每张测试图片要先获取2000个候选区域，再对每个区域抽取特征，耗时很长</li>
</ol></li>
</ol>
<h3 id="sppnet的缺点">SPPnet的缺点</h3>
<h4 id="sppnet对rcnn的改进">SPPnet对RCNN的改进</h4>
<p>SPPnet对RCNN进行了改进，引入了一个空间金字塔池化层(SPP
layer)，这个层的本质是：通过采用动态的池化核尺寸，来限制最终特征输出尺寸的最大池化层(max
pooling
layer)。从而使网络借助该层可以把不同大小的候选区域特征图转换成特定大小的输出。</p>
<p>因此该网络的运行流程大致如下：</p>
<p>输入整张图片进行前向传播，计算一个卷积特征图=&gt;从这个共享特征图抠出每个候选区域的特征图=&gt;通过SPP
layer把不同大小的候选区域特征图转换成特定大小的输出=&gt;对特征向量进行分类。</p>
<p>这种做法只需要对整张图片做一次前向传播，得到整张图片的特征图，再从中抠出不同候选区域的特征图即可，不用像RCNN一样对2000张候选区域图像做2000次前向传播，实现了通过共享计算来加速，解决了RCNN预测时速度慢的问题</p>
<h4 id="sppnet的缺点-1">SPPnet的缺点</h4>
<ol type="1">
<li>训练是多阶段的：抽取特征==》微调网络==》训练SVMs分类器==》训练边界框回归</li>
<li>耗费时间和空间：因为要额外训练SVMs分类器和边界框回归网络，所以CNN得出的特征仍然要被写入磁盘</li>
<li>SPPnet的微调算法部分不能更新卷积层的参数，限制了深层网络的精度</li>
</ol>
<h2 id="主要贡献">主要贡献</h2>
<ol type="1">
<li>精度更高（比RCNN、SPPnet）</li>
<li>训练使用多任务损失函数(multi-task loss)实现单阶段的训练</li>
<li>训练可以更新所有的网络层</li>
<li>不需要磁盘进行特征缓存</li>
</ol>
<h2 id="模型结构">模型结构</h2>
<h3 id="总体流程">总体流程</h3>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYAJv.png" alt="OKYAJv.png" />
<figcaption aria-hidden="true">OKYAJv.png</figcaption>
</figure>
<p>输入一整张图片和一套候选区域（也叫ROIs）=&gt;Deep
ConvNet（卷积+池化）得到整体的特征图=&gt;根据候选区域在原图中的位置，使用ROI投影，获取到候选区域的特征图=&gt;针对每个候选区域，用ROI池化层把尺寸不固定的候选区域特征图转换成特定尺寸的特征图（如7
x
7）=&gt;接上2个全连接层，得到每个候选区域的特征向量=&gt;再接上两个并列的全连接层，获得两个输出：</p>
<ol type="1">
<li>利用softmax预测类别（对K+1个类别）</li>
<li>产生每个类别对应的边界框坐标（(K+1)*4）</li>
</ol>
<h3 id="与sppnet的区别">与SPPnet的区别</h3>
<ol type="1">
<li>SPPnet在ConvNet之后接上了SPP
layer（空间金字塔池化层），用来把不同尺寸的候选区域特征图转换为特定大小的输出；而Fast
RCNN在ConvNet之后接上了ROI pooling
layer（ROI池化层），用于把不同尺寸的候选区域特征图转换成特定尺寸的特征图</li>
<li>SPPnet在提取到图像的CNN特征后，又额外训练SVM进行分类和回归；而Fast
RCNN就是直接接了两个并行的全连接层做分类和回归</li>
</ol>
<h3 id="组成部分及实现步骤">组成部分及实现步骤</h3>
<h4 id="roi池化层">ROI池化层</h4>
<p>用最大池化把感兴趣区域的特征转换成特定大小的特征图（如7 x
7），是spatial pyramid pooling layer只有一个金字塔层时的特例</p>
<h4 id="初始化fast-rcnn">初始化Fast RCNN</h4>
<p>从在ImageNet上预训练好的图像分类模型（AlexNet）上初始化一个Fast
RCNN，改造步骤为;</p>
<p>（1）首先，把Conv Net之后最后一层的最大池化层替换为一个ROI池化层</p>
<p>（2）其次，网络的最后一个全连接层和softmax层替换为两个并行的全连接层（一个分支用来预测K+1个类别，一个分支用来预测边界框回归）</p>
<p>（3）最后，网络要接受两个数据输入：a list of images和 a list of ROIs
in those images</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYrxY.png" alt="OKYrxY.png" />
<figcaption aria-hidden="true">OKYrxY.png</figcaption>
</figure>
<h4 id="微调模型">微调模型</h4>
<p>即：通过反向传播来训练整个网络的权重</p>
<p>（1）为什么SPPnet不能更新空间金字塔池化层前的权重？</p>
<p>根本原因：当训练样本（ROIs）来自于不同的图片时，通过空间金字塔池化层（SPP
layer）的反向传播是无效的。（至于为啥无效，没看懂解释）</p>
<p>（2）Fast
RCNN是怎么有效训练的？（通过反向传播来训练整个网络的权重）</p>
<ul>
<li>mini-batch
分层采样：SGD的mini-batches是被分层采样的，先采样N个图片，然后从每张图片中采样R/N个ROIs。这样，来自同一张图片的ROIs就能在前向传播和后向传播中共享计算和内存。论文中取N=2，R=128。即每次采样2张图片，从每张图片采样64个ROI。</li>
<li>精简训练过程：用一个微调阶段共同优化一个softmax分类器和边界框回归器</li>
</ul>
<p>（3）multi-task loss</p>
<p>multi-task loss = 类别损失 + 框回归损失</p>
<ul>
<li>类别损失</li>
</ul>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKY7Hp.png" alt="OKY7Hp.png" />
<figcaption aria-hidden="true">OKY7Hp.png</figcaption>
</figure>
<ul>
<li>框回归损失</li>
</ul>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYNXU.png" alt="OKYNXU.png" />
<figcaption aria-hidden="true">OKYNXU.png</figcaption>
</figure>
<p>（4）mini-batch 分层采样</p>
<p>（5）通过ROI池化层反向传播</p>
<p>（6）SGD 超参数</p>
<h4 id="目标的尺度不变性">目标的尺度不变性</h4>
<p>（1）含义：如果有两个内容相同的目标，唯一区别是一个目标比较小，一个目标比较大，如果网络能将这两个目标都识别出来，说明网络具有较好的尺度不变性</p>
<p>（2）两种策略：</p>
<ul>
<li>单尺度训练：每张图片都被处理成预定义好的图片尺寸来进行训练和预测。让网络来直接学会尺度不变性</li>
<li>多尺度训练：在训练期间，每一张图片都被随机采样成特定的尺度。这也是一种数据增强的手段</li>
</ul>
<h3 id="测试流程">测试流程</h3>
<p>接收输入（一张图片和这张图片中的一系列候选区域），输入网络就能预测出候选区域的类别和精确坐标</p>
<h3 id="截断的奇异值分解">截断的奇异值分解</h3>
<p>能够减少全连接层的参数，从而加速全连接层</p>
<h3 id="实验设置">实验设置</h3>
<p>更换不同的CNN网络结构（AlexNet、VGG_CNN_M_1024、VGG16），对比实验结果（精度和测试时间）。</p>
<p>此外，还关注了一个问题：对于SPPnet中不太深的ConvNet，只微调全连接层就足以获得较好的精度，然而论文在这里假设：对于很深的网络，上述结论不成立。进而提出了一个问题：微调哪些层的效果更好？</p>
<p>实验结果是：微调卷积层精度高于只微调全连接层</p>
<h3 id="模型的设计评估">模型的设计评估</h3>
<h4 id="多任务训练是否有效">多任务训练是否有效</h4>
<p>多任务训练：指同时训练分类和边界框回归任务，共同调整一套参数</p>
<p>多阶段训练：指分类和边界框回归分成两个阶段进行训练，先训练分类，训练好后冻结参数，再额外训练一个边界框回归分支，也会利用第二个分支的回归结果</p>
<p>实验结果表明：多任务的训练结果比多阶段的要好</p>
<h4 id="单尺度还是多尺度训练">单尺度还是多尺度训练？</h4>
<p>单尺度训练：把短边固定到600像素</p>
<p>多尺度训练：把短边固定到5种像素</p>
<p>结果：多尺度精度更高</p>
<h4 id="是否需要更多训练数据">是否需要更多训练数据</h4>
<p>扩增2007数据集，精度会提高。不会出现传统模型出现的精度饱和的情况</p>
<h4 id="svm是不是比softmax好">SVM是不是比softmax好？</h4>
<p>实验结果：Fast RCNN中，直接用softmax效果比好</p>
<h4 id="候选区域是不是越多越好">候选区域是不是越多越好？</h4>
<p>实验结果：候选区域越多，精度先提升后下降</p>
<p>参考资料：</p>
<blockquote>
<p>https://www.bilibili.com/video/BV1y94y1Q7QJ/?spm_id_from=333.880.my_history.page.click&amp;vd_source=66a72b15abe9693bd8b4f738f5a67ee7</p>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>Fast RCNN</tag>
        <tag>论文理解</tag>
      </tags>
  </entry>
  <entry>
    <title>FastRCNN代码复现</title>
    <url>/2023/12/29/FastRCNN%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="fast-rcnn代码复现">Fast RCNN代码复现</h1>
<p>项目源代码下载地址：</p>
<blockquote>
<p>Fast-R-CNN-pytorch-master https://www.alipan.com/s/FqYEYzqCe7k
提取码:ue87 点击链接保存，或者复制本段内容，打开「阿里云盘」APP
，无需下载极速在线查看，视频原画倍速播放。</p>
</blockquote>
<span id="more"></span>
<p>项目目录如下;</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYKlq.png" alt="OKYKlq.png" />
<figcaption aria-hidden="true">OKYKlq.png</figcaption>
</figure>
<p>对Fast RCNN的论文理解见专栏的上篇内容，本文介绍Fast
RCNN的代码复现。基本流程如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">利用coco2017数据集训练Fast-RCNN模型（训练过程详细步骤记录）：</span><br><span class="line"></span><br><span class="line">（1）初始化COCO数据集</span><br><span class="line"></span><br><span class="line">（2）构造训练集和验证集：利用选择搜索算法（selective-search）生成一定数量的候选框，将候选框与gound-truth进行IOU（交并比）计算，如果IoU大于等于0.5，则认为候选区域是正样本，0.1&lt;IoU&lt;0.5，则认为候选区域是负样本</span><br><span class="line"></span><br><span class="line">（3）设置ROI Pooling模块、特征提取网络模型。利用ROIPlooing方法，从共享特征图抠出各个候选区域特征图</span><br><span class="line"></span><br><span class="line">（4）设置输出为一个分类分支（类别类数+背景类（1））与回归分支</span><br><span class="line"></span><br><span class="line">（5）设置多目标损失函数：交叉熵损失与回归损失</span><br><span class="line"></span><br><span class="line">（6）训练网络模型</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="初始化coco数据集">初始化COCO数据集</h4>
<p><strong>COCOdataset.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> PIL</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    COCO数据集的处理</span></span><br><span class="line"><span class="string">    1、读取数据</span></span><br><span class="line"><span class="string">    2、数据的预处理</span></span><br><span class="line"><span class="string">    3、数据的加载</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	需要修改内容：COCO数据集的存放路径、加载训练集还是验证集(mode为&quot;train&quot;or&quot;val&quot;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">COCOdataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="comment"># todo：注意修改coco数据集的存放路径</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, <span class="built_in">dir</span>=<span class="string">&#x27;D:\\WritePapers\\object_detection_basics\\Datasets\\COCO2017\\&#x27;</span>, mode=<span class="string">&#x27;train&#x27;</span>,</span></span><br><span class="line"><span class="params">                 transform=transforms.Compose(<span class="params">[transforms.ToTensor(<span class="params"></span>),</span></span></span><br><span class="line"><span class="params"><span class="params">                                               transforms.Normalize(<span class="params">[<span class="number">0.485</span>, <span class="number">0.456</span>, -<span class="number">.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span>)]</span>)</span>):</span><br><span class="line">        <span class="comment"># transform执行2步操作：1、将PIL.Image转换为torch.Tensor，并自动将数据缩放到[0,1]之间；</span></span><br><span class="line">        <span class="comment"># 2.对图像进行标准化。这里的两个参数分别是RGB通道的均值和标准差。这个操作会按照每个通道进行标准化，即(image - mean) / std</span></span><br><span class="line">        <span class="comment"># transforms.Normalize([0.485, 0.456, -.406], [0.229, 0.224, 0.225])的两个参数分别是ImageNet数据集的统计得到的RGB通道的均值和标准差</span></span><br><span class="line">        <span class="comment"># 这样做的目的是使得模型的输入数据分布和预训练模型（项目使用了在ImageNet预训练的VGG19模型）的输入数据分布一致，从而可以更好地利用预训练模型。</span></span><br><span class="line">        <span class="keyword">assert</span> mode <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>], <span class="string">&#x27;mode must be \&#x27;train\&#x27; or \&#x27;val\&#x27;&#x27;</span></span><br><span class="line">        self.<span class="built_in">dir</span> = <span class="built_in">dir</span> <span class="comment"># self关键字代表类的实例</span></span><br><span class="line">        self.mode = mode <span class="comment"># train则加载训练集，val则加载验证集</span></span><br><span class="line">        self.transform = transform</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(self.<span class="built_in">dir</span>, <span class="string">&#x27;%s.json&#x27;</span> % self.mode), <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f: <span class="comment">#%s是一个字符串占位符。%操作符用于指定要插入的值==&gt;%s会被self.mode的值替换</span></span><br><span class="line">            self.ss_regions = json.load(f)</span><br><span class="line">        <span class="comment"># with语句并不创建一个新的作用域。在with语句块内部定义的变量，其作用域是包含with语句的那个作用域。</span></span><br><span class="line">        self.img_dir = os.path.join(self.<span class="built_in">dir</span>, <span class="string">&#x27;%s2017&#x27;</span> % self.mode)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.ss_regions) <span class="comment"># 说明ss_regions是一个列表，每个元素代表一张图片对应的region信息</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, i, max_num_pos=<span class="number">8</span>, max_num_neg=<span class="number">16</span></span>):</span><br><span class="line">        img = PIL.Image.<span class="built_in">open</span>(os.path.join(self.img_dir, <span class="string">&#x27;%012d.jpg&#x27;</span> %</span><br><span class="line">                                     self.ss_regions[i][<span class="string">&#x27;id&#x27;</span>]))</span><br><span class="line">        <span class="comment"># %012d是一个占位符，表示一个十二位的整数，不足十二位的部分会用0填充==&gt;%012d会被self.ss_regions[i][&#x27;id&#x27;]的值替换，self.ss_regions[i][&#x27;id&#x27;]是从JSON文件中读取的某张图片的ID</span></span><br><span class="line">        img = img.convert(<span class="string">&#x27;RGB&#x27;</span>) <span class="comment"># 将图片转换为RGB格式</span></span><br><span class="line">        img = img.resize([<span class="number">224</span>, <span class="number">224</span>])</span><br><span class="line">        pos_regions = self.ss_regions[i][<span class="string">&#x27;pos_regions&#x27;</span>] <span class="comment"># 获取正样本区域</span></span><br><span class="line">        neg_regions = self.ss_regions[i][<span class="string">&#x27;neg_regions&#x27;</span>] <span class="comment"># 获取负样本区域</span></span><br><span class="line">        <span class="keyword">if</span> self.transform != <span class="literal">None</span>: <span class="comment"># 如果设置了图像预处理方法</span></span><br><span class="line">            img = self.transform(img)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(pos_regions) &gt; max_num_pos: <span class="comment"># 如果正样本区域的数量大于最大数量,随机选择一部分正样本区域</span></span><br><span class="line">            pos_regions = random.sample(pos_regions, max_num_pos)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(neg_regions) &gt; max_num_neg:</span><br><span class="line">            neg_regions = random.sample(neg_regions, max_num_neg)</span><br><span class="line">        regions = pos_regions + neg_regions <span class="comment"># 合并正样本区域和负样本区域</span></span><br><span class="line">        random.shuffle(regions) <span class="comment"># 随机打乱区域</span></span><br><span class="line">        rects = [] <span class="comment"># 初始化矩形列表</span></span><br><span class="line">        rela_locs = []  <span class="comment"># 初始化相对位置列表</span></span><br><span class="line">        cats = [] <span class="comment"># 初始化类别列表</span></span><br><span class="line">        <span class="keyword">for</span> region <span class="keyword">in</span> regions:<span class="comment"># 遍历第i张图片的得到的区域（包括正样本和负样本区域）</span></span><br><span class="line">            rects.append(region[<span class="string">&#x27;rect&#x27;</span>]) <span class="comment"># 将区域的矩形信息添加到矩形列表中</span></span><br><span class="line">            p_rect = region[<span class="string">&#x27;rect&#x27;</span>] <span class="comment"># 获取区域的矩形信息</span></span><br><span class="line">            g_rect = region[<span class="string">&#x27;gt_rect&#x27;</span>] <span class="comment"># 获取区域的真实矩形信息</span></span><br><span class="line">            t_x = (g_rect[<span class="number">0</span>] + g_rect[<span class="number">2</span>] - p_rect[<span class="number">0</span>] - p_rect[<span class="number">2</span>]) / <span class="number">2</span> / (p_rect[<span class="number">2</span>] - p_rect[<span class="number">0</span>])</span><br><span class="line">            t_y = (g_rect[<span class="number">1</span>] + g_rect[<span class="number">3</span>] - p_rect[<span class="number">1</span>] - p_rect[<span class="number">3</span>]) / <span class="number">2</span> / (p_rect[<span class="number">3</span>] - p_rect[<span class="number">1</span>])</span><br><span class="line">            t_w = math.log((g_rect[<span class="number">2</span>] - g_rect[<span class="number">0</span>]) / (p_rect[<span class="number">2</span>] - p_rect[<span class="number">0</span>]))</span><br><span class="line">            t_h = math.log((g_rect[<span class="number">3</span>] - g_rect[<span class="number">1</span>]) / (p_rect[<span class="number">3</span>] - p_rect[<span class="number">1</span>]))</span><br><span class="line">            rela_locs.append([t_x, t_y, t_w, t_h]) <span class="comment"># 将区域的相对位置信息添加到相对位置列表中</span></span><br><span class="line">            cats.append(region[<span class="string">&#x27;category&#x27;</span>]) <span class="comment"># 将区域的类别信息添加到类别列表中</span></span><br><span class="line">        roi_idx_len = <span class="built_in">len</span>(regions) <span class="comment"># 获取区域的数量</span></span><br><span class="line">        <span class="keyword">return</span> img, rects, roi_idx_len, rela_locs, cats</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset = COCOdataset()</span></span><br><span class="line"><span class="comment"># print(dataset[1][0].shape)</span></span><br><span class="line"><span class="comment"># print(dataset[1][1])</span></span><br><span class="line"><span class="comment"># from torch.utils.data import DataLoader</span></span><br><span class="line"><span class="comment"># dataloader = DataLoader(dataset, batch_size=2)</span></span><br><span class="line"><span class="comment"># print(next(iter(dataloader))[1])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dataset = COCOdataset()</span><br><span class="line">    <span class="built_in">print</span>(dataset.__len__())</span><br><span class="line">    img, rects, roi_idx_len, rela_locs, cats = dataset.__getitem__(<span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(img, rects, roi_idx_len, rela_locs, cats)</span><br><span class="line">    <span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">    loader = DataLoader(dataset, batch_size=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i, temp <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">        <span class="built_in">print</span>(i,<span class="built_in">type</span>(temp))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="构造训练集和验证集">构造训练集和验证集</h4>
<p><strong>利用选择搜索算法（selective-search）生成一定数量的候选框，将候选框与gound-truth进行IOU（交并比）计算，如果IoU大于等于0.5，则认为候选区域是正样本，0.1&lt;IoU&lt;0.5，则认为候选区域是负样本</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse <span class="comment"># 导入argparse模块，用于处理命令行参数</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> sys <span class="comment"># 导入sys模块，用于处理Python运行时环境</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> progressbar <span class="keyword">import</span> * <span class="comment"># 导入progressbar模块，用于显示进度条</span></span><br><span class="line"><span class="keyword">from</span> pycocotools.coco <span class="keyword">import</span> COCO <span class="comment"># 导入pycocotools模块，用于处理COCO数据集</span></span><br><span class="line"><span class="keyword">from</span> selectivesearch <span class="keyword">import</span> selective_search <span class="comment"># 从selectivesearch模块导入selective_search函数，用于进行选择性搜索</span></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io, util, color <span class="comment"># 从selectivesearch模块导入selective_search函数，用于进行选择性搜索</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_iou</span>(<span class="params">a, b</span>): <span class="comment"># 定义计算IoU（交并比）的函数，输入参数为两个矩形框</span></span><br><span class="line">    <span class="comment"># 矩形框的格式为：[左上角x坐标，左上角y坐标，宽度，高度]</span></span><br><span class="line">    a_min_x, a_min_y, a_delta_x, a_delta_y = a</span><br><span class="line">    b_min_x, b_min_y, b_delta_x, b_delta_y = b</span><br><span class="line">    a_max_x = a_min_x + a_delta_x</span><br><span class="line">    a_max_y = a_min_y + a_delta_y</span><br><span class="line">    b_max_x = b_min_x + b_delta_x</span><br><span class="line">    b_max_y = b_min_y + b_delta_y</span><br><span class="line">    <span class="comment"># 如果两个矩形框没有交集，则IoU为0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">min</span>(a_max_y, b_max_y) &lt; <span class="built_in">max</span>(a_min_y, b_min_y) <span class="keyword">or</span> <span class="built_in">min</span>(a_max_x, b_max_x) &lt; <span class="built_in">max</span>(a_min_x, b_min_x):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 计算交集的面积</span></span><br><span class="line">        intersect_area = (<span class="built_in">min</span>(a_max_y, b_max_y) - <span class="built_in">max</span>(a_min_y, b_min_y) + <span class="number">1</span>) * \</span><br><span class="line">            (<span class="built_in">min</span>(a_max_x, b_max_x) - <span class="built_in">max</span>(a_min_x, b_min_x) + <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算并集的面积</span></span><br><span class="line">        union_area = (a_delta_x + <span class="number">1</span>) * (a_delta_y + <span class="number">1</span>) + \</span><br><span class="line">            (b_delta_x + <span class="number">1</span>) * (b_delta_y + <span class="number">1</span>) - intersect_area</span><br><span class="line">        <span class="comment"># 返回IoU</span></span><br><span class="line">        <span class="keyword">return</span> intersect_area / union_area</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ss_img</span>(<span class="params">img_id, coco, cat_dict, args</span>): <span class="comment"># 定义selective_search函数，输入参数为图像id、COCO数据集、类别字典、命令行参数</span></span><br><span class="line">    img_path = os.path.join(args.data_dir, args.mode +</span><br><span class="line">                            <span class="string">&#x27;2017&#x27;</span>, <span class="string">&#x27;%012d.jpg&#x27;</span> % img_id) <span class="comment"># 获取图像的路径</span></span><br><span class="line">    coco_dict = &#123;cat[<span class="string">&#x27;id&#x27;</span>]: cat[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">                 <span class="keyword">for</span> cat <span class="keyword">in</span> coco.loadCats(coco.getCatIds())&#125;  <span class="comment"># 创建一个字典，将COCO数据集的类别ID映射到类别名</span></span><br><span class="line">    img = io.imread(img_path) <span class="comment"># 读取图像</span></span><br><span class="line">    <span class="keyword">if</span> img.ndim == <span class="number">2</span>:    <span class="comment"># 如果图像是灰度图，则将其转换为RGB图像</span></span><br><span class="line">        img = color.gray2rgb(img)</span><br><span class="line">    _, ss_regions = selective_search(   <span class="comment"># 对图像进行选择性搜索，获取候选区域</span></span><br><span class="line">        img, args.scale, args.sigma, args.min_size)         <span class="comment"># &#x27;rect&#x27;: (left, top, width, height)</span></span><br><span class="line">    anns = coco.loadAnns(coco.getAnnIds(</span><br><span class="line">        imgIds=[img_id], catIds=coco.getCatIds(catNms=args.cats))) <span class="comment"># 获取图像的标注信息</span></span><br><span class="line">    pos_regions = [] <span class="comment"># 初始化正样本区域列表</span></span><br><span class="line">    neg_regions = [] <span class="comment"># 初始化负样本区域列表</span></span><br><span class="line">    h = img.shape[<span class="number">0</span>] <span class="comment"># 获取图像的高度</span></span><br><span class="line">    w = img.shape[<span class="number">1</span>] <span class="comment"># 获取图像的宽度</span></span><br><span class="line">    <span class="keyword">for</span> region <span class="keyword">in</span> ss_regions: <span class="comment"># 遍历每个候选区域</span></span><br><span class="line">        <span class="keyword">for</span> ann <span class="keyword">in</span> anns: <span class="comment"># 遍历每个标注信息</span></span><br><span class="line">            iou = cal_iou(region[<span class="string">&#x27;rect&#x27;</span>], ann[<span class="string">&#x27;bbox&#x27;</span>]) <span class="comment"># 计算候选区域和标注区域的IoU</span></span><br><span class="line">            <span class="keyword">if</span> iou &gt;= <span class="number">0.1</span>: <span class="comment"># 如果IoU大于等于0.1，则认为候选区域是有效的</span></span><br><span class="line">                rect = <span class="built_in">list</span>(region[<span class="string">&#x27;rect&#x27;</span>]) <span class="comment"># 获取候选区域的矩形框</span></span><br><span class="line">                rect[<span class="number">0</span>] = rect[<span class="number">0</span>] / w <span class="comment"># 将矩形框的x坐标转换为相对于图像宽度的比例</span></span><br><span class="line">                rect[<span class="number">1</span>] = rect[<span class="number">1</span>] / h <span class="comment"># 将矩形框的y坐标转换为相对于图像高度的比例</span></span><br><span class="line">                rect[<span class="number">2</span>] = rect[<span class="number">0</span>] + rect[<span class="number">2</span>] / w <span class="comment"># 将矩形框的宽度转换为相对于图像宽度的比例</span></span><br><span class="line">                rect[<span class="number">3</span>] = rect[<span class="number">1</span>] + rect[<span class="number">3</span>] / h <span class="comment"># 将矩形框的高度转换为相对于图像高度的比例</span></span><br><span class="line">                gt_rect = <span class="built_in">list</span>(ann[<span class="string">&#x27;bbox&#x27;</span>]) <span class="comment"># 获取标注区域的矩形框</span></span><br><span class="line">                gt_rect[<span class="number">0</span>] = gt_rect[<span class="number">0</span>] / w <span class="comment"># 将矩形框的x坐标转换为相对于图像宽度的比例</span></span><br><span class="line">                gt_rect[<span class="number">1</span>] = gt_rect[<span class="number">1</span>] / h <span class="comment"># 将矩形框的y坐标转换为相对于图像高度的比例</span></span><br><span class="line">                gt_rect[<span class="number">2</span>] = gt_rect[<span class="number">0</span>] + gt_rect[<span class="number">2</span>] / w <span class="comment"># 将矩形框的宽度转换为相对于图像宽度的比例</span></span><br><span class="line">                gt_rect[<span class="number">3</span>] = gt_rect[<span class="number">1</span>] + gt_rect[<span class="number">3</span>] / h <span class="comment"># 将矩形框的高度转换为相对于图像高度的比例</span></span><br><span class="line">                <span class="keyword">if</span> iou &gt;= <span class="number">0.5</span>: <span class="comment"># 如果IoU大于等于0.5，则认为候选区域是正样本</span></span><br><span class="line">                    pos_regions.append(&#123;<span class="string">&#x27;rect&#x27;</span>: rect, </span><br><span class="line">                                        <span class="string">&#x27;gt_rect&#x27;</span>: gt_rect,</span><br><span class="line">                                        <span class="string">&#x27;category&#x27;</span>: cat_dict[coco_dict[ann[<span class="string">&#x27;category_id&#x27;</span>]]]&#125;)</span><br><span class="line">                <span class="keyword">else</span>: <span class="comment"># 否则，认为候选区域是负样本</span></span><br><span class="line">                    neg_regions.append(&#123;<span class="string">&#x27;rect&#x27;</span>: rect, </span><br><span class="line">                                        <span class="string">&#x27;gt_rect&#x27;</span>: gt_rect,</span><br><span class="line">                                        <span class="string">&#x27;category&#x27;</span>: <span class="number">0</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> pos_regions, neg_regions <span class="comment"># 返回正样本区域和负样本区域</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(<span class="string">&#x27;parser to create regions&#x27;</span>) <span class="comment"># 创建一个命令行参数解析器，用于处理命令行参数。</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;D:\\WritePapers\\object_detection_basics\\Datasets\\COCO2017\\&#x27;</span>) <span class="comment"># 指定COCO2017数据集的路径</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--mode&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;train&#x27;</span>)   <span class="comment"># train/val</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;D:\\WritePapers\\object_detection_basics\\Datasets\\COCO2017\\&#x27;</span>) <span class="comment">#指定保存结果的路径</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cats&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, nargs=<span class="string">&#x27;*&#x27;</span>, default=[</span><br><span class="line">                        <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>, <span class="string">&#x27;elephant&#x27;</span>, <span class="string">&#x27;bear&#x27;</span>, <span class="string">&#x27;zebra&#x27;</span>, <span class="string">&#x27;giraffe&#x27;</span>]) <span class="comment"># 指定需要处理的类别</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--scale&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">30.0</span>) <span class="comment"># 指定选择性搜索的尺度</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--sigma&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.8</span>) <span class="comment"># 指定选择性搜索的高斯平滑参数</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--min_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">50</span>) <span class="comment"># 指定选择性搜索的最小区域大小</span></span><br><span class="line">    args = parser.parse_args() <span class="comment"># 解析命令行参数，并将结果保存在args中</span></span><br><span class="line">    coco = COCO(os.path.join(args.data_dir, <span class="string">&#x27;annotations&#x27;</span>,</span><br><span class="line">                             <span class="string">&#x27;instances_%s2017.json&#x27;</span> % args.mode)) <span class="comment">#加载COCO2017数据集的标注信息</span></span><br><span class="line">    cat_dict = &#123;args.cats[i]: i+<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(args.cats))&#125; <span class="comment"># 创建一个字典，将类别名称映射到类别ID</span></span><br><span class="line">    cat_dict[<span class="string">&#x27;background&#x27;</span>] = <span class="number">0</span> <span class="comment"># 将背景类别的ID设置为0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># get relavant image ids</span></span><br><span class="line">    <span class="keyword">if</span> args.mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">        num_cat = <span class="number">400</span> <span class="comment"># 如果运行模式为训练，则每个类别的图像数量设置为400</span></span><br><span class="line">    <span class="keyword">if</span> args.mode == <span class="string">&#x27;val&#x27;</span>:</span><br><span class="line">        num_cat = <span class="number">100</span> <span class="comment"># 如果运行模式为验证，则每个类别的图像数量设置为100</span></span><br><span class="line">    img_ids = []</span><br><span class="line">    cat_ids = coco.getCatIds(catNms=args.cats) <span class="comment"># 获取需要处理的类别的ID</span></span><br><span class="line">    <span class="keyword">for</span> cat_id <span class="keyword">in</span> cat_ids:</span><br><span class="line">        cat_img_ids = coco.getImgIds(catIds=[cat_id]) <span class="comment"># 获取该类别的所有图像ID</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(cat_img_ids) &gt; num_cat:</span><br><span class="line">            cat_img_ids = random.sample(cat_img_ids, num_cat) <span class="comment"># 如果该类别的图像数量大于num_cat，则随机选择num_cat个图像</span></span><br><span class="line">        img_ids += cat_img_ids <span class="comment"># 将选择的图像ID添加到图像ID列表</span></span><br><span class="line">    img_ids = <span class="built_in">list</span>(<span class="built_in">set</span>(img_ids)) <span class="comment"># 去除重复的图像ID</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># selective_search each image</span></span><br><span class="line">    <span class="comment"># [&#123;&#x27;id&#x27;: 1, &#x27;pos_regions&#x27;:[...], &#x27;neg_regions&#x27;:[...]&#125;, ...]</span></span><br><span class="line"></span><br><span class="line">    num_imgs = <span class="built_in">len</span>(img_ids) <span class="comment"># 获取图像的数量</span></span><br><span class="line">    ss_regions = [] <span class="comment"># 初始化选择性搜索的区域列表</span></span><br><span class="line">    p = ProgressBar(widgets=[<span class="string">&#x27;Progress: &#x27;</span>, Percentage(),</span><br><span class="line">                             <span class="string">&#x27; &#x27;</span>, Bar(<span class="string">&#x27;#&#x27;</span>), <span class="string">&#x27; &#x27;</span>, Timer(), <span class="string">&#x27; &#x27;</span>, ETA()]) <span class="comment"># 创建一个进度条</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> p(<span class="built_in">range</span>(num_imgs)): <span class="comment"># 遍历每个图像</span></span><br><span class="line">        img_id = img_ids[i] <span class="comment"># 获取当前图像的ID</span></span><br><span class="line">        pos_regions, neg_regions = ss_img(img_id, coco, cat_dict, args) <span class="comment"># 对当前图像进行选择性搜索，获取正样本区域和负样本区域</span></span><br><span class="line">        ss_regions.append(&#123;<span class="string">&#x27;id&#x27;</span>: img_id,</span><br><span class="line">                           <span class="string">&#x27;pos_regions&#x27;</span>: pos_regions,</span><br><span class="line">                           <span class="string">&#x27;neg_regions&#x27;</span>: neg_regions&#125;)<span class="comment"># 将当前图像的ID、正样本区域和负样本区域添加到选择性搜索的区域列表中</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># save</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(args.save_dir, <span class="string">&#x27;%s.json&#x27;</span> % args.mode), <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(ss_regions, f) <span class="comment"># 将选择性搜索的区域列表保存为JSON格式</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="设置roi-pooling模块特征提取网络模型及多目标损失函数">设置ROI
Pooling模块、特征提取网络模型及多目标损失函数</h4>
<p><strong>ROI Plooing模块</strong> <strong>roipooling.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ROIPooling</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, output_size</span>): <span class="comment"># 初始化函数，设置输出大小</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.maxpool = nn.AdaptiveMaxPool2d(output_size)  <span class="comment"># 创建一个自适应最大池化层，输出大小为output_size</span></span><br><span class="line">        self.size = output_size  <span class="comment"># 设置输出大小</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, imgs, rois, roi_idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param img: img:批次内的图像</span></span><br><span class="line"><span class="string">        :param rois: rois:[[单张图片内框体],[],[]]</span></span><br><span class="line"><span class="string">        :param roi_idx: [2]*6-------&gt;[2, 2, 2, 2, 2, 2]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        n = rois.shape[<span class="number">0</span>] <span class="comment"># 获取roi的数量</span></span><br><span class="line">        h = imgs.shape[<span class="number">2</span>] <span class="comment"># 获取图像的高度</span></span><br><span class="line">        w = imgs.shape[<span class="number">3</span>] <span class="comment"># 获取图像的宽度</span></span><br><span class="line"></span><br><span class="line">        x1 = rois[:, <span class="number">0</span>] <span class="comment"># 获取所有区域的左上角x坐标</span></span><br><span class="line">        y1 = rois[:, <span class="number">1</span>] <span class="comment"># 获取所有区域的左上角y坐标</span></span><br><span class="line">        x2 = rois[:, <span class="number">2</span>] <span class="comment"># 获取所有区域的右下角x坐标</span></span><br><span class="line">        y2 = rois[:, <span class="number">3</span>] <span class="comment"># 获取所有区域的右下角y坐标</span></span><br><span class="line"></span><br><span class="line">        x1 = np.floor(x1 * w).astype(<span class="built_in">int</span>) <span class="comment"># 将x1坐标转换为图像的实际坐标</span></span><br><span class="line">        x2 = np.ceil(x2 * w).astype(<span class="built_in">int</span>) <span class="comment"># 将x2坐标转换为图像的实际坐标</span></span><br><span class="line">        y1 = np.floor(y1 * h).astype(<span class="built_in">int</span>) <span class="comment"># 将y1坐标转换为图像的实际坐标</span></span><br><span class="line">        y2 = np.ceil(y2 * h).astype(<span class="built_in">int</span>) <span class="comment"># 将y2坐标转换为图像的实际坐标</span></span><br><span class="line"></span><br><span class="line">        res = [] <span class="comment"># 初始化结果列表</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n): <span class="comment"># 遍历每个区域</span></span><br><span class="line">            img = imgs[roi_idx[i]].unsqueeze(dim=<span class="number">0</span>) <span class="comment"># 获取第i个区域所在的图像</span></span><br><span class="line">            img = img[:, :, y1[i]:y2[i], x1[i]:x2[i]]  <span class="comment"># 对图像进行裁剪，只保留区域内的部分</span></span><br><span class="line">            img = self.maxpool(img) <span class="comment"># 对裁剪后的图像进行最大池化操作</span></span><br><span class="line">            res.append(img) <span class="comment"># 将处理后的图像添加到结果列表中</span></span><br><span class="line">        res = torch.cat(res, dim=<span class="number">0</span>) <span class="comment"># 将所有处理后的图像沿着批次维度拼接起来，最终res保存了所有池化后的ROI区域</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">    imgs = torch.randn(<span class="number">2</span>, <span class="number">10</span>, <span class="number">224</span>, <span class="number">224</span>) <span class="comment"># 创建一个随机的图像张量（batch_size, Channel, Height, Weight）</span></span><br><span class="line">    rois = np.array([[<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.4</span>],</span><br><span class="line">                    [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.7</span>, <span class="number">0.7</span>],</span><br><span class="line">                    [<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.3</span>]]) <span class="comment"># 创建一个随机的区域张量（x1, y1, x2, y2）</span></span><br><span class="line">    <span class="comment"># roi_idx表示每个区域（Region of Interest，ROI）所在的图像的索引</span></span><br><span class="line">    <span class="comment"># 表示有三个区域，前两个区域在第一张图像上（索引为0），第三个区域在第二张图像上（索引为1）</span></span><br><span class="line">    roi_idx = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    r = ROIPooling((<span class="number">7</span>, <span class="number">7</span>)) <span class="comment"># (7, 7)表示池化后的输出大小为7x7。这意味着无论输入区域的大小如何，ROIPooling层都会将其池化为7x7的大小</span></span><br><span class="line">    <span class="built_in">print</span>(r.forward(imgs, rois, roi_idx).shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>fast_rcnn.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> .roipooling <span class="keyword">import</span> ROIPooling <span class="comment"># 从当前目录下的roipooling模块导入ROIPooling类</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FastRCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes</span>):<span class="comment"># 初始化方法，接收一个参数：类别数量</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.num_classes = num_classes <span class="comment"># 将类别数量保存为实例变量</span></span><br><span class="line">        vgg = torchvision.models.vgg19_bn(pretrained=<span class="literal">True</span>) <span class="comment"># 加载预训练的VGG19模型</span></span><br><span class="line">        <span class="comment"># 获取VGG19模型的特征提取部分：通过卷积和池化操作提取图像的特征</span></span><br><span class="line">        <span class="comment"># vgg.features.children(): vgg.features获取VGG19模型的特征提取部分，children()方法获取这部分的所有子模块。这些子模块是一系列的卷积层、激活函数和池化层。</span></span><br><span class="line">        <span class="comment"># list(vgg.features.children()): 将子模块的迭代器转换为列表</span></span><br><span class="line">        <span class="comment"># list(vgg.features.children())[:-1]: 使用切片操作获取除最后一个子模块外的所有子模块。在VGG19模型中，最后一个子模块是一个池化层。</span></span><br><span class="line">        <span class="comment"># *list(vgg.features.children())[:-1]: 使用*操作符将列表解包，这样每个子模块都会作为nn.Sequential的一个单独参数传入。</span></span><br><span class="line">        <span class="comment"># nn.Sequential(*list(vgg.features.children())[:-1]): nn.Sequential是一个容器，它按照在构造函数中传入的顺序保存各个模块。</span></span><br><span class="line">        self.features = nn.Sequential(*<span class="built_in">list</span>(vgg.features.children())[:-<span class="number">1</span>])</span><br><span class="line">        self.roipool = ROIPooling(output_size=(<span class="number">7</span>, <span class="number">7</span>)) <span class="comment"># 创建ROIPooling层，输出大小为7x7</span></span><br><span class="line">        <span class="comment"># vgg.classifier.children(): vgg.classifier获取VGG19模型的分类部分，children()方法获取这部分的所有子模块。这些子模块是一系列的全连接层、激活函数和Dropout层。</span></span><br><span class="line">        <span class="comment"># list(vgg.classifier.children())[:-1]: 使用切片操作获取除最后一个子模块外的所有子模块。在VGG19模型中，最后一个子模块是一个全连接层，用于输出每个类别的概率。</span></span><br><span class="line">        self.output = nn.Sequential(*<span class="built_in">list</span>(vgg.classifier.children())[:-<span class="number">1</span>]) <span class="comment"># 获取VGG19模型的分类部分</span></span><br><span class="line">        self.prob = nn.Linear(<span class="number">4096</span>, num_classes+<span class="number">1</span>)<span class="comment"># 创建一个线性层，用于输出每个类别的概率</span></span><br><span class="line">        self.loc = nn.Linear(<span class="number">4096</span>, <span class="number">4</span> * (num_classes + <span class="number">1</span>)) <span class="comment"># 创建一个线性层，用于输出每个类别的边界框位置</span></span><br><span class="line"></span><br><span class="line">        self.cat_loss = nn.CrossEntropyLoss() <span class="comment"># 创建交叉熵损失函数，用于计算类别损失</span></span><br><span class="line">        self.loc_loss = nn.SmoothL1Loss() <span class="comment"># 创建Smooth L1损失函数，用于计算位置损失</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img, rois, roi_idx</span>): <span class="comment"># 接收三个参数：图像、区域、区域索引</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param img: img:批次内的图像</span></span><br><span class="line"><span class="string">        :param rois: rois:[[单张图片内框体],[],[]]</span></span><br><span class="line"><span class="string">        :param roi_idx: [2]*6-------&gt;[2, 2, 2, 2, 2, 2]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        res = self.features(img) <span class="comment"># 对图像进行特征提取</span></span><br><span class="line">        res = self.roipool(res, rois, roi_idx) <span class="comment"># 对特征图进行ROIPooling</span></span><br><span class="line">        res = res.view(res.shape[<span class="number">0</span>], -<span class="number">1</span>) <span class="comment"># 将ROIPooling的结果展平</span></span><br><span class="line">        features = self.output(res) <span class="comment"># 对展平的结果进行分类</span></span><br><span class="line">        prob = self.prob(features) <span class="comment"># 计算每个类别的概率</span></span><br><span class="line">        loc = self.loc(features).view(-<span class="number">1</span>, self.num_classes+<span class="number">1</span>, <span class="number">4</span>) <span class="comment"># 计算每个类别的边界框位置</span></span><br><span class="line">        <span class="comment"># 输出的张量的形状就变成了(N, num_classes + 1, 4)，其中N是批次大小，num_classes + 1是类别数量（包括背景类别），4是边界框的参数数量。</span></span><br><span class="line">        <span class="comment"># 相当于最终输出是==&gt;每个图像都会输出：每个类别对应的一个边界框，这个边界框由4个参数确定。</span></span><br><span class="line">        <span class="keyword">return</span> prob, loc</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, prob, bbox, label, gt_bbox, lmb=<span class="number">1.0</span></span>): <span class="comment"># 计算损失的方法，接收五个参数：预测类别概率、预测边界框、真实类别标签、真实边界框、lambda</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param prob: 预测类别</span></span><br><span class="line"><span class="string">        :param bbox:预测边界框</span></span><br><span class="line"><span class="string">        :param label:真实类别</span></span><br><span class="line"><span class="string">        :param gt_bbox:真实边界框</span></span><br><span class="line"><span class="string">        :param lmb:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        loss_cat = self.cat_loss(prob, label) <span class="comment"># 计算类别损失</span></span><br><span class="line">        lbl = label.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(label.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">4</span>) <span class="comment"># 将标签扩展为与边界框相同的形状 (N, 1, 4)，N：标签的数量 1：每个标签对应一个边界框 4：边界框的参数数量</span></span><br><span class="line">        mask = (label != <span class="number">0</span>).<span class="built_in">float</span>().view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(label.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">4</span>) <span class="comment"># 将标签扩展为与边界框相同的形状</span></span><br><span class="line">        loss_loc = self.loc_loss(gt_bbox * mask, bbox.gather(<span class="number">1</span>, lbl).squeeze(<span class="number">1</span>) * mask) <span class="comment"># 计算位置损失</span></span><br><span class="line">        loss = loss_cat + lmb * loss_loc <span class="comment"># 计算总损失</span></span><br><span class="line">        <span class="keyword">return</span> loss, loss_cat, loss_loc <span class="comment"># 返回总损失、类别损失和位置损失</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="训练网络模型">训练网络模型</h4>
<p><strong>train.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse <span class="comment"># 导入argparse模块，用于处理命令行参数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> dataset <span class="keyword">import</span> COCOdataset</span><br><span class="line"><span class="keyword">from</span> fast_rcnn <span class="keyword">import</span> FastRCNN</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练函数，输入参数为模型、训练数据集、优化器和命令行参数</span></span><br><span class="line"><span class="comment"># 训练时要用gpu，记得把参数--cuda的默认值改为True</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, train_dataset, optimizer, args</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    num_batches = <span class="built_in">len</span>(train_dataset) // args.batch_size  <span class="comment"># 计算批次数量</span></span><br><span class="line">    indexes = np.random.shuffle(np.arange(<span class="built_in">len</span>(train_dataset))) <span class="comment"># 随机打乱数据集的索引</span></span><br><span class="line">    <span class="comment"># 初始化损失和准确率</span></span><br><span class="line">    loss_all = <span class="number">0</span></span><br><span class="line">    loss_cat_all = <span class="number">0</span></span><br><span class="line">    loss_loc_all = <span class="number">0</span></span><br><span class="line">    accuracy = <span class="number">0</span></span><br><span class="line">    num_samples = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历每个批次</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_batches):</span><br><span class="line">        <span class="comment"># 初始化图像、区域、ROI索引、相对位置和类别列表</span></span><br><span class="line">        imgs = []</span><br><span class="line">        rects = []</span><br><span class="line">        roi_idxs = []</span><br><span class="line">        rela_locs = []</span><br><span class="line">        cats = []</span><br><span class="line">        <span class="comment"># 遍历每个样本</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(args.batch_size):</span><br><span class="line">            <span class="comment"># img:原始图像; rect:建议框体;roi_idx_len:正负样本框体总数;rela_loc:调整后框体;cat:类别</span></span><br><span class="line">            img, rect, roi_idx_len, rela_loc, cat = train_dataset[i *</span><br><span class="line">                                                                 args.batch_size+j]</span><br><span class="line">            <span class="comment"># print(img, rect, roi_idx_len, gt_rect, cat)</span></span><br><span class="line">            <span class="comment"># 添加到对应的列表中</span></span><br><span class="line">            imgs.append(img.unsqueeze(<span class="number">0</span>))</span><br><span class="line">            rects += rect</span><br><span class="line">            rela_locs += rela_loc</span><br><span class="line">            roi_idxs += ([j] * roi_idx_len)   <span class="comment"># [2]*6-------&gt;[2, 2, 2, 2, 2, 2]</span></span><br><span class="line">            cats += cat</span><br><span class="line">        <span class="comment"># 将列表转换为张量或数组</span></span><br><span class="line">        imgs = torch.cat(imgs, dim=<span class="number">0</span>)</span><br><span class="line">        rects = np.array(rects)</span><br><span class="line">        rela_locs = torch.FloatTensor(rela_locs)</span><br><span class="line">        cats = torch.LongTensor(cats)</span><br><span class="line">        <span class="comment"># print(imgs, rects, roi_idxs, rela_locs, cats)</span></span><br><span class="line">        <span class="comment"># 如果使用CUDA，则将张量移动到GPU上</span></span><br><span class="line">        <span class="keyword">if</span> args.cuda:</span><br><span class="line">            imgs = imgs.cuda()</span><br><span class="line">            rela_locs = rela_locs.cuda()</span><br><span class="line">            cats = cats.cuda()</span><br><span class="line">        <span class="comment"># 清空梯度</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 前向传播，计算预测的概率和边界框</span></span><br><span class="line">        prob, bbox = model.forward(imgs, rects, roi_idxs)</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss, loss_cat, loss_loc = model.loss(prob, bbox, cats, rela_locs)</span><br><span class="line">        <span class="comment"># 反向传播，计算梯度</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 更新参数</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># 更新损失和准确率</span></span><br><span class="line">        num_samples += <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_all += loss.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_cat_all += loss_cat.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_loc_all += loss_loc.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        accuracy += (torch.argmax(prob.detach(), dim=-<span class="number">1</span>) == cats).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="comment"># 返回模型、损失和准确率</span></span><br><span class="line">    <span class="keyword">return</span> model, loss_all/num_samples, loss_cat_all/num_samples, loss_loc_all/num_samples, accuracy/num_samples</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义测试函数，输入参数为模型、验证数据集和命令行参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">model, val_dataset, args</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    num_batches = <span class="built_in">len</span>(val_dataset) // args.batch_size <span class="comment"># 计算批次数量</span></span><br><span class="line">    indexes = np.random.shuffle(np.arange(<span class="built_in">len</span>(val_dataset))) <span class="comment"># 随机打乱数据集的索引</span></span><br><span class="line">    <span class="comment"># 初始化损失和准确率</span></span><br><span class="line">    loss_all = <span class="number">0</span></span><br><span class="line">    loss_cat_all = <span class="number">0</span></span><br><span class="line">    loss_loc_all = <span class="number">0</span></span><br><span class="line">    accuracy = <span class="number">0</span></span><br><span class="line">    num_samples = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历每个批次</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_batches):</span><br><span class="line">        <span class="comment"># 初始化图像、区域、ROI索引、相对位置和类别列表</span></span><br><span class="line">        imgs = []</span><br><span class="line">        rects = []</span><br><span class="line">        roi_idxs = []</span><br><span class="line">        rela_locs = []</span><br><span class="line">        cats = []</span><br><span class="line">        <span class="comment"># 遍历每个样本</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(args.batch_size):</span><br><span class="line">            <span class="comment"># 加载图像、区域、ROI索引长度、相对位置和类别</span></span><br><span class="line">            img, rect, roi_idx_len, rela_loc, cat = val_dataset[i *</span><br><span class="line">                                                               args.batch_size+j]</span><br><span class="line">            <span class="comment"># print(img, rect, roi_idx_len, gt_rect, cat)</span></span><br><span class="line">            <span class="comment"># 添加到对应的列表中</span></span><br><span class="line">            imgs.append(img.unsqueeze(<span class="number">0</span>))</span><br><span class="line">            rects += rect</span><br><span class="line">            rela_locs += rela_loc</span><br><span class="line">            roi_idxs += ([j] * roi_idx_len)</span><br><span class="line">            cats += cat</span><br><span class="line">        <span class="comment"># 将列表转换为张量或数组</span></span><br><span class="line">        imgs = torch.cat(imgs, dim=<span class="number">0</span>)</span><br><span class="line">        rects = np.array(rects)</span><br><span class="line">        rela_locs = torch.FloatTensor(rela_locs)</span><br><span class="line">        cats = torch.LongTensor(cats)</span><br><span class="line">        <span class="comment"># print(imgs, rects, roi_idxs, rela_locs, cats)</span></span><br><span class="line">        <span class="comment"># 如果使用CUDA，则将张量移动到GPU</span></span><br><span class="line">        <span class="keyword">if</span> args.cuda:</span><br><span class="line">            imgs = imgs.cuda()</span><br><span class="line">            rela_locs = rela_locs.cuda()</span><br><span class="line">            cats = cats.cuda()</span><br><span class="line">        <span class="comment"># 前向传播，计算预测的概率和边界框</span></span><br><span class="line">        prob, bbox = model.forward(imgs, rects, roi_idxs)</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss, loss_cat, loss_loc = model.loss(prob, bbox, cats, rela_locs)</span><br><span class="line">        <span class="comment"># 更新损失和准确率</span></span><br><span class="line">        num_samples += <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_all += loss.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_cat_all += loss_cat.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_loc_all += loss_loc.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        accuracy += (torch.argmax(prob.detach(), dim=-<span class="number">1</span>) == cats).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="comment"># 返回模型、损失和准确率</span></span><br><span class="line">    <span class="keyword">return</span> model, loss_all/num_samples, loss_cat_all/num_samples, loss_loc_all/num_samples, accuracy/num_samples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(<span class="string">&#x27;parser for fast-rcnn&#x27;</span>) <span class="comment"># 创建一个命令行参数解析器</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">16</span>) <span class="comment"># 添加一个命令行参数--batch_size，用于指定批次大小，默认值为16</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>) <span class="comment"># 添加一个命令行参数--num_classes，用于指定类别数量，默认值为10</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--learning_rate&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">2e-4</span>) <span class="comment"># 添加一个命令行参数--learning_rate，用于指定学习率，默认值为2e-4</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">20</span>) <span class="comment"># 添加一个命令行参数--epochs，用于指定训练的轮数，默认值为20</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save_path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&#x27;./model/fast_rcnn.pkl&#x27;</span>) <span class="comment"># 添加一个命令行参数--save_path，用于指定模型保存的路径，默认值为&#x27;./model/fast_rcnn.pkl&#x27;</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cuda&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args() <span class="comment"># 解析命令行参数，并将结果保存在args中</span></span><br><span class="line">    train_dataset = COCOdataset(mode=<span class="string">&#x27;train&#x27;</span>) <span class="comment"># 解析命令行参数，并将结果保存在args中</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-----------------&quot;</span>,train_dataset.__len__())</span><br><span class="line">    valid_dataset = COCOdataset(mode=<span class="string">&#x27;val&#x27;</span>) <span class="comment"># 创建一个COCOdataset实例，模式为&#x27;val&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-----------------&quot;</span>, valid_dataset.__len__())</span><br><span class="line">    model = FastRCNN(num_classes=args.num_classes) <span class="comment"># 创建一个FastRCNN模型实例，类别数量为args.num_classes</span></span><br><span class="line">    <span class="keyword">if</span> args.cuda:<span class="comment"># 如果args.cuda为True，则将模型移动到GPU上</span></span><br><span class="line">        model.cuda()</span><br><span class="line">    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate) <span class="comment"># 创建一个Adam优化器，优化目标为模型的参数，学习率为args.learning_rate</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):<span class="comment"># 对于每一个训练轮次</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch %d:&quot;</span> % epoch)<span class="comment"># 打印当前轮次</span></span><br><span class="line">        model, train_loss, train_loss_cat, train_loss_loc, train_accuracy = train(</span><br><span class="line">            model, train_dataset, optimizer, args) <span class="comment"># 调用train函数进行训练，并获取模型、总损失、类别损失、位置损失和准确率</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Train: loss=%.4f, loss_cat=%.4f, loss_loc=%.4f, accuracy=%.4f&quot;</span> %</span><br><span class="line">              (train_loss, train_loss_cat, train_loss_loc, train_accuracy))<span class="comment"># 打印训练的损失和准确率</span></span><br><span class="line">        model, valid_loss, valid_loss_cat, valid_loss_loc, valid_accuracy = test(</span><br><span class="line">            model, valid_dataset, args)<span class="comment"># 打印训练的损失和准确率</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Valid: loss=%.4f, loss_cat=%.4f, loss_loc=%.4f, accuracy=%.4f&quot;</span> %</span><br><span class="line">              (valid_loss, valid_loss_cat, valid_loss_loc, valid_accuracy))<span class="comment"># 打印验证的损失和准确率</span></span><br><span class="line"></span><br><span class="line">    torch.save(model.state_dict(), args.save_path) <span class="comment"># 将模型的状态字典保存到args.save_path指定的路径</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main() <span class="comment"># 如果当前脚本被直接运行，则调用main函数</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h4 id="测试">测试</h4>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> skimage</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw, ImageFont</span><br><span class="line"><span class="keyword">from</span> selectivesearch <span class="keyword">import</span> selective_search <span class="comment"># 从selectivesearch模块导入selective_search函数，用于进行选择性搜索</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fast_rcnn <span class="keyword">import</span> FastRCNN</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试时如果用gpu，则：</span></span><br><span class="line"><span class="comment"># 1. 将模型加载到gpu上：trained_net = torch.load(args.model)，不加 map_location = &#x27;cpu&#x27;</span></span><br><span class="line"><span class="comment"># 2. 把参数--cuda的默认值改为True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义计算IoU（交并比）的函数，输入参数为两个矩形框</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_iou</span>(<span class="params">a, b</span>):</span><br><span class="line">    a_min_x, a_min_y, a_max_x, a_max_y = a</span><br><span class="line">    b_min_x, b_min_y, b_max_x, b_max_y = b</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">min</span>(a_max_y, b_max_y) &lt; <span class="built_in">max</span>(a_min_y, b_min_y) <span class="keyword">or</span> <span class="built_in">min</span>(a_max_x, b_max_x) &lt; <span class="built_in">max</span>(a_min_x, b_min_x):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        intersect_area = (<span class="built_in">min</span>(a_max_y, b_max_y) - <span class="built_in">max</span>(a_min_y, b_min_y) + <span class="number">1</span>) * \</span><br><span class="line">            (<span class="built_in">min</span>(a_max_x, b_max_x) - <span class="built_in">max</span>(a_min_x, b_min_x) + <span class="number">1</span>)</span><br><span class="line">        union_area = (a_max_x - a_min_x + <span class="number">1</span>) * (a_max_y - a_min_y + <span class="number">1</span>) + \</span><br><span class="line">            (b_max_x - b_min_x + <span class="number">1</span>) * (b_max_y - b_min_y + <span class="number">1</span>) - intersect_area</span><br><span class="line">    <span class="keyword">return</span> intersect_area / union_area</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(<span class="string">&#x27;parser for testing fast-rcnn&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--jpg_path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&#x27;D:\\WritePapers\\object_detection_basics\\Datasets\\COCO2017\\val2017\\000000241326.jpg&#x27;</span>)<span class="comment"># 添加一个命令行参数--jpg_path，用于指定待测试的图像的路径，默认值为&#x27;/devdata/project/ai_learn/COCO2017/val2017/000000241326.jpg&#x27;</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save_path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;sample.png&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save_type&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;png&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--model&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./model/fast_rcnn.pkl&#x27;</span>) <span class="comment"># 添加一个命令行参数--model，用于指定模型的路径，默认值为&#x27;./model/fast_rcnn.pkl&#x27;</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--scale&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">30.0</span>) <span class="comment"># 添加一个命令行参数--scale，用于指定选择性搜索的尺度，默认值为30.0</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--sigma&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.8</span>) <span class="comment"># 添加一个命令行参数--sigma，用于指定选择性搜索的高斯平滑参数，默认值为0.8</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--min_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">50</span>) <span class="comment"># 添加一个命令行参数--min_size，用于指定选择性搜索的最小区域大小，默认值为50</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cats&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, nargs=<span class="string">&#x27;*&#x27;</span>, default=[</span><br><span class="line">                        <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>, <span class="string">&#x27;elephant&#x27;</span>, <span class="string">&#x27;bear&#x27;</span>, <span class="string">&#x27;zebra&#x27;</span>, <span class="string">&#x27;giraffe&#x27;</span>]) <span class="comment"># 添加一个命令行参数--cats，用于指定需要处理的类别，默认值为一系列动物的名称</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cuda&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">False</span>)</span><br><span class="line">    args = parser.parse_args() <span class="comment"># 解析命令行参数，并将结果保存在args中</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># trained_net = torch.load(args.model) # 加载模型</span></span><br><span class="line">    trained_net = torch.load(args.model, map_location = <span class="string">&#x27;cpu&#x27;</span>) <span class="comment"># 加载模型</span></span><br><span class="line"></span><br><span class="line">    model = FastRCNN(num_classes=args.num_classes) <span class="comment"># 创建一个FastRCNN模型实例，类别数量为args.num_classes</span></span><br><span class="line">    model.load_state_dict(trained_net) <span class="comment"># 将加载的模型的状态字典加载到FastRCNN模型实例中</span></span><br><span class="line">    <span class="keyword">if</span> args.cuda: <span class="comment"># 如果args.cuda为True，则将模型移动到GPU上</span></span><br><span class="line">        model.cuda()</span><br><span class="line"></span><br><span class="line">    img = skimage.io.imread(args.jpg_path) <span class="comment"># 读取图像</span></span><br><span class="line">    h = img.shape[<span class="number">0</span>] <span class="comment"># 获取图像的高度</span></span><br><span class="line">    w = img.shape[<span class="number">1</span>] <span class="comment"># 获取图像的宽度</span></span><br><span class="line">    _, ss_regions = selective_search(</span><br><span class="line">        img, args.scale, args.sigma, args.min_size) <span class="comment"># 对图像进行选择性搜索，获取候选区域</span></span><br><span class="line">    rois = []</span><br><span class="line">    <span class="keyword">for</span> region <span class="keyword">in</span> ss_regions: <span class="comment"># 遍历每个候选区域</span></span><br><span class="line">        rect = <span class="built_in">list</span>(region[<span class="string">&#x27;rect&#x27;</span>]) <span class="comment"># 获取候选区域的矩形框</span></span><br><span class="line">        rect[<span class="number">0</span>] = rect[<span class="number">0</span>] / w <span class="comment"># 将矩形框的x坐标转换为相对于图像宽度的比例</span></span><br><span class="line">        rect[<span class="number">1</span>] = rect[<span class="number">1</span>] / h <span class="comment"># 将矩形框的y坐标转换为相对于图像高度的比例</span></span><br><span class="line">        rect[<span class="number">2</span>] = rect[<span class="number">0</span>] + rect[<span class="number">2</span>] / w <span class="comment"># 将矩形框的宽度转换为相对于图像宽度的比例</span></span><br><span class="line">        rect[<span class="number">3</span>] = rect[<span class="number">1</span>] + rect[<span class="number">3</span>] / h <span class="comment"># 将矩形框的高度转换为相对于图像高度的比例</span></span><br><span class="line">        rois.append(rect) <span class="comment"># 将处理后的矩形框添加到列表中</span></span><br><span class="line">    img = Image.fromarray(img) <span class="comment"># 将图像数组转换为PIL图像</span></span><br><span class="line">    img_tensor = img.resize([<span class="number">224</span>, <span class="number">224</span>]) <span class="comment"># 将图像大小调整为224x224</span></span><br><span class="line">    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([</span><br><span class="line">                                   <span class="number">0.485</span>, <span class="number">0.456</span>, -<span class="number">.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])]) <span class="comment"># 创建一个图像预处理管道，包括将PIL图像转换为张量和标准化</span></span><br><span class="line">    img_tensor = transform(img_tensor).unsqueeze(<span class="number">0</span>) <span class="comment"># 对图像进行预处理，并添加一个新的维度</span></span><br><span class="line">    <span class="keyword">if</span> args.cuda: <span class="comment"># 如果args.cuda为True，则将图像张量移动到GPU</span></span><br><span class="line">        img_tensor = img_tensor.cuda()</span><br><span class="line">    rois = np.array(rois) <span class="comment"># 将候选区域的列表转换为数组</span></span><br><span class="line">    roi_idx = [<span class="number">0</span>] * rois.shape[<span class="number">0</span>] <span class="comment"># 创建一个列表，长度为候选区域的数量，所有元素都为0</span></span><br><span class="line"></span><br><span class="line">    prob, rela_loc = model.forward(img_tensor, rois, roi_idx) <span class="comment"># 前向传播，计算预测的概率和边界框</span></span><br><span class="line">    prob = torch.nn.Softmax(dim=-<span class="number">1</span>)(prob).cpu().detach().numpy() <span class="comment"># 对预测的概率进行softmax操作，并将结果转换为numpy数组</span></span><br><span class="line">    <span class="comment"># rela_loc = rela_loc.cpu().detach().numpy()[:, 1:, :].mean(axis=1)</span></span><br><span class="line">    labels = []</span><br><span class="line">    max_probs = []</span><br><span class="line">    bboxs = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(prob)): <span class="comment"># 遍历每个预测的概率</span></span><br><span class="line">        <span class="keyword">if</span> prob[i].<span class="built_in">max</span>() &gt; <span class="number">0.8</span> <span class="keyword">and</span> np.argmax(prob[i], axis=<span class="number">0</span>) != <span class="number">0</span>: <span class="comment"># 如果最大概率大于0.8且对应的类别不是背景，则认为候选区域是有效的</span></span><br><span class="line">            <span class="comment"># proposal regions is directly used because of limited training epochs, bboxs predicted are not precise</span></span><br><span class="line">            <span class="comment"># bbox = [(rois[i][2] - rois[i][0]) * rela_loc[i][0] + 0.5 * (rois[i][2] + rois[i][0]),</span></span><br><span class="line">            <span class="comment">#         (rois[i][3] - rois[i][1]) * rela_loc[i][1] + 0.5 * (rois[i][3] + rois[i][1]),</span></span><br><span class="line">            <span class="comment">#         np.exp(rela_loc[i][2]) * rois[i][2],</span></span><br><span class="line">            <span class="comment">#         np.exp(rela_loc[i][3]) * rois[i][3]]</span></span><br><span class="line">            <span class="comment"># bbox = [bbox[0] - 0.5 * bbox[2],</span></span><br><span class="line">            <span class="comment">#         bbox[1] - 0.5 * bbox[3],</span></span><br><span class="line">            <span class="comment">#         bbox[0] + 0.5 * bbox[2],</span></span><br><span class="line">            <span class="comment">#         bbox[1] + 0.5 * bbox[3]]</span></span><br><span class="line">            labels.append(np.argmax(prob[i], axis=<span class="number">0</span>))  <span class="comment"># 将有效候选区域的类别添加到列表中</span></span><br><span class="line">            max_probs.append(prob[i].<span class="built_in">max</span>()) <span class="comment"># 将有效候选区域的最大概率添加到列表中</span></span><br><span class="line">            rois[i] = [<span class="built_in">int</span>(w * rois[i][<span class="number">0</span>]), <span class="built_in">int</span>(h * rois[i][<span class="number">1</span>]),</span><br><span class="line">                       <span class="built_in">int</span>(w * rois[i][<span class="number">2</span>]), <span class="built_in">int</span>(w * rois[i][<span class="number">3</span>])] <span class="comment"># 将候选区域的矩形框的坐标和大小转换为相对于原图的像素值</span></span><br><span class="line">            bboxs.append(rois[i]) <span class="comment"># 将处理后的矩形框添加到列表中</span></span><br><span class="line">    labels = np.array(labels) <span class="comment"># 将类别的列表转换为数组</span></span><br><span class="line">    max_probs = np.array(max_probs) <span class="comment"># 将最大概率的列表转换为数组</span></span><br><span class="line">    bboxs = np.array(bboxs) <span class="comment"># 将矩形框的列表转换为数组</span></span><br><span class="line">    order = np.argsort(-max_probs) <span class="comment"># 对最大概率进行降序排序，获取排序后的索引</span></span><br><span class="line">    labels = labels[order] <span class="comment"># 根据排序的索引重新排序类别</span></span><br><span class="line">    max_probs = max_probs[order]</span><br><span class="line">    bboxs = bboxs[order]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 下面的代码是进行非极大值抑制（NMS），用于去除重叠的候选区域</span></span><br><span class="line">    nms_labels = []</span><br><span class="line">    nms_probs = []</span><br><span class="line">    nms_bboxs = []</span><br><span class="line">    del_indexes = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels)):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> del_indexes:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels)):</span><br><span class="line">                <span class="keyword">if</span> j <span class="keyword">not</span> <span class="keyword">in</span> del_indexes <span class="keyword">and</span> cal_iou(bboxs[i], bboxs[j]) &gt; <span class="number">0.3</span>:</span><br><span class="line">                    del_indexes.append(j)</span><br><span class="line">            nms_labels.append(labels[i])</span><br><span class="line">            nms_probs.append(max_probs[i])</span><br><span class="line">            nms_bboxs.append(bboxs[i])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将预测结果绘制到图像上</span></span><br><span class="line">    cat_dict = &#123;(i + <span class="number">1</span>): args.cats[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(args.cats))&#125;</span><br><span class="line">    cat_dict[<span class="number">0</span>] = <span class="string">&#x27;background&#x27;</span></span><br><span class="line">    font = ImageFont.truetype(<span class="string">&#x27;./fonts/chinese_cht.ttf&#x27;</span>, size=<span class="number">16</span>)</span><br><span class="line">    draw = ImageDraw.Draw(img)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nms_labels)):</span><br><span class="line">        draw.polygon([(nms_bboxs[i][<span class="number">0</span>], nms_bboxs[i][<span class="number">1</span>]), (nms_bboxs[i][<span class="number">2</span>], nms_bboxs[i][<span class="number">1</span>]),</span><br><span class="line">                      (nms_bboxs[i][<span class="number">2</span>], nms_bboxs[i][<span class="number">3</span>]), (nms_bboxs[i][<span class="number">0</span>], nms_bboxs[i][<span class="number">3</span>])], outline=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">        draw.text((nms_bboxs[i][<span class="number">0</span>] + <span class="number">5</span>, nms_bboxs[i][<span class="number">1</span>] + <span class="number">5</span>), <span class="string">&#x27;%s %.2f%%&#x27;</span> % (</span><br><span class="line">            cat_dict[nms_labels[i]], <span class="number">100</span> * max_probs[i]), fill=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), font=font)</span><br><span class="line">    img.save(args.save_path, args.save_type) <span class="comment"># 将绘制了预测结果的图像保存到指定的路径</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>测试结果如下： <img src="https://ooo.0x0.ooo/2023/12/29/OKYvBc.png"
alt="OKYvBc.png" /></p>
<p>参考资料</p>
<blockquote>
<p>1.博客：<a
href="https://blog.csdn.net/guoqingru0311/article/details/129584426">目标检测
pytorch复现Fast_RCNN目标检测项目-CSDN博客</a></p>
<p>2.COCO数据集下载：</p>
<p>``` 训练集： http://images.cocodataset.org/zips/train2017.zip
验证集： http://images.cocodataset.org/zips/val2017.zip
训练集和验证集对应的标签：
http://images.cocodataset.org/annotations/annotations_trainval2017.zip
测试集： http://images.cocodataset.org/zips/test2017.zip</p>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>Fast RCNN</tag>
        <tag>代码复现</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster RCNN代码分析（二）</title>
    <url>/2023/12/29/Faster-RCNN%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="fasterrcnn代码分析">FasterRCNN代码分析</h1>
<p><strong>项目源码</strong>：https://github.com/chenyuntc/simple-faster-rcnn-pytorch</p>
<p><strong>对源码增加注释后的代码（代码2）：</strong></p>
<p><code>simple-faster-rcnn-pytorch-master</code>
https://www.alipan.com/s/faJGPR261aG 提取码: ry92
点击链接保存，或者复制本段内容，打开「阿里云盘」APP
，无需下载极速在线查看，视频原画倍速播放。
<strong>代码2</strong>只要将VOCdevkit数据集放到dataset目录下即可运行</p>
<p>这个项目是一个基于Faster
R-CNN模型的目标检测项目，主要包含以下几个部分：</p>
<span id="more"></span>
<ol type="1">
<li><p><code>utils/config.py</code>：这个文件包含了项目的配置选项，例如数据集路径、学习率、优化器类型、预训练模型的路径等。</p></li>
<li><p><code>data/dataset.py</code>：这个文件包含了处理PASCAL
VOC数据集的类，例如<code>Dataset</code>、<code>TestDataset</code>。这些类用于加载数据集（这里会调用<code>data/voc_dataset.py</code>中的<code>VOCBboxDataset</code>），对图像和标签进行预处理，并提供了用于训练和测试模型的接口。</p></li>
<li><p><code>model/faster_rcnn.py</code>：这个文件包含了Faster
R-CNN模型的实现。这个模型由三个主要部分组成：特征提取器、RPN网络和头部网络。特征提取器用于从图像中提取特征，RPN网络用于生成目标的候选区域，头部网络用于在这些候选区域上进行分类和回归。</p></li>
<li><p><code>model/faster_rcnn_vgg16.py</code>：这个文件包含了基于VGG-16的Faster
R-CNN模型<code>FasterRCNNVGG16</code>（继承了<code>model/faster_rcnn.py</code>中的<code>FasterRCNN</code>）。这个模型由三个主要部分组成：基于VGG-16的特征提取器、RPN网络和<code>VGG16RoIHead</code>头部网络。特征提取器用于从图像中提取特征，RPN网络用于生成目标的候选区域，头部网络用于在这些候选区域上进行分类和回归。</p></li>
<li><p><code>model/region_proposal_network.py</code>：这个文件包含了Region
Proposal Network（RPN）的实现。RPN是Faster
R-CNN模型的一个关键组件，它用于生成目标的候选区域。</p></li>
<li><p><code>model/utils/creator_tool.py</code>：这个文件包含了一些用于生成训练Faster
R-CNN模型所需的目标的工具类，例如<code>AnchorTargetCreator</code>和<code>ProposalTargetCreator</code>。</p></li>
<li><p><code>trainer.py</code>：这个文件包含了一个用于训练Faster
R-CNN模型的类<code>FasterRCNNTrainer</code>。这个类提供了一些方法，例如<code>train_step</code>用于执行一步训练，<code>save</code>和<code>load</code>用于保存和加载模型，<code>update_meters</code>和<code>reset_meters</code>用于更新和重置度量等。</p></li>
<li><p><code>train.py</code>：这个文件是项目的主程序，它首先加载数据集，然后创建Faster
R-CNN模型和训练器，接着进入一个循环，每个循环代表一个训练周期，在每个训练周期中，它会遍历数据集中的所有图像，并使用训练器的<code>train_step</code>方法来更新模型的参数。</p></li>
</ol>
<p>这些文件之间的关系主要是通过数据和模型的流动来实现的。首先，<code>train.py</code>会加载<code>dataset.py</code>中的数据集，然后使用<code>model/faster_rcnn.py</code>中的模型对数据进行处理，接着使用<code>trainer.py</code>中的训练器对模型进行训练。在训练过程中，<code>model/utils/creator_tool.py</code>中的工具类会被用来生成训练所需的目标，<code>model/region_proposal_network.py</code>中的RPN会被用来生成目标的候选区域。</p>
<p>1.<code>train.py</code></p>
<p>在<code>main</code>函数中调用<code>train()</code>方法，<code>train()</code>方法的主要步骤为：</p>
<p>（1）加载数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset = Dataset(opt)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;load data&#x27;</span>)</span><br><span class="line">dataloader = data_.DataLoader(dataset, \</span><br><span class="line">                              batch_size=<span class="number">1</span>, \</span><br><span class="line">                              shuffle=<span class="literal">True</span>, \</span><br><span class="line">                              <span class="comment"># pin_memory=True,</span></span><br><span class="line">                              num_workers=opt.num_workers)</span><br><span class="line">testset = TestDataset(opt)</span><br><span class="line">test_dataloader = data_.DataLoader(testset,</span><br><span class="line">                                   batch_size=<span class="number">1</span>,</span><br><span class="line">                                   num_workers=opt.test_num_workers,</span><br><span class="line">                                   shuffle=<span class="literal">False</span>, \</span><br><span class="line">                                   pin_memory=<span class="literal">True</span></span><br><span class="line">                                  )</span><br></pre></td></tr></table></figure>
<p>（2）创建Faster RCNN模型及其训练器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">faster_rcnn = FasterRCNNVGG16()<span class="comment"># 创建Faster R-CNN模型对象</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;model construct completed&#x27;</span>)</span><br><span class="line">trainer = FasterRCNNTrainer(faster_rcnn).cuda() <span class="comment"># 创建Faster R-CNN模型的训练器</span></span><br><span class="line"><span class="keyword">if</span> opt.load_path:<span class="comment"># 如果指定了预训练模型的路径</span></span><br><span class="line">   trainer.load(opt.load_path)<span class="comment"># 加载预训练模型</span></span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;load pretrained model from %s&#x27;</span> % opt.load_path)</span><br></pre></td></tr></table></figure>
<p>（3）开启训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">best_map = <span class="number">0</span> <span class="comment"># 初始化最佳mAP为0</span></span><br><span class="line">lr_ = opt.lr <span class="comment"># 获取初始学习率 lr=0.001</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(opt.epoch):</span><br><span class="line">   trainer.reset_meters() <span class="comment"># 重置训练器的度量计数器</span></span><br><span class="line">   <span class="keyword">for</span> ii, (img, bbox_, label_, scale) <span class="keyword">in</span> tqdm(<span class="built_in">enumerate</span>(dataloader)): <span class="comment"># 对数据加载器中的每个batch进行循环 ii为批次索引 img==tensor(1,3,800,600) bbox_==tensor(1,1,4) label_==tensor(1,1) scale==(1,)</span></span><br><span class="line">        scale = at.scalar(scale) <span class="comment"># 获取缩放因子</span></span><br><span class="line">        img, bbox, label = img.cuda().<span class="built_in">float</span>(), bbox_.cuda(), label_.cuda() <span class="comment"># 将图像、边界框（ground_truth）和标签移动到GPU上，并将图像转换为浮点类型</span></span><br><span class="line">        trainer.train_step(img, bbox, label, scale) <span class="comment"># 执行一个训练步骤</span></span><br></pre></td></tr></table></figure>
<p>（4）评估训练结果并在visdom中可视化展示</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">eval_result = <span class="built_in">eval</span>(test_dataloader, faster_rcnn, test_num=opt.test_num)<span class="comment"># 对测试数据集进行评估</span></span><br><span class="line">trainer.vis.plot(<span class="string">&#x27;test_map&#x27;</span>, eval_result[<span class="string">&#x27;map&#x27;</span>])<span class="comment"># 在visdom中绘制mAP</span></span><br><span class="line">lr_ = trainer.faster_rcnn.optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]<span class="comment"># 获取当前的学习率</span></span><br><span class="line">log_info = <span class="string">&#x27;lr:&#123;&#125;, map:&#123;&#125;,loss:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(lr_),</span><br><span class="line">                                          <span class="built_in">str</span>(eval_result[<span class="string">&#x27;map&#x27;</span>]),</span><br><span class="line">                                          <span class="built_in">str</span>(trainer.get_meter_data()))<span class="comment"># 生成日志信息</span></span><br><span class="line">trainer.vis.log(log_info)<span class="comment"># 在visdom中显示日志信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> eval_result[<span class="string">&#x27;map&#x27;</span>] &gt; best_map:<span class="comment"># 如果当前的mAP大于最佳mAP</span></span><br><span class="line">    best_map = eval_result[<span class="string">&#x27;map&#x27;</span>]<span class="comment"># 更新最佳mAP</span></span><br><span class="line">    best_path = trainer.save(best_map=best_map)<span class="comment"># 保存当前的模型，并获取保存路径</span></span><br><span class="line">    <span class="keyword">if</span> epoch == <span class="number">9</span>:<span class="comment"># 如果当前是第10个训练周期</span></span><br><span class="line">        trainer.load(best_path)<span class="comment"># 加载最佳模型</span></span><br><span class="line">        trainer.faster_rcnn.scale_lr(opt.lr_decay)<span class="comment"># 调整学习率</span></span><br><span class="line">        lr_ = lr_ * opt.lr_decay <span class="comment"># 更新当前的学习率</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch == <span class="number">13</span>: <span class="comment"># 如果当前是第14个训练周期</span></span><br><span class="line">            <span class="keyword">break</span><span class="comment"># 结束训练</span></span><br></pre></td></tr></table></figure>
<p>2.<code>trainer.py</code></p>
<p>在<code>train.py</code>的<code>train()</code>开启训练后，<code>trainer.train_step(img, bbox, label, scale)</code>
会执行一个训练步骤，即进入<code>trainer.py</code>的<code>train_step()</code>方法，进而通过内部的<code>losses = self.forward(imgs, bboxes, labels, scale)</code>进行前向传播，前向传播的主要步骤为：</p>
<p>（1）使用<code>Faster R-CNN</code>的特征提取器提取特征</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">features = self.faster_rcnn.extractor(imgs)  <span class="comment"># 使用Faster R-CNN的特征提取器提取特征</span></span><br></pre></td></tr></table></figure>
<p>（2）使用RPN生成RoIs(初步筛选后得到每张图片约2000个RoI)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># RPN</span></span><br><span class="line"><span class="comment"># rpn_locs代表所有偏移锚框的位置，形状为(1, hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># rpn_scores代表所有偏移锚框的得分下，形状为(1, hh*ww*9, 2)</span></span><br><span class="line"><span class="comment"># rois代表所有的RoIs(感兴趣区域)，形状约为(2000, 4)</span></span><br><span class="line"><span class="comment"># roi_indices代表RoIs对应的图像索引，形状约为(2000, ) 表明rois中的每个RoI都对应于哪张图片（这里batch=1，每次都来自第0张图片）</span></span><br><span class="line">rpn_locs, rpn_scores, rois, roi_indices, anchor = \</span><br><span class="line">	self.faster_rcnn.rpn(features, img_size, scale) <span class="comment"># 使用RPN生成RoIs</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RegionProposalNetwork</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self, in_channels=<span class="number">512</span>, mid_channels=<span class="number">512</span>, ratios=[<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>],</span></span><br><span class="line"><span class="params">            anchor_scales=[<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>], feat_stride=<span class="number">16</span>,</span></span><br><span class="line"><span class="params">            proposal_creator_params=<span class="built_in">dict</span>(<span class="params"></span>),</span></span><br><span class="line"><span class="params">    </span>):  <span class="comment"># 初始化方法，接受输入通道数、中间通道数、长宽比、锚框尺度、特征步长和proposal创建器参数作为参数</span></span><br><span class="line">        <span class="built_in">super</span>(RegionProposalNetwork, self).__init__()</span><br><span class="line">        self.anchor_base = generate_anchor_base(</span><br><span class="line">            anchor_scales=anchor_scales, ratios=ratios)<span class="comment"># 生成基础参考框anchor_base==&gt;shape(9,4)</span></span><br><span class="line">        self.feat_stride = feat_stride <span class="comment"># 设置特征步长</span></span><br><span class="line">        self.proposal_layer = ProposalCreator(self, **proposal_creator_params)  <span class="comment"># 创建proposal创建器</span></span><br><span class="line">        n_anchor = self.anchor_base.shape[<span class="number">0</span>]  <span class="comment"># 获取锚框数量 n_anchor ==&gt; 9</span></span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, mid_channels, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>) <span class="comment"># 创建一个卷积层，用于特征提取 ==&gt; shape(512,512,3,1,1) kernel_size=(3,3), stride=(1,1), padding=(1,1)</span></span><br><span class="line">        self.score = nn.Conv2d(mid_channels, n_anchor * <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>) <span class="comment"># 创建一个卷积层，用于计算锚框的得分 ==&gt; shape(512,9*2,1,1,0)</span></span><br><span class="line">        self.loc = nn.Conv2d(mid_channels, n_anchor * <span class="number">4</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>) <span class="comment"># 创建一个卷积层，用于计算锚框的位置 ==&gt; shape(512,9*4,1,1,0)</span></span><br><span class="line">        normal_init(self.conv1, <span class="number">0</span>, <span class="number">0.01</span>) <span class="comment"># 初始化conv1的权重</span></span><br><span class="line">        normal_init(self.score, <span class="number">0</span>, <span class="number">0.01</span>) <span class="comment"># 初始化score的权重</span></span><br><span class="line">        normal_init(self.loc, <span class="number">0</span>, <span class="number">0.01</span>) <span class="comment"># 初始化loc的权重</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, img_size, scale=<span class="number">1.</span></span>):<span class="comment"># 定义前向传播方法，接受FasterRCNN特征提取得到的(也是vgg16的)特征图features、图像尺寸和缩放因子作为参数 img_size==(800,600) scale==1</span></span><br><span class="line">      </span><br><span class="line">        n, _, hh, ww = x.shape <span class="comment"># 获取输入特征图x的形状</span></span><br><span class="line">        anchor = _enumerate_shifted_anchor(</span><br><span class="line">            np.array(self.anchor_base),</span><br><span class="line">            self.feat_stride, hh, ww) <span class="comment"># 枚举所有的偏移锚框，数量为特征图的像素数每个像素的锚框数==&gt;(hh*ww)*9</span></span><br><span class="line"></span><br><span class="line">        n_anchor = anchor.shape[<span class="number">0</span>] // (hh * ww) <span class="comment"># 计算每个像素的锚框数量</span></span><br><span class="line">        h = F.relu(self.conv1(x)) <span class="comment"># 对输入进行卷积操作并通过ReLU激活函数</span></span><br><span class="line"></span><br><span class="line">        rpn_locs = self.loc(h) <span class="comment"># 计算锚框的位置</span></span><br><span class="line">        <span class="comment"># UN<span class="doctag">NOTE:</span> check whether need contiguous</span></span><br><span class="line">        <span class="comment"># A: Yes</span></span><br><span class="line">        rpn_locs = rpn_locs.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).contiguous().view(n, -<span class="number">1</span>, <span class="number">4</span>) <span class="comment"># 调整rpn_locs的形状  rpn_locs代表所有偏移锚框的位置，形状为(1, hh*ww*9, 4)</span></span><br><span class="line">        rpn_scores = self.score(h) <span class="comment"># 计算锚框的得分 rpn_scores代表所有偏移锚框的得分</span></span><br><span class="line">        rpn_scores = rpn_scores.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).contiguous() <span class="comment"># 调整rpn_scores的形状</span></span><br><span class="line">        rpn_softmax_scores = F.softmax(rpn_scores.view(n, hh, ww, n_anchor, <span class="number">2</span>), dim=<span class="number">4</span>)  <span class="comment"># (1,hh,ww,9,2)# 对得分进行softmax操作，得到每个类别的概率  rpn_softmax_scores代表所有偏移锚框的得分，形状为(1, hh, ww, 9, 2)</span></span><br><span class="line">        rpn_fg_scores = rpn_softmax_scores[:, :, :, :, <span class="number">1</span>].contiguous()  <span class="comment"># 获取前景的得分</span></span><br><span class="line">        rpn_fg_scores = rpn_fg_scores.view(n, -<span class="number">1</span>)  <span class="comment"># 调整rpn_fg_scores的形状 rpn_fg_scores代表所有偏移锚框的前景得分，形状为(1, hh*ww*9)</span></span><br><span class="line">        rpn_scores = rpn_scores.view(n, -<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># 调整rpn_scores的形状 (1, hh*ww*9, 2)</span></span><br><span class="line"></span><br><span class="line">        rois = <span class="built_in">list</span>() <span class="comment"># 创建一个列表，用于存储RoIs</span></span><br><span class="line">        roi_indices = <span class="built_in">list</span>() <span class="comment"># 创建一个列表，用于存储RoIs的索引</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n): <span class="comment"># 对每个图像进行循环</span></span><br><span class="line">            roi = self.proposal_layer(</span><br><span class="line">                rpn_locs[i].cpu().data.numpy(),</span><br><span class="line">                rpn_fg_scores[i].cpu().data.numpy(),</span><br><span class="line">                anchor, img_size,</span><br><span class="line">                scale=scale) <span class="comment"># 使用proposal创建器生成RoIs roi==&gt;(1944,4)</span></span><br><span class="line">            batch_index = i * np.ones((<span class="built_in">len</span>(roi),), dtype=np.int32) <span class="comment"># 创建一个数组，用于存储RoIs的索引</span></span><br><span class="line">            rois.append(roi) <span class="comment"># 将RoIs添加到列表中</span></span><br><span class="line">            roi_indices.append(batch_index) <span class="comment"># 将RoIs的索引添加到列表中</span></span><br><span class="line"></span><br><span class="line">        rois = np.concatenate(rois, axis=<span class="number">0</span>) <span class="comment"># 将所有图像的RoIs合并</span></span><br><span class="line">        roi_indices = np.concatenate(roi_indices, axis=<span class="number">0</span>) <span class="comment"># 将所有图像的RoIs的索引合并</span></span><br><span class="line">        <span class="keyword">return</span> rpn_locs, rpn_scores, rois, roi_indices, anchor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用处：获取偏移后的锚框</span></span><br><span class="line"><span class="comment"># 在Faster R-CNN中，我们首先在图像中生成一系列的锚点（也称为锚框或参考框）</span></span><br><span class="line"><span class="comment"># 这些锚点通常是在不同的位置、尺度和长宽比下生成的（称为基础锚点：3*3=9——特征图的每个像素处都会有9个锚点——即下文代码中的A=9）</span></span><br><span class="line"><span class="comment"># 然后，我们会预测每个锚点需要偏移多少，才能更好地匹配到真实的目标边界框，这个偏移的过程就是所谓的偏移锚点</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为什么需要偏移?</span></span><br><span class="line"><span class="comment"># 因为我们希望在特征图的每个位置都有一组锚点，这样可以更全面地覆盖到图像中的所有可能的目标。</span></span><br><span class="line"><span class="comment"># 如果只使用基础锚点，那么锚点的位置就只能在参考窗口的位置，这样可能会漏掉一些位于其他位置的目标。</span></span><br><span class="line"><span class="comment"># 通过偏移，我们可以让锚点覆盖到特征图的每个位置，从而更好地检测到所有的目标。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_enumerate_shifted_anchor</span>(<span class="params">anchor_base, feat_stride, height, width</span>):</span><br><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> xp</span><br><span class="line">    shift_y = xp.arange(<span class="number">0</span>, height * feat_stride, feat_stride) <span class="comment"># 计算y方向上的所有偏移</span></span><br><span class="line">    shift_x = xp.arange(<span class="number">0</span>, width * feat_stride, feat_stride) <span class="comment"># 计算x方向上的所有偏移</span></span><br><span class="line">    shift_x, shift_y = xp.meshgrid(shift_x, shift_y)  <span class="comment"># 生成网格坐标</span></span><br><span class="line">    shift = xp.stack((shift_y.ravel(), shift_x.ravel(),</span><br><span class="line">                      shift_y.ravel(), shift_x.ravel()), axis=<span class="number">1</span>) <span class="comment"># 将偏移堆叠成一个数组</span></span><br><span class="line"></span><br><span class="line">    A = anchor_base.shape[<span class="number">0</span>] <span class="comment"># 每个像素处会有A个锚点（A=9）</span></span><br><span class="line">    K = shift.shape[<span class="number">0</span>] <span class="comment"># 特征图的像素数量（K=hh*ww）==&gt; 整张特征图总的偏移量的数量=K*A</span></span><br><span class="line">    anchor = anchor_base.reshape((<span class="number">1</span>, A, <span class="number">4</span>)) + \</span><br><span class="line">             shift.reshape((<span class="number">1</span>, K, <span class="number">4</span>)).transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)) <span class="comment"># 将基础锚点和偏移相加，得到所有的偏移后的锚点</span></span><br><span class="line">    anchor = anchor.reshape((K * A, <span class="number">4</span>)).astype(np.float32) <span class="comment"># 调整偏移锚点的形状，并转换为浮点类型</span></span><br><span class="line">    <span class="keyword">return</span> anchor</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>（3）生成用于训练<code>Faster R-CNN</code>的head网络（即RoI网络）所需的目标：经IoU阈值筛选后得到128个ROIs(<code>sample_roi</code>)，使用<code>ProposalTargetCreator</code>为<code>sample_roi</code>分配真实边界框<code>gt_roi_loc</code>和真实标签<code>gt_roi_label</code>，此时就生成了用于训练<code>Faster R-CNN</code>的head网络（即RoI网络）所需的目标。这些目标包括每个RoI对应的ground
truth边界框的偏移和比例（用于边界框回归任务），以及每个RoI对应的ground
truth边界框的类别标签（用于分类任务）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sample_roi代表经过IoU阈值筛选后的RoIs，由前景roi和背景roi组成，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># gt_roi_loc代表sample_roi与其对应的真实边界框（其实是与它IoU最大的真实边界框）之间的偏移和比例，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># gt_roi_label代表sample_roi对应的真实标签（其实是与它IoU最大的真实边界框的标签），形状为(128,)</span></span><br><span class="line">sample_roi, gt_roi_loc, gt_roi_label = self.proposal_target_creator(</span><br><span class="line">            roi,</span><br><span class="line">            at.tonumpy(bbox),</span><br><span class="line">            at.tonumpy(label),</span><br><span class="line">            self.loc_normalize_mean,</span><br><span class="line">            self.loc_normalize_std)<span class="comment"># 使用ProposalTargetCreator生成训练目标</span></span><br></pre></td></tr></table></figure>
<p><code>utils/creator_tool.py</code>中的类<code>ProposalTargetCreator</code>的代码如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用处：为给定的RoIs分配ground truth边界框</span></span><br><span class="line"><span class="comment"># 1.计算RoIs和边界框的IoU</span></span><br><span class="line"><span class="comment"># 2.找出每个RoI与哪个边界框的IoU最大</span></span><br><span class="line"><span class="comment"># 3.将每个RoI分配给与其IoU最大的边界框</span></span><br><span class="line"><span class="comment"># 4.计算这些RoI与其对应的边界框的偏移和比例</span></span><br><span class="line"><span class="comment"># 5.对偏移和比例进行归一化</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProposalTargetCreator</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 n_sample=<span class="number">128</span>,</span></span><br><span class="line"><span class="params">                 pos_ratio=<span class="number">0.25</span>, pos_iou_thresh=<span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">                 neg_iou_thresh_hi=<span class="number">0.5</span>, neg_iou_thresh_lo=<span class="number">0.0</span></span></span><br><span class="line"><span class="params">                 </span>):<span class="comment"># 初始化方法，接受一系列参数，包括采样区域的数量、前景的比例、前景的IoU阈值、背景的IoU阈值等</span></span><br><span class="line">        self.n_sample = n_sample  <span class="comment"># 采样区域的数量</span></span><br><span class="line">        self.pos_ratio = pos_ratio  <span class="comment"># 前景的比例</span></span><br><span class="line">        self.pos_iou_thresh = pos_iou_thresh  <span class="comment"># 前景的IoU阈值</span></span><br><span class="line">        self.neg_iou_thresh_hi = neg_iou_thresh_hi  <span class="comment"># 背景的IoU阈值上限</span></span><br><span class="line">        self.neg_iou_thresh_lo = neg_iou_thresh_lo  <span class="comment"># 背景的IoU阈值下限 <span class="doctag">NOTE:</span>default 0.1 in py-faster-rcnn</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, roi, bbox, label,</span></span><br><span class="line"><span class="params">        loc_normalize_mean=(<span class="params"><span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span></span>),</span></span><br><span class="line"><span class="params">        loc_normalize_std=(<span class="params"><span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span></span>)</span>):<span class="comment"># 定义__call__方法，接受RoIs、边界框、标签、位置归一化的均值和标准差作为参数</span></span><br><span class="line">        n_bbox, _ = bbox.shape <span class="comment"># 获取边界框的数量</span></span><br><span class="line"></span><br><span class="line">        roi = np.concatenate((roi, bbox), axis=<span class="number">0</span>)  <span class="comment"># 将RoIs和边界框合并</span></span><br><span class="line"></span><br><span class="line">        pos_roi_per_image = np.<span class="built_in">round</span>(self.n_sample * self.pos_ratio)  <span class="comment"># 计算每个图像的前景RoI数量</span></span><br><span class="line">        iou = bbox_iou(roi, bbox)  <span class="comment"># 计算RoIs和边界框的IoU</span></span><br><span class="line">        gt_assignment = iou.argmax(axis=<span class="number">1</span>)  <span class="comment"># 找出每个RoI与哪个边界框的IoU最大</span></span><br><span class="line">        max_iou = iou.<span class="built_in">max</span>(axis=<span class="number">1</span>)  <span class="comment"># 找出每个RoI的最大IoU</span></span><br><span class="line">        <span class="comment"># Offset range of classes from [0, n_fg_class - 1] to [1, n_fg_class].</span></span><br><span class="line">        <span class="comment"># The label with value 0 is the background.</span></span><br><span class="line">        gt_roi_label = label[gt_assignment] + <span class="number">1</span> <span class="comment"># 将每个RoI分配给与其IoU最大的边界框的标签</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Select foreground RoIs as those with &gt;= pos_iou_thresh IoU.</span></span><br><span class="line">        pos_index = np.where(max_iou &gt;= self.pos_iou_thresh)[<span class="number">0</span>]  <span class="comment"># 找出IoU大于等于前景阈值的RoIs</span></span><br><span class="line">        pos_roi_per_this_image = <span class="built_in">int</span>(<span class="built_in">min</span>(pos_roi_per_image, pos_index.size)) <span class="comment"># 计算这个图像的前景RoI数量</span></span><br><span class="line">        <span class="keyword">if</span> pos_index.size &gt; <span class="number">0</span>:  <span class="comment"># 如果存在前景RoI</span></span><br><span class="line">            pos_index = np.random.choice(</span><br><span class="line">                pos_index, size=pos_roi_per_this_image, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Select background RoIs as those within</span></span><br><span class="line">        <span class="comment"># [neg_iou_thresh_lo, neg_iou_thresh_hi).</span></span><br><span class="line">        neg_index = np.where((max_iou &lt; self.neg_iou_thresh_hi) &amp;</span><br><span class="line">                             (max_iou &gt;= self.neg_iou_thresh_lo))[<span class="number">0</span>]  <span class="comment"># 找出IoU在背景阈值范围内的RoIs</span></span><br><span class="line">        neg_roi_per_this_image = self.n_sample - pos_roi_per_this_image  <span class="comment"># 计算这个图像的背景RoI数量</span></span><br><span class="line">        neg_roi_per_this_image = <span class="built_in">int</span>(<span class="built_in">min</span>(neg_roi_per_this_image,</span><br><span class="line">                                         neg_index.size)) <span class="comment"># 计算这个图像的背景RoI数量</span></span><br><span class="line">        <span class="keyword">if</span> neg_index.size &gt; <span class="number">0</span>:  <span class="comment"># 如果存在背景RoI</span></span><br><span class="line">            neg_index = np.random.choice(</span><br><span class="line">                neg_index, size=neg_roi_per_this_image, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The indices that we&#x27;re selecting (both positive and negative).</span></span><br><span class="line">        keep_index = np.append(pos_index, neg_index)  <span class="comment"># 将前景和背景的索引合并</span></span><br><span class="line">        gt_roi_label = gt_roi_label[keep_index]  <span class="comment"># 保留这些RoI的标签</span></span><br><span class="line">        gt_roi_label[pos_roi_per_this_image:] = <span class="number">0</span>  <span class="comment"># negative labels --&gt; 0  # 将背景RoI的标签设置为0</span></span><br><span class="line">        sample_roi = roi[keep_index] <span class="comment"># 保留这些RoI</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute offsets and scales to match sampled RoIs to the GTs.</span></span><br><span class="line">        gt_roi_loc = bbox2loc(sample_roi, bbox[gt_assignment[keep_index]]) <span class="comment"># 计算这些RoI与其对应的边界框的偏移和比例</span></span><br><span class="line">        gt_roi_loc = ((gt_roi_loc - np.array(loc_normalize_mean, np.float32)</span><br><span class="line">                       ) / np.array(loc_normalize_std, np.float32))<span class="comment"># 对偏移和比例进行归一化</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sample_roi, gt_roi_loc, gt_roi_label</span><br><span class="line">    <span class="comment">#sample_roi代表经过IoU阈值筛选后的RoIs，由前景roi和背景roi组成，形状为(128, 4)</span></span><br><span class="line">    <span class="comment">#gt_roi_loc代表sample_roi与其对应的真实边界框（其实是与它IoU最大的真实边界框）之间的偏移和比例，形状为(128, 4)</span></span><br><span class="line">    <span class="comment">#gt_roi_label代表sample_roi对应的真实标签（其实是与它IoU最大的真实边界框的标签），形状为(128,)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>（4）生成用于训练<code>Faster R-CNN</code>的RPN网络所需的目标：这些目标包括每个锚点对应的ground
truth边界框的偏移和比例（用于边界框回归任务），以及每个锚点是否包含物体的标签（用于前景/背景分类任务）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># rpn_loc代表偏移后的锚框的位置</span></span><br><span class="line"><span class="comment"># gt_rpn_loc代表每个anchor与其对应的真实边界框之间的偏移和比例 (hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># gt_rpn_label代表每个anchor对应的真实边界框的标签 (hh*ww*9,)</span></span><br><span class="line">gt_rpn_loc, gt_rpn_label = self.anchor_target_creator(</span><br><span class="line">            at.tonumpy(bbox),</span><br><span class="line">            anchor,</span><br><span class="line">            img_size)  <span class="comment"># 使用AnchorTargetCreator生成训练目标</span></span><br></pre></td></tr></table></figure>
<p><code>utils/creator_tool.py</code>中的类<code>AnchorTargetCreator</code>的代码如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AnchorTargetCreator</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 n_sample=<span class="number">256</span>,</span></span><br><span class="line"><span class="params">                 pos_iou_thresh=<span class="number">0.7</span>, neg_iou_thresh=<span class="number">0.3</span>,</span></span><br><span class="line"><span class="params">                 pos_ratio=<span class="number">0.5</span></span>):  <span class="comment"># 初始化方法，接受一系列参数，包括采样区域的数量、前景的IoU阈值、背景的IoU阈值、前景的比例等</span></span><br><span class="line">        self.n_sample = n_sample <span class="comment"># 采样区域的数量</span></span><br><span class="line">        self.pos_iou_thresh = pos_iou_thresh  <span class="comment"># 前景的IoU阈值</span></span><br><span class="line">        self.neg_iou_thresh = neg_iou_thresh  <span class="comment"># 背景的IoU阈值</span></span><br><span class="line">        self.pos_ratio = pos_ratio   <span class="comment"># 前景的比例</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, bbox, anchor, img_size</span>):   <span class="comment"># 定义__call__方法，接受边界框、锚点和图像尺寸作为参数</span></span><br><span class="line"></span><br><span class="line">        img_H, img_W = img_size  <span class="comment"># 获取图像的尺寸</span></span><br><span class="line"></span><br><span class="line">        n_anchor = <span class="built_in">len</span>(anchor)  <span class="comment"># 获取锚点的数量</span></span><br><span class="line">        inside_index = _get_inside_index(anchor, img_H, img_W) <span class="comment"># 获取在图像内部的锚点的索引</span></span><br><span class="line">        anchor = anchor[inside_index]   <span class="comment"># 获取在图像内部的锚点</span></span><br><span class="line">        argmax_ious, label = self._create_label(</span><br><span class="line">            inside_index, anchor, bbox)  <span class="comment"># 创建标签</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute bounding box regression targets</span></span><br><span class="line">        loc = bbox2loc(anchor, bbox[argmax_ious])  <span class="comment"># 计算anchor和ground truth边界框之间的偏移和缩放</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># map up to original set of anchors</span></span><br><span class="line">        label = _unmap(label, n_anchor, inside_index, fill=-<span class="number">1</span>)  <span class="comment"># 将标签映射回原始的锚点集</span></span><br><span class="line">        loc = _unmap(loc, n_anchor, inside_index, fill=<span class="number">0</span>)  <span class="comment"># 将位置映射回原始的锚点集</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loc, label  <span class="comment"># 返回位置和标签</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_create_label</span>(<span class="params">self, inside_index, anchor, bbox</span>):</span><br><span class="line">        <span class="comment"># label: 1 is positive, 0 is negative, -1 is dont care</span></span><br><span class="line">        label = np.empty((<span class="built_in">len</span>(inside_index),), dtype=np.int32)  <span class="comment"># 创建一个空的标签数组</span></span><br><span class="line">        label.fill(-<span class="number">1</span>)  <span class="comment"># 将标签数组填充为-1</span></span><br><span class="line"></span><br><span class="line">        argmax_ious, max_ious, gt_argmax_ious = \</span><br><span class="line">            self._calc_ious(anchor, bbox, inside_index)  <span class="comment"># 计算IoU</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># assign negative labels first so that positive labels can clobber them</span></span><br><span class="line">        label[max_ious &lt; self.neg_iou_thresh] = <span class="number">0</span>  <span class="comment"># 将IoU小于背景阈值的锚点标记为背景</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># positive label: for each gt, anchor with highest iou</span></span><br><span class="line">        label[gt_argmax_ious] = <span class="number">1</span>  <span class="comment"># 将每个ground truth对应的IoU最大的锚点标记为前景</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># positive label: above threshold IOU</span></span><br><span class="line">        label[max_ious &gt;= self.pos_iou_thresh] = <span class="number">1</span>  <span class="comment"># 将IoU大于前景阈值的锚点标记为前景</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># subsample positive labels if we have too many</span></span><br><span class="line">        n_pos = <span class="built_in">int</span>(self.pos_ratio * self.n_sample)   <span class="comment"># 计算前景的数量</span></span><br><span class="line">        pos_index = np.where(label == <span class="number">1</span>)[<span class="number">0</span>]   <span class="comment"># 获取前景的索引</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(pos_index) &gt; n_pos:   <span class="comment"># 如果前景的数量过多</span></span><br><span class="line">            disable_index = np.random.choice(</span><br><span class="line">                pos_index, size=(<span class="built_in">len</span>(pos_index) - n_pos), replace=<span class="literal">False</span>)   <span class="comment"># 随机选择一部分前景</span></span><br><span class="line">            label[disable_index] = -<span class="number">1</span>   <span class="comment"># 将这部分前景标记为不关心</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># subsample negative labels if we have too many</span></span><br><span class="line">        n_neg = self.n_sample - np.<span class="built_in">sum</span>(label == <span class="number">1</span>)  <span class="comment"># 计算背景的数量</span></span><br><span class="line">        neg_index = np.where(label == <span class="number">0</span>)[<span class="number">0</span>] <span class="comment"># 获取背景的索引</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(neg_index) &gt; n_neg:  <span class="comment"># 如果背景的数量过多</span></span><br><span class="line">            disable_index = np.random.choice(</span><br><span class="line">                neg_index, size=(<span class="built_in">len</span>(neg_index) - n_neg), replace=<span class="literal">False</span>) <span class="comment"># 随机选择一部分背景</span></span><br><span class="line">            label[disable_index] = -<span class="number">1</span> <span class="comment"># 将这部分背景标记为不关心</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> argmax_ious, label  <span class="comment"># 返回最大IoU的索引和标签</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_calc_ious</span>(<span class="params">self, anchor, bbox, inside_index</span>):</span><br><span class="line">        <span class="comment"># ious between the anchors and the gt boxes</span></span><br><span class="line">        ious = bbox_iou(anchor, bbox) <span class="comment"># 计算锚点和ground truth边界框之间的IoU</span></span><br><span class="line">        argmax_ious = ious.argmax(axis=<span class="number">1</span>)  <span class="comment"># 获取每个锚点对应的最大IoU的索引</span></span><br><span class="line">        max_ious = ious[np.arange(<span class="built_in">len</span>(inside_index)), argmax_ious]  <span class="comment"># 获取每个锚点的最大IoU</span></span><br><span class="line">        gt_argmax_ious = ious.argmax(axis=<span class="number">0</span>) <span class="comment"># 获取每个ground truth边界框对应的最大IoU的索引</span></span><br><span class="line">        gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[<span class="number">1</span>])]  <span class="comment"># 获取每个ground truth边界框的最大IoU</span></span><br><span class="line">        gt_argmax_ious = np.where(ious == gt_max_ious)[<span class="number">0</span>] <span class="comment"># 获取最大IoU的索引</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> argmax_ious, max_ious, gt_argmax_ious   <span class="comment"># 返回最大IoU的索引、最大IoU和ground truth边界框的最大IoU的索引</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>（5）使用<code>Faster R-CNN</code>的头部网络（即RoI网络）对<code>sample_roi</code>进行前向传播，返回<code>roi_cls_locs</code>、<code>roi_scores</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sample_roi代表经过IoU阈值筛选后的RoIs，由前景roi和背景roi组成，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># sample_roi_index：一个全零的数组，用于存储RoIs的索引</span></span><br><span class="line"><span class="comment"># roi_cls_locs代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的边界框位置 (128,21*4)，128为RPN得出的sample_roi的数量</span></span><br><span class="line"><span class="comment"># roi_scores代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的得分 (128,21)</span></span><br><span class="line">roi_cls_loc, roi_score = self.faster_rcnn.head(</span><br><span class="line">    features,</span><br><span class="line">    sample_roi,</span><br><span class="line">    sample_roi_index) <span class="comment"># 使用Faster R-CNN的头部网络进行前向传播</span></span><br></pre></td></tr></table></figure>
<p>（6）计算<code>RPN losses</code></p>
<p>RPN的定位损失：偏移后的锚框位置和真实边界框位置之间的平滑L1损失</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ------------------ RPN losses -------------------#</span></span><br><span class="line"><span class="comment"># rpn_loc代表偏移后的锚框的位置 (hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># gt_rpn_loc代表每个anchor与其对应的真实边界框之间的偏移和比例 (hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># gt_rpn_label代表每个anchor对应的真实边界框的标签 (hh*ww*9,)</span></span><br><span class="line">rpn_loc_loss = _fast_rcnn_loc_loss(</span><br><span class="line">rpn_loc,</span><br><span class="line">gt_rpn_loc,</span><br><span class="line">gt_rpn_label.data,</span><br><span class="line">self.rpn_sigma)  <span class="comment"># 计算RPN的定位损失：偏移后的锚框位置和真实边界框位置之间的平滑L1损失</span></span><br></pre></td></tr></table></figure>
<p>RPN的分类损失</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># rpn_score代表偏移后的锚框的得分 (hh*ww*9, 2)</span></span><br><span class="line">rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_label.cuda(), ignore_index=-<span class="number">1</span>)  <span class="comment"># 计算RPN的分类损失</span></span><br></pre></td></tr></table></figure>
<p>（7）计算<code>ROI losses</code>（fast rcnn loss）</p>
<p>ROI的定位损失</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ------------------ ROI losses (fast rcnn loss) -------------------#</span></span><br><span class="line"><span class="comment"># roi_cls_loc代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的边界框位置 (128,21,4)，128为RPN得出的sample_roi的数量</span></span><br><span class="line"><span class="comment"># roi_score代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的得分 (128,21)</span></span><br><span class="line"><span class="comment"># gt_roi_loc代表sample_roi与其对应的真实边界框（其实是与它IoU最大的真实边界框）之间的偏移和比例，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># gt_roi_label代表sample_roi对应的真实标签（其实是与它IoU最大的真实边界框的标签），形状为(128,)</span></span><br><span class="line">roi_loc_loss = _fast_rcnn_loc_loss(</span><br><span class="line">roi_loc.contiguous(),</span><br><span class="line">gt_roi_loc,</span><br><span class="line">gt_roi_label.data,</span><br><span class="line">self.roi_sigma)  <span class="comment"># 计算RoI的定位损失</span></span><br></pre></td></tr></table></figure>
<p>ROI的分类损失</p>
<p>（8）计算总损失</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 总损失 = rpn定位损失+rpn分类损失+roi定位损失+roi分类损失</span></span><br><span class="line">losses = [rpn_loc_loss, rpn_cls_loss, roi_loc_loss, roi_cls_loss]  <span class="comment"># 创建一个列表，用于存储所有的损失</span></span><br><span class="line">losses = losses + [<span class="built_in">sum</span>(losses)]  <span class="comment"># 计算总损失</span></span><br></pre></td></tr></table></figure>
<p>（9）前向传播返回总损失后，执行反向传播、参数更新等操作</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">self, imgs, bboxes, labels, scale</span>): <span class="comment"># 定义训练步骤方法，接受图像、边界框、标签和缩放因子作为参数</span></span><br><span class="line">    self.optimizer.zero_grad() <span class="comment"># 清零优化器的梯度缓存</span></span><br><span class="line">    losses = self.forward(imgs, bboxes, labels, scale) <span class="comment"># 调用forward方法，计算损失 imgs==tensor(1,3,800,600) bboxes==tensor(1,1,4) labels==tensor(1,1) scale==(1,)</span></span><br><span class="line">    losses.total_loss.backward()<span class="comment"># 对总损失进行反向传播</span></span><br><span class="line">    self.optimizer.step()  <span class="comment"># 执行一步优化（参数更新）</span></span><br><span class="line">    self.update_meters(losses)  <span class="comment"># 更新度量</span></span><br><span class="line">    <span class="keyword">return</span> losses <span class="comment"># 返回损失</span></span><br></pre></td></tr></table></figure>
<p>（10）一个训练步骤<code>trainer.train_step(img, bbox, label, scale)</code>完成后，评估训练结果并在<code>visdom</code>中可视化展示
<img src="https://ooo.0x0.ooo/2023/12/29/OKYXOt.png"
alt="OKYXOt.png" /></p>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>代码复现</tag>
        <tag>Faster RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster RCNN论文理解</title>
    <url>/2023/12/29/Faster-RCNN%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="faster-rcnn论文理解">Faster RCNN论文理解</h1>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYpMG.png" alt="OKYpMG.png" />
<figcaption aria-hidden="true">OKYpMG.png</figcaption>
</figure>
<span id="more"></span>
<h2 id="背景">背景</h2>
<p>基于候选区域的CNNs(RCNN、SPPnet、FastRCNN...)在目标检测领域取得了很好的效果，尤其是共享卷积特征及大地降低了计算代价，提高了训练和测试的速度。如果忽略产生候选区域(region
proposals)的耗时，Fast
RCNN输入一张图片和其候选区域后几乎可以实现实时检测。因此，现在检测系统的计算瓶颈主要在于产生候选区域的部分。Selective
Search
(SS)产生一张图片的2000个候选区域要耗时2s，EdgeBoxes则要耗时0.2s（两种方法都只有CPU实现）——太慢了！因此，本文提出利用deep
ConvNet来产生候选区域。</p>
<h2 id="主要贡献">主要贡献</h2>
<ol type="1">
<li><strong>用RPN代替selective、EdgeBoxes产生候选区域</strong>：RPN(Region
Proposal Networks)，能够同时预测边界框和对象性得分(objectness
scores)，并和Fast RCNN目标检测网络共享了卷积特征，实现了网络加速。</li>
<li>提出了一种“轮流”的训练模式来合并RPN和Fast RCNN</li>
</ol>
<h2 id="rpnregion-proposal-networks">RPN(Region Proposal Networks)</h2>
<h3 id="网络结构">网络结构</h3>
<blockquote>
<p>下图展示了RPN的总体结构示意图</p>
</blockquote>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYPHI.png" alt="OKYPHI.png" />
<figcaption aria-hidden="true">OKYPHI.png</figcaption>
</figure>
<p>共享卷积层(conv layers)本文实验了ZF模型和VGG-16模型</p>
<p>输入：一张任意大小的图片</p>
<p>输出：一系列矩形候选区域及其对应的对象性得分(objectness
score——object/not-object)</p>
<blockquote>
<p>下图展示了"RPN特有部分"的结构示意图</p>
</blockquote>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYRXD.png" alt="OKYRXD.png" />
<figcaption aria-hidden="true">OKYRXD.png</figcaption>
</figure>
<h3
id="平移不变的参考框translation-invariant-anchors">平移不变的参考框(Translation-Invariant
Anchors)</h3>
<p>用三种不同的尺度(scale)和长宽比(aspect
ratio)，在每个滑动窗口位置产生9种不同的参考框。</p>
<p>参考框和根据参考框计算候选区域的函数，二者都具有平移不变性</p>
<h3 id="rpn损失函数">RPN损失函数</h3>
<p><strong>注意！！！这里是RPN的分类和回归网络两个分支的损失函数，不是Fast
RCNN的损失函数</strong></p>
<ol type="1">
<li><p>怎么判断预测的参考框是正样本还是负样本？</p>
<ul>
<li>正样本：将参考框和所有的ground-truth计算IoU，与每个ground-truth有着最大IoU的参考框是正样本；将参考框和所有的ground-truth计算IoU，与任意ground-truth的IoU超过0.7的也是正样本</li>
<li>负样本：将参考框和所有的ground-truth计算IoU，与所有的ground-truth的IoU&lt;0.3的是负样本</li>
</ul></li>
<li><p>最小化Fast RCNN中的多任务损失函数(multi-task loss)</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYyZr.png" alt="OKYyZr.png" />
<figcaption aria-hidden="true">OKYyZr.png</figcaption>
</figure></li>
<li><p>cls：识别参考框(anchor box)属于object or
not-object；reg：将参考框(anchor box)回归到真实标注框(ground-truth
box)</p></li>
<li><p>回归的实现方式有所改变：</p>
<ul>
<li>RCNN、Fast
RCNN：将任意大小的候选区域池化后，执行边界框回归，回归权重被各尺寸的候选区域共享</li>
<li>RPN：只在相同大小的特征图上进行回归，学习到k个不同的边界框回归器，它们之间的权重互不共享</li>
</ul></li>
</ol>
<h3 id="训练rpn">训练RPN</h3>
<p>以图片为中心采样(“image centric” sampling
strategy)：每个mini-batch来自于一张图片包含的正负样本。</p>
<p>实际做法：在一张图片上随机采样256个参考框，其中正负参考框占比接近1:1，用这些样本作为mini-batch，计算这个mini-batch的损失函数</p>
<h2 id="faster-rcnn整体训练">Faster RCNN整体训练</h2>
<p><strong>Faster RCNN = RPN + Fast RCNN</strong></p>
<h3 id="如何共享">如何共享</h3>
<p><strong>如何在RPN和Fast RCNN间共享卷积层？</strong></p>
<h4 id="思路1轮流训练">思路1：轮流训练</h4>
<p>step
1，训练RPN：用ImageNet上的预训练模型初始化RPN，并在端到端的区域建议任务上微调。</p>
<p>step 2，训练Fast RCNN：用step-1训练的RPN产生的候选区域 +
ImageNet上的预训练模型从头训练一个Fast
RCNN检测模型。到此为止，这两个网络还没有共享卷积层的特征。</p>
<p>step 3，用step-2得到的Fast RCNN检测网络的特征提取部分(Deep
ConvNet)初始化RPN的训练，微调RPN特有的的层。此时，两个网络实现了共享卷积层。</p>
<p>step 4，固定共享卷积层，微调Fast
RCNN的全连接层（特有的那些层）。到此为止，两个网络就共享了卷积层并形成了一个统一的网络。</p>
<p>下图展示了这一轮流训练过程 <img
src="https://ooo.0x0.ooo/2023/12/29/OKYJ71.png" alt="OKYJ71.png" /></p>
<h4 id="思路2近似联合训练法">思路2：近似联合训练法</h4>
<p>做法：训练初始就将RPN和Fast
RCNN合并成一个网络，然后用同时进行反向传播来优化。</p>
<p>问题：无法求解坐标偏导数，因为Fast
RCNN的损失函数反向传播也会传导到RPN回归出的坐标部分，但这种方法忽略了这部分</p>
<h4 id="思路3非近似联合训练法">思路3：非近似联合训练法</h4>
<p>利用ROI Warping实现了Fast RCNN尾部网络反向传播到坐标部分的问题</p>
<h3 id="实现细节">实现细节</h3>
<ol type="1">
<li><p>RPN和Fast
RCNN的训练和测试都使用了单尺度图片：缩放图片的短边为600px</p></li>
<li><p>参考框选取了3种尺度：128<sup>2，256</sup>2，512^2，3种长宽比：1:1，1:2，2:1=&gt;不需要多尺寸特征、多尺寸滑动窗口来预测大区域</p></li>
<li><p>处理跨图片边界的参考框：</p>
<ul>
<li>训练时忽略所有跨边界的参考框，因为如果不忽略跨边界的参考框，它们会在损失函数中引入很大很难纠正的错误模式，导致训练很难收敛。</li>
<li>测试时遇到跨图片边界的候选框，会保留其并裁剪其到图片边界</li>
</ul>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKY4zF.png" alt="OKY4zF.png" />
<figcaption aria-hidden="true">OKY4zF.png</figcaption>
</figure></li>
<li><p>基于cls
scores针对每一类别的候选区域应用非极大值抑制过滤，以减少冗余。当NMS的IoU的阈值设定为0.7时，每张图片最终会留下大约2k个候选区域，用这2k个候选区域训练Fast
RCNN（测试时不一定需要使用2k个，实际使用了300个）</p></li>
</ol>
<h3 id="实验">实验</h3>
<p>数据集：PASCAL VOC 2007，5k trainval images，5k test
images，超过20个对象类</p>
<p>评估指标：mAP</p>
<h3 id="消融实验">消融实验</h3>
<ol type="1">
<li><p>困惑：在RPN和Fast RCNN之间共享卷积特征有什么作用？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验：在4-step的训练步骤的step-2后停下来，用2个分离的网络（RPN和Fast RCNN）完成获取候选区域和实现目标检测</span><br><span class="line"></span><br><span class="line">实验结果：精度会下降</span><br><span class="line"></span><br><span class="line">解释：说明step-2训练好的Fast RCNN网络的特征提取能力能更好地辅助RPN模块产生候选区域，提高了候选区域的质量</span><br></pre></td></tr></table></figure></li>
<li><p>困惑：只在测试时使用RPN产生的候选区域，对Fast
RCNN检测网络有什么影响?<strong>（注意这里是Fast RCNN，Fast
RCNN的训练还是采用selective-search产生的候选区域来实现的，而不是Faster
RCNN，即这里RPN和Fast RCNN并没有共享卷积特征）</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验1：</span><br><span class="line"></span><br><span class="line">- 训练时：selective search产生2k个候选区域+ZF；</span><br><span class="line">- 测试时：固定训练产生的检测器，采用RPN产生的候选区域。这时RPN并没有和此时的ZF共享特征。</span><br><span class="line"></span><br><span class="line">实验结果：测试时用300个RPN产生的候选区域来代替selective-search，精度会下降</span><br><span class="line"></span><br><span class="line">解释：精度损失是因为训练和测试时所用的候选区域(proposals)不一致，该结果为后续实验提供baseline</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验2：测试时用RPN产生的前100个候选区域代替前300个</span><br><span class="line"></span><br><span class="line">实验结果：精度下降但下降不多</span><br><span class="line"></span><br><span class="line">解释：说明排名靠前的RPN proposals很准确</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验3：测试时用前6k个RPN proposals(without NMS)产生的候选区域</span><br><span class="line"></span><br><span class="line">实验结果：精度并没有比用300个RPN proposals(with NMS)更好，说明NMS并不损害检测时的mAP，</span><br></pre></td></tr></table></figure></li>
<li><p>测试时RPN的分类和回归输出分别有什么作用？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验1：测试时移除RPN的cls layer，然后从没有打分的region proposals随机采样N个proposals进行测试（关闭分类层会导致后续——不会进行NMS，因为NMS是针对每一类(object/not-object)的cls score来进行的，而此时没有分类了）</span><br><span class="line"></span><br><span class="line">实验结果：N=1000时，精度几乎无影响；N=100是，精度大幅下降</span><br><span class="line"></span><br><span class="line">解释：cls scores 考虑到了排名最高的proposals的准确性</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验2：测试时移除RPN的reg layer（移除reg layer的后续影响是——proposals变成了anchor boxes）</span><br><span class="line"></span><br><span class="line">实验结果：精度下降</span><br><span class="line"></span><br><span class="line">解释：高质量的候选区域(proposals)主要是因为位置回归，只有参考框不足以准确定位</span><br></pre></td></tr></table></figure></li>
<li><p>更强大的网络(VGG-16)对RPN产生的候选区域质量有什么影响</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验：在上述实验（训练：selective-search + ZF，测试：利用ZF训练的RPN产生候选区域），改用VGG-16训练的RPN产生候选区域进行测试（注意这里RPN和目标检测网络都没有共享卷积特征）</span><br><span class="line"></span><br><span class="line">结果：精度提高</span><br><span class="line"></span><br><span class="line">解释：RPN+VGG-16产生的候选区域质量优于RPN+ZF（用ZF训练出来的RPN）</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="recall-to-iou">Recall-to-IoU</h3>
<p>这个评估指标主要用于诊断（注意是诊断，不是评估）产生候选区域的方法的优劣</p>
<p>下图展示了不同候选区域算法（SS、EB、RPN+ZF、RPN+VGG）在不同IoU时的召回率</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYdLK.png" alt="OKYdLK.png" />
<figcaption aria-hidden="true">OKYdLK.png</figcaption>
</figure>
<p>解释：</p>
<ol type="1">
<li>当proposals的数量下降的时候，RPN在各个IoU比率下的召回率都只是略微降低</li>
<li>当proposals的数量下降的时候，SS和EB方法在各个IoU比率下的召回率都显著降低</li>
<li>这就解释了为什么RPN只需要300个候选区域就能取得比较好的精度</li>
</ol>
<h3 id="一阶段检测vs两阶段检测">一阶段检测vs两阶段检测</h3>
<p>和OverFeat比较</p>
<p>参考资料：</p>
<blockquote>
<p>https://www.bilibili.com/video/BV1GB4y1r7rM/?spm_id_from=333.880.my_history.page.click&amp;vd_source=66a72b15abe9693bd8b4f738f5a67ee7</p>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>论文理解</tag>
        <tag>Faster RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster RCNN项目部署（一）</title>
    <url>/2023/12/29/Faster-RCNN%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h2 id="faster-rcnn项目部署">Faster RCNN项目部署</h2>
<p>simple-faster-rcnn-pytorch-master</p>
<p><strong>项目源码</strong>：https://github.com/chenyuntc/simple-faster-rcnn-pytorch</p>
<span id="more"></span>
<p><strong>云服务器环境：</strong></p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYfPN.png" alt="OKYfPN.png" />
<figcaption aria-hidden="true">OKYfPN.png</figcaption>
</figure>
<h3 id="安装依赖">安装依赖</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">!pip install scikit-image</span><br><span class="line">!pip install visdom</span><br><span class="line">!pip install torchnet</span><br><span class="line">!pip install opencv-python</span><br><span class="line">!pip install ipdb</span><br><span class="line">!pip install ipython==7.28.0</span><br><span class="line">!pip install fire</span><br></pre></td></tr></table></figure>
<h3 id="运行demo">运行demo</h3>
<h4 id="下载预训练模型">下载预训练模型</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">百度网盘地址：https://pan.baidu.com/s/1o87RuXW</span><br><span class="line">密码：scxn</span><br></pre></td></tr></table></figure>
<h4 id="运行demo.pipynb">运行demo.pipynb</h4>
<blockquote>
<p>问题：在运行<code>img = read_image('/root/autodl-tmp/FasterRCNN/misc/demo.jpg')</code>出现错误：
<code>UnidentifiedImageError：Image.open() cannot identify image file</code></p>
<p>解决：我也不知道咋解决，因为另外测试后发现PIL的Image.open()是可以用的，我重启了几次不知道为什么就能用了</p>
</blockquote>
<h3 id="train">Train</h3>
<h4 id="准备数据">准备数据</h4>
<p>参考项目官网的<code>5.1 Prepare data--Pascal VOC2007</code></p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYllC.png" alt="OKYllC.png" />
<figcaption aria-hidden="true">OKYllC.png</figcaption>
</figure>
<p>最终得到的数据目录如下</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYjTL.png" alt="OKYjTL.png" />
<figcaption aria-hidden="true">OKYjTL.png</figcaption>
</figure>
<h4 id="修改配置">修改配置</h4>
<ol type="1">
<li>utils/config.py：修改VOC数据集的存放位置<code>voc_data_dir = '/root/autodl-tmp/FasterRCNN/dataset/VOCdevkit/VOC2007/'</code></li>
</ol>
<h4 id="开启训练">开启训练</h4>
<p>如果直接运行代码<code>!python train.py train --env='fasterrcnn' --plot-every=100</code>，会出现以下问题：</p>
<blockquote>
<p>问题：ERROR:visdom:[WinError 10061]
由于目标计算机积极拒绝，无法连接。</p>
<p>原因：代码中用到了在线可视化工具visdom，但是没有启动</p>
<p>解决：利用Xshell映射云端服务器的visdom，进行训练过程可视。参考博客https://blog.csdn.net/m0_6551</p>
</blockquote>
<p>因此，先利用Xshell映射云端服务器的visdom（参见上面的博客），再在jupyter
notebook运行以下代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python train.py train --env=&#x27;fasterrcnn&#x27; --plot-every=100</span><br></pre></td></tr></table></figure>
<p>运行成功结果如下： <img
src="https://ooo.0x0.ooo/2023/12/29/OKY2vi.png" alt="OKY2vi.png" /></p>
<h4 id="利用pycharm进行调试">利用Pycharm进行调试</h4>
<p>因为在jupyter
notebook中开启训练时使用了代码<code>python train.py train --env='fasterrcnn' --plot-every=100</code>，而在Pycharm中无法输入这样的命令进行debug，因此我对<code>train.py</code>做了以下修改：</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYsua.png" alt="OKYsua.png" />
<figcaption aria-hidden="true">OKYsua.png</figcaption>
</figure>
<p>我舍弃了利用fire.Fire()来调用函数train，而是直接在main函数中调用了train()方法，并传递了参数。此时就可以在Pycharm进行debug了。</p>
<blockquote>
<p>另外，Pycharm在调试过程会遇到一个问题，即：debug时Pycharm卡住在connected界面不动</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYYzS.png" alt="OKYYzS.png" />
<figcaption aria-hidden="true">OKYYzS.png</figcaption>
</figure>
<p>解决：<img src="https://ooo.0x0.ooo/2023/12/29/OKY6cX.png"
alt="OKY6cX.png" /></p>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>代码复现</tag>
        <tag>Faster RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>RCNN代码复现</title>
    <url>/2023/12/29/RCNN%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><p>本代码最初在colab中实现，以下为全部代码及运行输出结果 #
挂载谷歌云盘，解压数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%pwd</span><br></pre></td></tr></table></figure>
<p>'/content'</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!unzip <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN/Images.zip&#x27;</span> -d <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN&#x27;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!unzip <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN/Airplanes_Annotations.zip&#x27;</span> -d <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN&#x27;</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h1 id="安装并导入依赖">安装并导入依赖</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!pip install tensorflow==<span class="number">2.8</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os,cv2,keras</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.__version__</span><br></pre></td></tr></table></figure>
<p>'2.8.0'</p>
<h1 id="更改工作目录">更改工作目录</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cd /content/drive/MyDrive/AI_content/RCNN</span><br></pre></td></tr></table></figure>
<p>/content/drive/MyDrive/AI_content/RCNN</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">path = <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN/Images&#x27;</span></span><br><span class="line">annot = <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN/Airplanes_Annotations&#x27;</span></span><br></pre></td></tr></table></figure>
<h1 id="查看数据和标签">查看数据和标签</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Index=<span class="number">148</span></span><br><span class="line">filename = <span class="string">&quot;airplane_&quot;</span>+<span class="built_in">str</span>(Index)+<span class="string">&quot;.jpg&quot;</span></span><br><span class="line"><span class="built_in">print</span>(filename)</span><br><span class="line">img = cv2.imread(os.path.join(path,filename))</span><br><span class="line">df = pd.read_csv(os.path.join(annot,filename.replace(<span class="string">&quot;.jpg&quot;</span>,<span class="string">&quot;.csv&quot;</span>)))</span><br><span class="line">plt.imshow(img)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    x1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">0</span>])</span><br><span class="line">    y1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">1</span>])</span><br><span class="line">    x2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">2</span>])</span><br><span class="line">    y2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">3</span>])</span><br><span class="line">    cv2.rectangle(img,(x1,y1),(x2,y2),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>airplane_148.jpg</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYkfL.png" alt="OKYkfL.png" />
<figcaption aria-hidden="true">OKYkfL.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYzBi.png" alt="OKYzBi.png" />
<figcaption aria-hidden="true">OKYzBi.png</figcaption>
</figure>
<h1 id="selective-search">Selective search</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.setUseOptimized(<span class="literal">True</span>);</span><br><span class="line">ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">im = cv2.imread(os.path.join(path,<span class="string">&quot;42850.jpg&quot;</span>))</span><br><span class="line">ss.setBaseImage(im)</span><br><span class="line">ss.switchToSelectiveSearchFast()</span><br><span class="line">rects = ss.process()</span><br><span class="line">imOut = im.copy() <span class="comment">#复制原图，在复制后的图片上绘制矩形</span></span><br><span class="line"><span class="keyword">for</span> i, rect <span class="keyword">in</span> (<span class="built_in">enumerate</span>(rects)):</span><br><span class="line">    x, y, w, h = rect</span><br><span class="line">    cv2.rectangle(imOut, (x, y), (x+w, y+h), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>, cv2.LINE_AA) <span class="comment">#在imOut上绘制矩形</span></span><br><span class="line"></span><br><span class="line">plt.imshow(imOut)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示可视化的结果</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYbpC.png" alt="OKYbpC.png" />
<figcaption aria-hidden="true">OKYbpC.png</figcaption>
</figure>
<h1 id="iou">IOU</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_iou</span>(<span class="params">bb1, bb2</span>):</span><br><span class="line">  <span class="comment"># assuring for proper dimension.</span></span><br><span class="line">    <span class="keyword">assert</span> bb1[<span class="string">&#x27;x1&#x27;</span>] &lt; bb1[<span class="string">&#x27;x2&#x27;</span>]</span><br><span class="line">    <span class="keyword">assert</span> bb1[<span class="string">&#x27;y1&#x27;</span>] &lt; bb1[<span class="string">&#x27;y2&#x27;</span>]</span><br><span class="line">    <span class="keyword">assert</span> bb2[<span class="string">&#x27;x1&#x27;</span>] &lt; bb2[<span class="string">&#x27;x2&#x27;</span>]</span><br><span class="line">    <span class="keyword">assert</span> bb2[<span class="string">&#x27;y1&#x27;</span>] &lt; bb2[<span class="string">&#x27;y2&#x27;</span>]</span><br><span class="line">  <span class="comment"># calculating dimension of common area between these two boxes.</span></span><br><span class="line">    x_left = <span class="built_in">max</span>(bb1[<span class="string">&#x27;x1&#x27;</span>], bb2[<span class="string">&#x27;x1&#x27;</span>])</span><br><span class="line">    y_top = <span class="built_in">max</span>(bb1[<span class="string">&#x27;y1&#x27;</span>], bb2[<span class="string">&#x27;y1&#x27;</span>])</span><br><span class="line">    x_right = <span class="built_in">min</span>(bb1[<span class="string">&#x27;x2&#x27;</span>], bb2[<span class="string">&#x27;x2&#x27;</span>])</span><br><span class="line">    y_bottom = <span class="built_in">min</span>(bb1[<span class="string">&#x27;y2&#x27;</span>], bb2[<span class="string">&#x27;y2&#x27;</span>])</span><br><span class="line">  <span class="comment"># if there is no overlap output 0 as intersection area is zero.</span></span><br><span class="line">    <span class="keyword">if</span> x_right &lt; x_left <span class="keyword">or</span> y_bottom &lt; y_top:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">  <span class="comment"># calculating intersection area.</span></span><br><span class="line">    intersection_area = (x_right - x_left) * (y_bottom - y_top)</span><br><span class="line">  <span class="comment"># individual areas of both these bounding boxes.</span></span><br><span class="line">    bb1_area = (bb1[<span class="string">&#x27;x2&#x27;</span>] - bb1[<span class="string">&#x27;x1&#x27;</span>]) * (bb1[<span class="string">&#x27;y2&#x27;</span>] - bb1[<span class="string">&#x27;y1&#x27;</span>])</span><br><span class="line">    bb2_area = (bb2[<span class="string">&#x27;x2&#x27;</span>] - bb2[<span class="string">&#x27;x1&#x27;</span>]) * (bb2[<span class="string">&#x27;y2&#x27;</span>] - bb2[<span class="string">&#x27;y1&#x27;</span>])</span><br><span class="line">  <span class="comment"># union area = area of bb1_+ area of bb2 - intersection of bb1 and bb2.</span></span><br><span class="line">    iou = intersection_area / <span class="built_in">float</span>(bb1_area + bb2_area - intersection_area)</span><br><span class="line">    <span class="keyword">assert</span> iou &gt;= <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">assert</span> iou &lt;= <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure>
<h1 id="准备训练数据">准备训练数据</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># At the end of below code we will have our train data in these lists</span></span><br><span class="line">train_images=[]</span><br><span class="line">train_labels=[]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> e,i <span class="keyword">in</span> <span class="built_in">enumerate</span>(os.listdir(annot)):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> i.startswith(<span class="string">&quot;airplane&quot;</span>):</span><br><span class="line">            filename = i.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>]+<span class="string">&quot;.jpg&quot;</span></span><br><span class="line">            <span class="built_in">print</span>(e,filename)</span><br><span class="line">            <span class="comment"># 读取图像</span></span><br><span class="line">            image = cv2.imread(os.path.join(path,filename))</span><br><span class="line">            <span class="comment"># 读取标注文件</span></span><br><span class="line">            df = pd.read_csv(os.path.join(annot,i))</span><br><span class="line">            gtvalues=[]</span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">                x1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">0</span>])</span><br><span class="line">                y1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">1</span>])</span><br><span class="line">                x2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">2</span>])</span><br><span class="line">                y2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">3</span>])</span><br><span class="line">                gtvalues.append(&#123;<span class="string">&quot;x1&quot;</span>:x1,<span class="string">&quot;x2&quot;</span>:x2,<span class="string">&quot;y1&quot;</span>:y1,<span class="string">&quot;y2&quot;</span>:y2&#125;)</span><br><span class="line">            <span class="comment"># 设置基础图像</span></span><br><span class="line">            ss.setBaseImage(image)   <span class="comment"># setting given image as base image</span></span><br><span class="line">            ss.switchToSelectiveSearchFast()     <span class="comment"># running selective search on base image</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 运行选择性搜索</span></span><br><span class="line">            ssresults = ss.process()     <span class="comment"># processing to get the outputs</span></span><br><span class="line">            imout = image.copy()</span><br><span class="line">            counter = <span class="number">0</span></span><br><span class="line">            falsecounter = <span class="number">0</span></span><br><span class="line">            flag = <span class="number">0</span></span><br><span class="line">            fflag = <span class="number">0</span></span><br><span class="line">            bflag = <span class="number">0</span></span><br><span class="line">             <span class="comment"># 遍历选择性搜索的结果</span></span><br><span class="line">            <span class="keyword">for</span> e,result <span class="keyword">in</span> <span class="built_in">enumerate</span>(ssresults):</span><br><span class="line">                <span class="keyword">if</span> e &lt; <span class="number">2000</span> <span class="keyword">and</span> flag == <span class="number">0</span>:     <span class="comment"># till 2000 to get top 2000 regions only</span></span><br><span class="line">                    <span class="keyword">for</span> gtval <span class="keyword">in</span> gtvalues:</span><br><span class="line">                        x,y,w,h = result</span><br><span class="line">                        iou = get_iou(gtval,&#123;<span class="string">&quot;x1&quot;</span>:x,<span class="string">&quot;x2&quot;</span>:x+w,<span class="string">&quot;y1&quot;</span>:y,<span class="string">&quot;y2&quot;</span>:y+h&#125;)  <span class="comment"># calculating IoU for each of the proposed regions</span></span><br><span class="line">                        <span class="keyword">if</span> counter &lt; <span class="number">30</span>:       <span class="comment"># getting only 30 psoitive examples</span></span><br><span class="line">                            <span class="keyword">if</span> iou &gt; <span class="number">0.70</span>:     <span class="comment"># IoU of being positive is 0.7</span></span><br><span class="line">                                timage = imout[x:x+w,y:y+h]</span><br><span class="line">                                resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA)</span><br><span class="line">                                train_images.append(resized)</span><br><span class="line">                                train_labels.append(<span class="number">1</span>)</span><br><span class="line">                                counter += <span class="number">1</span></span><br><span class="line">                        <span class="keyword">else</span> :</span><br><span class="line">                            fflag =<span class="number">1</span>              <span class="comment"># to insure we have collected all psotive examples</span></span><br><span class="line">                        <span class="keyword">if</span> falsecounter &lt;<span class="number">30</span>:      <span class="comment"># 30 negatve examples are allowed only</span></span><br><span class="line">                            <span class="keyword">if</span> iou &lt; <span class="number">0.3</span>:         <span class="comment"># IoU of being negative is 0.3</span></span><br><span class="line">                                timage = imout[x:x+w,y:y+h]</span><br><span class="line">                                resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA)</span><br><span class="line">                                train_images.append(resized)</span><br><span class="line">                                train_labels.append(<span class="number">0</span>)</span><br><span class="line">                                falsecounter += <span class="number">1</span></span><br><span class="line">                        <span class="keyword">else</span> :</span><br><span class="line">                            bflag = <span class="number">1</span>             <span class="comment">#to ensure we have collected all negative examples</span></span><br><span class="line">                    <span class="keyword">if</span> fflag == <span class="number">1</span> <span class="keyword">and</span> bflag == <span class="number">1</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;inside&quot;</span>)</span><br><span class="line">                        flag = <span class="number">1</span>        <span class="comment"># to signal the complition of data extaction from a particular image</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;error in &quot;</span>+filename)</span><br><span class="line">        <span class="keyword">continue</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># conversion of train data into arrays for further training</span></span><br><span class="line">X_new = np.array(train_images)</span><br><span class="line">Y_new = np.array(train_labels)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为方便下次不用重新处理输入的训练数据，在这里将X_new,Y_new进行保存</span></span><br><span class="line">np.save(<span class="string">&#x27;save_X_new&#x27;</span>,X_new)</span><br><span class="line">np.save(<span class="string">&#x27;save_Y_new&#x27;</span>,Y_new)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取保存的数据X_new,Y_new</span></span><br><span class="line">X_new = np.load(<span class="string">&#x27;save_X_new.npy&#x27;</span>)</span><br><span class="line">Y_new = np.load(<span class="string">&#x27;save_Y_new.npy&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 这里因为colab提供的显存不够，只有15g，加载全部数据进去会爆显存，所以只截取一部分样本来进行训练，即X_new_subset 、Y_new_subset </span></span><br><span class="line">total_nums = <span class="built_in">len</span>(Y_new)</span><br><span class="line"><span class="built_in">print</span>(total_nums)</span><br></pre></td></tr></table></figure>
<p>30229</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从训练数据中随机选择 10000 个样本</span></span><br><span class="line">num_samples = <span class="number">5000</span></span><br><span class="line">random_indices = np.random.choice(<span class="built_in">len</span>(X_new), num_samples, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用随机选择的索引来获取样本</span></span><br><span class="line">X_new_subset = X_new[random_indices]</span><br><span class="line">Y_new_subset = Y_new[random_indices]</span><br></pre></td></tr></table></figure>
<h1
id="预训练使用vgg16模型创建一个迁移学习模型">预训练（使用VGG16模型创建一个迁移学习模型）</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用 VGG16 模型来创建一个迁移学习模型</span></span><br><span class="line">vgg = tf.keras.applications.vgg16.VGG16(include_top=<span class="literal">True</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>, input_tensor=<span class="literal">None</span>, input_shape=<span class="literal">None</span>, pooling=<span class="literal">None</span>, classes=<span class="number">1000</span>)</span><br><span class="line"><span class="comment"># 将 VGG16 模型的大部分层设为不可训练，保留最后两层的可训练性</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> vgg.layers[:-<span class="number">2</span>]:</span><br><span class="line">  layer.trainable = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 获取 VGG16 模型中名为 &#x27;fc2&#x27; 的层，并获取该层的输出</span></span><br><span class="line">x = vgg.get_layer(<span class="string">&#x27;fc2&#x27;</span>)</span><br><span class="line">last_output =  x.output</span><br><span class="line"><span class="comment"># 在 VGG16 模型的 &#x27;fc2&#x27; 层之后添加了一个新的全连接层，这个全连接层只有一个单元，使用 sigmoid 激活函数来输出二元分类的概率</span></span><br><span class="line">x = tf.keras.layers.Dense(<span class="number">1</span>,activation = <span class="string">&#x27;sigmoid&#x27;</span>)(last_output)</span><br><span class="line"><span class="comment"># 创建一个新的模型，该模型接受 VGG16 的输入，并输出通过添加新层后的结果</span></span><br><span class="line">model = tf.keras.Model(vgg.<span class="built_in">input</span>,x)</span><br><span class="line"><span class="comment"># 编译模型，使用 Adam 优化器，二元交叉熵作为损失函数进行训练，并监控模型的精度（accuracy）指标</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer = <span class="string">&quot;adam&quot;</span>,</span><br><span class="line">              loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              metrics = [<span class="string">&#x27;acc&#x27;</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 保存一下这个模型文件</span></span><br><span class="line">model.save(<span class="string">&#x27;my_model_vgg16.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103:
UserWarning: You are saving your model as an HDF5 file via
<code>model.save()</code>. This file format is considered legacy. We
recommend using instead the native Keras format, e.g.
<code>model.save('my_model.keras')</code>. saving_api.save_model(</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看模型结构并进行训练</span></span><br><span class="line">model.summary()</span><br><span class="line">model.fit(X_new_subset,Y_new_subset,batch_size = <span class="number">32</span>,epochs = <span class="number">3</span>, verbose = <span class="number">1</span>,validation_split=<span class="number">.05</span>,shuffle = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;model&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 224, 224, 3)]     0         
                                                                 
 block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      
                                                                 
 block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     
                                                                 
 block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         
                                                                 
 block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     
                                                                 
 block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    
                                                                 
 block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         
                                                                 
 block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    
                                                                 
 block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    
                                                                 
 block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    
                                                                 
 block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         
                                                                 
 block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   
                                                                 
 block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   
                                                                 
 block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   
                                                                 
 block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         
                                                                 
 block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         
                                                                 
 flatten (Flatten)           (None, 25088)             0         
                                                                 
 fc1 (Dense)                 (None, 4096)              102764544 
                                                                 
 fc2 (Dense)                 (None, 4096)              16781312  
                                                                 
 dense (Dense)               (None, 1)                 4097      
                                                                 
=================================================================
Total params: 134264641 (512.18 MB)
Trainable params: 16785409 (64.03 MB)
Non-trainable params: 117479232 (448.15 MB)
_________________________________________________________________
Epoch 1/3
149/149 [==============================] - 43s 214ms/step - loss: 1.4586 - acc: 0.7680 - val_loss: 0.3230 - val_acc: 0.8880
Epoch 2/3
149/149 [==============================] - 19s 129ms/step - loss: 0.3880 - acc: 0.8215 - val_loss: 0.3339 - val_acc: 0.8560
Epoch 3/3
149/149 [==============================] - 20s 131ms/step - loss: 0.3464 - acc: 0.8495 - val_loss: 0.3104 - val_acc: 0.8760

&lt;keras.src.callbacks.History at 0x7a67e60b2140&gt;</code></pre>
<h1 id="创建带有svm的新网络">创建带有SVM的新网络</h1>
<h2 id="创建供svm使用的数据集">创建供SVM使用的数据集</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">svm_image = [];</span><br><span class="line">svm_label = [];</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建SVM数据集采用了和训练数据集不同的iou标准</span></span><br><span class="line"><span class="keyword">for</span> e,i <span class="keyword">in</span> <span class="built_in">enumerate</span>(os.listdir(annot)):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> i.startswith(<span class="string">&quot;airplane&quot;</span>):</span><br><span class="line">            <span class="comment"># 提取图像文件名并读取图像</span></span><br><span class="line">            filename = i.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>]+<span class="string">&quot;.jpg&quot;</span></span><br><span class="line">            <span class="built_in">print</span>(e,filename)</span><br><span class="line">            image = cv2.imread(os.path.join(path,filename))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 读取对应的标注文件</span></span><br><span class="line">            df = pd.read_csv(os.path.join(annot,i))</span><br><span class="line">            gtvalues=[]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 解析标注文件中的目标坐标信息</span></span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">                x1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">0</span>])</span><br><span class="line">                y1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">1</span>])</span><br><span class="line">                x2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">2</span>])</span><br><span class="line">                y2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">3</span>])</span><br><span class="line">                gtvalues.append(&#123;<span class="string">&quot;x1&quot;</span>:x1,<span class="string">&quot;x2&quot;</span>:x2,<span class="string">&quot;y1&quot;</span>:y1,<span class="string">&quot;y2&quot;</span>:y2&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 从图像中截取目标区域并调整大小，作为正样本(ground_truth对应的图像区域，作为正样本)</span></span><br><span class="line">                timage = image[x1:x2,y1:y2]</span><br><span class="line">                resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA)</span><br><span class="line">                svm_image.append(resized)</span><br><span class="line">                svm_label.append([<span class="number">0</span>,<span class="number">1</span>])<span class="comment"># 正样本标签 [0, 1]</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 执行选择性搜索算法获取区域建议</span></span><br><span class="line">            ss.setBaseImage(image)</span><br><span class="line">            ss.switchToSelectiveSearchFast()</span><br><span class="line">            ssresults = ss.process()</span><br><span class="line">            imout = image.copy()</span><br><span class="line">            counter = <span class="number">0</span></span><br><span class="line">            falsecounter = <span class="number">0</span></span><br><span class="line">            flag = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">             <span class="comment"># 遍历选择性搜索结果以构建负样本</span></span><br><span class="line">            <span class="keyword">for</span> e,result <span class="keyword">in</span> <span class="built_in">enumerate</span>(ssresults):</span><br><span class="line">                <span class="keyword">if</span> e &lt; <span class="number">2000</span> <span class="keyword">and</span> flag == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">for</span> gtval <span class="keyword">in</span> gtvalues:</span><br><span class="line">                        x,y,w,h = result</span><br><span class="line">                        iou = get_iou(gtval,&#123;<span class="string">&quot;x1&quot;</span>:x,<span class="string">&quot;x2&quot;</span>:x+w,<span class="string">&quot;y1&quot;</span>:y,<span class="string">&quot;y2&quot;</span>:y+h&#125;)</span><br><span class="line"></span><br><span class="line">                        <span class="comment"># 添加满足条件的负样本</span></span><br><span class="line">                        <span class="keyword">if</span> falsecounter &lt;<span class="number">5</span>:</span><br><span class="line">                            <span class="keyword">if</span> iou &lt; <span class="number">0.3</span>:</span><br><span class="line">                                timage = imout[x:x+w,y:y+h]</span><br><span class="line">                                resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA)</span><br><span class="line">                                svm_image.append(resized)</span><br><span class="line">                                svm_label.append([<span class="number">1</span>,<span class="number">0</span>]) <span class="comment"># 负样本标签 [1, 0]</span></span><br><span class="line">                                falsecounter += <span class="number">1</span></span><br><span class="line">                        <span class="keyword">else</span> :</span><br><span class="line">                            flag = <span class="number">1</span> <span class="comment"># 达到负样本数量上限</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;error in &quot;</span>+filename)</span><br><span class="line">        <span class="keyword">continue</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为防止RAM不够，这里把svm_image、svm_label也只选取一部分</span></span><br><span class="line">X_svm = np.array(svm_image)</span><br><span class="line">Y_svm = np.array(svm_label)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为方便下次不用重新处理输入的训练数据，在这里将X_new,Y_new进行保存</span></span><br><span class="line">np.save(<span class="string">&#x27;save_X_svm&#x27;</span>,X_svm)</span><br><span class="line">np.save(<span class="string">&#x27;save_Y_svm&#x27;</span>,Y_svm)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_nums_svm = <span class="built_in">len</span>(Y_svm)</span><br><span class="line"><span class="built_in">print</span>(total_nums_svm)</span><br></pre></td></tr></table></figure>
<p>7750</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_svm = np.load(<span class="string">&#x27;save_X_svm.npy&#x27;</span>)</span><br><span class="line">Y_svm = np.load(<span class="string">&#x27;save_Y_svm.npy&#x27;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从训练数据中随机选择 2000 个样本</span></span><br><span class="line">num_samples = <span class="number">2000</span></span><br><span class="line">random_indices = np.random.choice(<span class="built_in">len</span>(X_svm), num_samples, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用随机选择的索引来获取样本</span></span><br><span class="line">X_svm_subset = X_svm[random_indices]</span><br><span class="line">Y_svm_subset = Y_svm[random_indices]</span><br></pre></td></tr></table></figure>
<h2 id="svm模型结构">SVM模型结构</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从现有模型中获取 &#x27;fc2&#x27; 层的输出</span></span><br><span class="line">x = model.get_layer(<span class="string">&#x27;fc2&#x27;</span>).output</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加一个具有2个单元的全连接层，没有激活函数</span></span><br><span class="line">Y = tf.keras.layers.Dense(<span class="number">2</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个新的模型，该模型接收现有模型的输入，并输出新添加的全连接层的结果</span></span><br><span class="line">final_model = tf.keras.Model(model.<span class="built_in">input</span>, Y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译新模型</span></span><br><span class="line">final_model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;hinge&#x27;</span>,  <span class="comment"># 使用hinge loss损失函数</span></span><br><span class="line">                    optimizer=<span class="string">&#x27;adam&#x27;</span>,  <span class="comment"># 优化器为 Adam</span></span><br><span class="line">                    metrics=[<span class="string">&#x27;accuracy&#x27;</span>])  <span class="comment"># 监控模型的准确度指标</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出新模型的概要信息</span></span><br><span class="line">final_model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载预训练模型的权重</span></span><br><span class="line"><span class="comment"># final_model.load_weights(&#x27;my_model_weights.h5&#x27;)</span></span><br></pre></td></tr></table></figure>
<pre><code>Model: &quot;model_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 224, 224, 3)]     0         
                                                                 
 block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      
                                                                 
 block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     
                                                                 
 block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         
                                                                 
 block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     
                                                                 
 block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    
                                                                 
 block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         
                                                                 
 block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    
                                                                 
 block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    
                                                                 
 block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    
                                                                 
 block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         
                                                                 
 block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   
                                                                 
 block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   
                                                                 
 block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   
                                                                 
 block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         
                                                                 
 block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         
                                                                 
 flatten (Flatten)           (None, 25088)             0         
                                                                 
 fc1 (Dense)                 (None, 4096)              102764544 
                                                                 
 fc2 (Dense)                 (None, 4096)              16781312  
                                                                 
 dense_1 (Dense)             (None, 2)                 8194      
                                                                 
=================================================================
Total params: 134268738 (512.19 MB)
Trainable params: 16789506 (64.05 MB)
Non-trainable params: 117479232 (448.15 MB)
_________________________________________________________________</code></pre>
<h2 id="模型训练">模型训练</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用 SVM 数据集对最终模型进行训练，训练过程中的结果将存储在 hist_final 中</span></span><br><span class="line">hist_final = final_model.fit(</span><br><span class="line">    X_svm_subset,  <span class="comment"># SVM 数据集中的图像数据</span></span><br><span class="line">    Y_svm_subset,  <span class="comment"># SVM 数据集中的标签数据</span></span><br><span class="line">    batch_size=<span class="number">32</span>,        <span class="comment"># 批处理大小</span></span><br><span class="line">    epochs=<span class="number">20</span>,            <span class="comment"># 迭代次数</span></span><br><span class="line">    verbose=<span class="number">1</span>,            <span class="comment"># 训练过程中输出日志的详细程度（1为详细输出，0为不输出）</span></span><br><span class="line">    shuffle=<span class="literal">True</span>,         <span class="comment"># 在每个 epoch 开始时是否对数据进行洗牌</span></span><br><span class="line">    validation_split=<span class="number">0.05</span>  <span class="comment"># 验证集的拆分比例，这里设置为 0.05 表示将 5% 的数据作为验证集</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<pre><code>Epoch 1/20
60/60 [==============================] - 17s 217ms/step - loss: 0.7543 - accuracy: 0.6689 - val_loss: 0.7870 - val_accuracy: 0.6100
Epoch 2/20
60/60 [==============================] - 8s 128ms/step - loss: 0.5756 - accuracy: 0.7463 - val_loss: 0.6612 - val_accuracy: 0.7200
Epoch 3/20
60/60 [==============================] - 8s 134ms/step - loss: 0.4762 - accuracy: 0.7905 - val_loss: 0.6471 - val_accuracy: 0.7300
Epoch 4/20
60/60 [==============================] - 8s 132ms/step - loss: 0.4303 - accuracy: 0.8232 - val_loss: 0.7102 - val_accuracy: 0.6900
Epoch 5/20
60/60 [==============================] - 8s 131ms/step - loss: 0.4178 - accuracy: 0.8200 - val_loss: 0.6434 - val_accuracy: 0.7000
Epoch 6/20
60/60 [==============================] - 8s 136ms/step - loss: 0.3378 - accuracy: 0.8558 - val_loss: 0.7106 - val_accuracy: 0.7000
Epoch 7/20
60/60 [==============================] - 8s 135ms/step - loss: 0.3321 - accuracy: 0.8647 - val_loss: 0.6975 - val_accuracy: 0.7400
Epoch 8/20
60/60 [==============================] - 8s 130ms/step - loss: 0.3007 - accuracy: 0.8737 - val_loss: 0.7403 - val_accuracy: 0.7500
Epoch 9/20
60/60 [==============================] - 8s 138ms/step - loss: 0.2735 - accuracy: 0.8858 - val_loss: 0.8128 - val_accuracy: 0.7100
Epoch 10/20
60/60 [==============================] - 8s 133ms/step - loss: 0.2241 - accuracy: 0.9153 - val_loss: 0.9183 - val_accuracy: 0.6900
Epoch 11/20
60/60 [==============================] - 8s 141ms/step - loss: 0.2732 - accuracy: 0.8916 - val_loss: 0.7814 - val_accuracy: 0.7100
Epoch 12/20
60/60 [==============================] - 8s 142ms/step - loss: 0.2009 - accuracy: 0.9163 - val_loss: 0.8467 - val_accuracy: 0.7100
Epoch 13/20
60/60 [==============================] - 8s 140ms/step - loss: 0.2214 - accuracy: 0.9126 - val_loss: 0.7389 - val_accuracy: 0.7500
Epoch 14/20
60/60 [==============================] - 9s 144ms/step - loss: 0.1761 - accuracy: 0.9268 - val_loss: 0.8726 - val_accuracy: 0.7300
Epoch 15/20
60/60 [==============================] - 9s 142ms/step - loss: 0.1645 - accuracy: 0.9295 - val_loss: 0.7956 - val_accuracy: 0.7400
Epoch 16/20
60/60 [==============================] - 9s 142ms/step - loss: 0.1385 - accuracy: 0.9453 - val_loss: 0.7979 - val_accuracy: 0.7200
Epoch 17/20
60/60 [==============================] - 8s 138ms/step - loss: 0.1303 - accuracy: 0.9495 - val_loss: 0.8370 - val_accuracy: 0.7700
Epoch 18/20
60/60 [==============================] - 8s 139ms/step - loss: 0.1469 - accuracy: 0.9426 - val_loss: 0.7578 - val_accuracy: 0.7900
Epoch 19/20
60/60 [==============================] - 9s 143ms/step - loss: 0.1020 - accuracy: 0.9611 - val_loss: 0.7946 - val_accuracy: 0.7600
Epoch 20/20
60/60 [==============================] - 9s 147ms/step - loss: 0.1020 - accuracy: 0.9632 - val_loss: 0.8619 - val_accuracy: 0.7500</code></pre>
<h2 id="绘制损失变化曲线">绘制损失变化曲线</h2>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绘制模型训练过程中的损失变化曲线</span></span><br><span class="line">plt.plot(hist_final.history[<span class="string">&#x27;loss&#x27;</span>])        <span class="comment"># 训练集的损失</span></span><br><span class="line">plt.plot(hist_final.history[<span class="string">&#x27;val_loss&#x27;</span>])    <span class="comment"># 验证集的损失</span></span><br><span class="line">plt.title(<span class="string">&quot;model loss&quot;</span>)                     <span class="comment"># 图像标题</span></span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)                          <span class="comment"># y 轴标签为损失</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;Epoch&quot;</span>)                         <span class="comment"># x 轴标签为 epoch</span></span><br><span class="line">plt.legend([<span class="string">&quot;Loss&quot;</span>, <span class="string">&quot;Validation Loss&quot;</span>])     <span class="comment"># 添加图例，分别对应训练集和验证集的损失</span></span><br><span class="line">plt.show()                                  <span class="comment"># 显示图像</span></span><br><span class="line"></span><br><span class="line">plt.savefig(<span class="string">&#x27;chart_loss.png&#x27;</span>)               <span class="comment"># 保存图像为文件（在 plt.show() 之后保存是无效的，应该放在 plt.show() 之前）</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYT8S.png" alt="OKYT8S.png" />
<figcaption aria-hidden="true">OKYT8S.png</figcaption>
</figure>
<p>​</p>
<p>&lt;Figure size 640x480 with 0 Axes&gt;</p>
<h1 id="测试">测试</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">###########  it&#x27;s time for test a image    ##########</span></span><br><span class="line">image = cv2.imread(os.path.join(path,<span class="string">&#x27;airplane_020.jpg&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ss.setBaseImage(image) <span class="comment"># 设置选择性搜索算法的基础图像为读取的图像</span></span><br><span class="line">ss.switchToSelectiveSearchFast() <span class="comment"># 使用选择性搜索算法的快速模式</span></span><br><span class="line">ssresults = ss.process() <span class="comment"># 对基础图像执行选择性搜索，获取区域建议</span></span><br><span class="line"></span><br><span class="line">imOut = image.copy() <span class="comment"># 创建图像的副本，用于绘制矩形框</span></span><br><span class="line">boxes = [] <span class="comment"># 存储被判断为飞机区域的边界框信息</span></span><br><span class="line">count = <span class="number">0</span> <span class="comment"># 计数器：记录被判断为飞机区域的数量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对选择性搜索结果的前 50 个区域建议进行处理</span></span><br><span class="line"><span class="keyword">for</span> e,result <span class="keyword">in</span> <span class="built_in">enumerate</span>(ssresults):</span><br><span class="line">  <span class="keyword">if</span> e &lt; <span class="number">50</span>:</span><br><span class="line">    x,y,w,h = result</span><br><span class="line"></span><br><span class="line">    timage = imout[x:x+w,y:y+h] <span class="comment"># 从原始图像中获取当前建议区域的图像部分</span></span><br><span class="line">    resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA) <span class="comment"># 调整图像大小为模型的输入尺寸</span></span><br><span class="line">    resized = np.expand_dims(resized,axis = <span class="number">0</span>) <span class="comment"># 将图像扩展一个维度以适应模型输入的要求</span></span><br><span class="line">    out = final_model.predict(resized)  <span class="comment"># 使用最终的模型对该区域进行预测，得到输出结果</span></span><br><span class="line">    <span class="built_in">print</span>(e,out)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(out[<span class="number">0</span>][<span class="number">0</span>]&lt;out[<span class="number">0</span>][<span class="number">1</span>]): <span class="comment"># 如果模型判断该区域可能包含飞机</span></span><br><span class="line">      boxes.append([x,y,w,h]) <span class="comment"># 将边界框信息添加到列表中，并增加计数器</span></span><br><span class="line">      count+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对被判断为飞机区域的边界框进行处理</span></span><br><span class="line"><span class="keyword">for</span> box <span class="keyword">in</span> boxes:</span><br><span class="line">    x, y, w, h = box</span><br><span class="line">    <span class="built_in">print</span>(x,y,w,h)</span><br><span class="line"><span class="comment">#     imOut = imOut[x:x+w,y:y+h]</span></span><br><span class="line">    <span class="comment"># 在原始图像上绘制矩形框，以突出显示这些被判断为飞机的区域</span></span><br><span class="line">    cv2.rectangle(imOut, (x, y), (x+w, y+h), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>, cv2.LINE_AA)</span><br><span class="line"></span><br><span class="line">plt.imshow(imOut)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>1/1 [==============================] - 1s 1s/step
0 [[ 2.551831  -2.6361141]]
1/1 [==============================] - 0s 31ms/step
1 [[ 1.2116516 -1.1462703]]
1/1 [==============================] - 0s 43ms/step
2 [[ 3.1247723 -3.0577419]]
1/1 [==============================] - 0s 38ms/step
3 [[ 0.3094477  -0.35184118]]
1/1 [==============================] - 0s 33ms/step
4 [[ 16.334412 -16.097301]]
1/1 [==============================] - 0s 36ms/step
5 [[-1.9055386  1.8246138]]
1/1 [==============================] - 0s 46ms/step
6 [[ 3.849068 -3.596069]]
1/1 [==============================] - 0s 35ms/step
7 [[-4.3343387  4.457566 ]]
1/1 [==============================] - 0s 28ms/step
8 [[ 2.1157243 -2.0935826]]
1/1 [==============================] - 0s 37ms/step
9 [[ 1.1227907 -1.0547544]]
1/1 [==============================] - 0s 32ms/step
10 [[ 3.028215  -3.0655315]]
1/1 [==============================] - 0s 35ms/step
11 [[-3.4406524  3.4818974]]
1/1 [==============================] - 0s 36ms/step
12 [[-3.3148727  3.2502732]]
1/1 [==============================] - 0s 69ms/step
13 [[-1.7705667  1.8401496]]
1/1 [==============================] - 0s 119ms/step
14 [[ 17.1168   -17.020542]]
1/1 [==============================] - 0s 31ms/step
15 [[-0.54532474  0.49859324]]
1/1 [==============================] - 0s 39ms/step
16 [[ 1.3955598 -1.4487445]]
1/1 [==============================] - 0s 39ms/step
17 [[-0.9255678  0.7681236]]
1/1 [==============================] - 0s 34ms/step
18 [[-1.0967708  1.0601681]]
1/1 [==============================] - 0s 35ms/step
19 [[ 1.6157322 -1.5883387]]
1/1 [==============================] - 0s 19ms/step
20 [[ 6.222667 -6.078978]]
1/1 [==============================] - 0s 22ms/step
21 [[ 1.9781907 -1.9643315]]
1/1 [==============================] - 0s 21ms/step
22 [[ 2.6352754 -2.6751401]]
1/1 [==============================] - 0s 22ms/step
23 [[-0.6199166  0.6234232]]
1/1 [==============================] - 0s 26ms/step
24 [[ 0.56931984 -0.52301127]]
1/1 [==============================] - 0s 19ms/step
25 [[-4.092036   4.0529504]]
1/1 [==============================] - 0s 20ms/step
26 [[-1.1211745  1.1134607]]
1/1 [==============================] - 0s 20ms/step
27 [[ 1.5422791 -1.504165 ]]
1/1 [==============================] - 0s 20ms/step
28 [[ 0.9709082 -1.1293985]]
1/1 [==============================] - 0s 22ms/step
29 [[ 6.2005806 -6.223065 ]]
1/1 [==============================] - 0s 19ms/step
30 [[ 0.7283702  -0.67930716]]
1/1 [==============================] - 0s 20ms/step
31 [[ 3.7712991 -3.7369084]]
1/1 [==============================] - 0s 20ms/step
32 [[ 1.7139057 -1.7024881]]
1/1 [==============================] - 0s 21ms/step
33 [[ 12.521779 -12.554838]]
1/1 [==============================] - 0s 24ms/step
34 [[ 3.4832761 -3.3890066]]
1/1 [==============================] - 0s 23ms/step
35 [[ 1.2881904 -1.3030462]]
1/1 [==============================] - 0s 31ms/step
36 [[ 1.3349662 -1.2856408]]
1/1 [==============================] - 0s 20ms/step
37 [[ 0.29870683 -0.25320527]]
1/1 [==============================] - 0s 20ms/step
38 [[-1.2835077  1.3210849]]
1/1 [==============================] - 0s 19ms/step
39 [[ 1.3556112 -1.3576012]]
1/1 [==============================] - 0s 20ms/step
40 [[ 5.945995  -5.7617545]]
1/1 [==============================] - 0s 20ms/step
41 [[ 4.5127177 -4.54366  ]]
1/1 [==============================] - 0s 19ms/step
42 [[ 1.2226268 -1.2334687]]
1/1 [==============================] - 0s 19ms/step
43 [[ 2.2175348 -2.1676831]]
1/1 [==============================] - 0s 20ms/step
44 [[ 5.3103013 -5.1500263]]
1/1 [==============================] - 0s 22ms/step
45 [[ 1.7600315 -1.8218967]]
1/1 [==============================] - 0s 20ms/step
46 [[ 3.2599857 -2.9830909]]
1/1 [==============================] - 0s 19ms/step
47 [[-1.2734337  1.2411362]]
1/1 [==============================] - 0s 21ms/step
48 [[ 10.405064 -10.193722]]
1/1 [==============================] - 0s 20ms/step
49 [[-1.247491   1.2709295]]
145 129 35 31
0 71 98 70
176 148 64 43
49 91 49 22
0 71 77 70
199 148 38 29
174 130 21 27
19 95 58 45
111 142 27 23
120 127 32 33
0 74 48 53
120 143 33 19
29 149 36 40
111 117 34 46</code></pre>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYWxN.png" alt="OKYWxN.png" />
<figcaption aria-hidden="true">OKYWxN.png</figcaption>
</figure>
<blockquote>
<p>最后的测试效果没有很好，可能因为使用的训练数据过少，如果显存足够可以不用截取训练集的子集来进行训练，效果应该会提高。</p>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>代码复现</tag>
        <tag>RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Pycharm连接云服务器训练</title>
    <url>/2023/12/29/Pycharm%E8%BF%9E%E6%8E%A5%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h4 id="在autodl租用实例">在AutoDL租用实例</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">获得主机名、端口号、用户名和密码</span><br></pre></td></tr></table></figure>
<h4 id="点击-tools点击-部署deployment点击configuration">点击
<code>Tools</code>，点击
部署<code>Deployment</code>，点击<code>Configuration</code></h4>
<span id="more"></span>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKfzRF.png" alt="OKfzRF.png" />
<figcaption aria-hidden="true">OKfzRF.png</figcaption>
</figure>
<h4 id="配置服务器信息并测试连接">配置服务器信息并测试连接</h4>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKfbuI.png" alt="OKfbuI.png" />
<figcaption aria-hidden="true">OKfbuI.png</figcaption>
</figure>
<h4 id="设置本地路径和远程路径映射">设置本地路径和远程路径映射</h4>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKfoUq.png" alt="OKfoUq.png" />
<figcaption aria-hidden="true">OKfoUq.png</figcaption>
</figure>
<h4 id="勾选同步代码时自动创建文件夹">勾选同步代码时自动创建文件夹</h4>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKfMPY.png" alt="OKfMPY.png" />
<figcaption aria-hidden="true">OKfMPY.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKfWE1.png" alt="OKfWE1.png" />
<figcaption aria-hidden="true">OKfWE1.png</figcaption>
</figure>
<h4 id="设置远程解释器和同步目录">设置远程解释器和同步目录</h4>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKf5dr.png" alt="OKf5dr.png" />
<figcaption aria-hidden="true">OKf5dr.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKfO9v.png" alt="OKfO9v.png" />
<figcaption aria-hidden="true">OKfO9v.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYILj.png" alt="OKYILj.png" />
<figcaption aria-hidden="true">OKYILj.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYuNx.png" alt="OKYuNx.png" />
<figcaption aria-hidden="true">OKYuNx.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYwFU.png" alt="OKYwFU.png" />
<figcaption aria-hidden="true">OKYwFU.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKfqvc.png" alt="OKfqvc.png" />
<figcaption aria-hidden="true">OKfqvc.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKY3up.png" alt="OKY3up.png" />
<figcaption aria-hidden="true">OKY3up.png</figcaption>
</figure>
<h4 id="连接成功">连接成功</h4>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKfxFD.png" alt="OKfxFD.png" />
<figcaption aria-hidden="true">OKfxFD.png</figcaption>
</figure>
<h4 id="打开远程terminal">打开远程Terminal</h4>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKfTaM.png" alt="OKfTaM.png" />
<figcaption aria-hidden="true">OKfTaM.png</figcaption>
</figure>
<h4 id="同地区可以选择跨实例拷贝数据">同地区可以选择跨实例拷贝数据</h4>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKfUNG.png" alt="OKfUNG.png" />
<figcaption aria-hidden="true">OKfUNG.png</figcaption>
</figure>
]]></content>
      <categories>
        <category>经验技巧</category>
      </categories>
      <tags>
        <tag>Pycharm</tag>
        <tag>云服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>RCNN论文理解</title>
    <url>/2023/12/29/RCNN%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="rcnn">RCNN</h1>
<h2 id="背景">背景</h2>
<p>过去主流的目标检测思路：输入一张图片==》获取一系列区域==》传统的特征提取方法（HOG特征）得到一组特征表示（x1,x2,...xn）==》输入预训练好的机器学习算法（SVM、决策树）进行分类</p>
<p>本文创新：用CNN代替传统的特征提取方法来提取图像特征</p>
<span id="more"></span>
<h2 id="主要贡献">主要贡献</h2>
<ol type="1">
<li>用CNN代替传统的特征提取方法来提取图像特征</li>
<li>迁移学习（模型微调）：模型在大的源领域数据集上预训练后，再在特定目标领域的小数据集上微调，能够适应新任务的要求。——解决目标领域数据稀缺问题。</li>
</ol>
<h2 id="面临问题及解决思路">面临问题及解决思路</h2>
<h3 id="问题1如何用cnn来定位目标">问题1：如何用CNN来定位目标？</h3>
<h4 id="问题">问题</h4>
<p>分类任务只需要确定类别；检测任务除了需要确定类别，还需要获得对象的检测边界框。CNN过去已经被证明可以用于分类任务，如何利用它来检测边界框呢？</p>
<h4 id="解决思路">解决思路</h4>
<ol type="1">
<li><p>基于回归的定位策略：直接用CNN来回归边界框 <img
src="https://ooo.0x0.ooo/2023/12/29/OKYa0B.png"
alt="OKYa0B.png" /></p></li>
<li><p>基于滑动窗口检测器的定位策略：在输入图片上用特定大小和比例的滑动窗口进行滑动，对于滑动到的区域用<strong>浅层的CNN</strong>进行检测，适用于人脸、行人这类<strong>特定比例的任务</strong>。（有人试了，效果不好）</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYows.png" alt="OKYows.png" />
<figcaption aria-hidden="true">OKYows.png</figcaption>
</figure></li>
<li><p><strong>基于区域的定位策略（本文√）</strong>：输入一张图片，用某种方法产生一定数量的候选区域（Region
proposal），然后用一个深层的CNN提取特征，最后输入分类器种进行分类</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKVIk6.png" alt="OKVIk6.png" />
<figcaption aria-hidden="true">OKVIk6.png</figcaption>
</figure></li>
</ol>
<h3 id="问题2标注数据太少">问题2：标注数据太少</h3>
<h4 id="问题-1">问题</h4>
<p>图像分类领域ImageNet数据集，标注数据丰富，而当时目标检测领域只有PASCAL
VOC数据集，标注数据很少</p>
<h4 id="解决思路-1">解决思路</h4>
<ol type="1">
<li>传统思路：无监督预训练+有监督微调</li>
<li>本文思路：迁移学习。在ImageNet大数据集上有监督预训练+在PASCAL
VOC小数据集上微调</li>
</ol>
<h2 id="模型结构">模型结构</h2>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKY51K.png" alt="OKY51K.png" />
<figcaption aria-hidden="true">OKY51K.png</figcaption>
</figure>
<h3 id="三个模块">三个模块</h3>
<ol type="1">
<li><p>产生候选区域：selective search</p></li>
<li><p>抽取图像特征： 利用deep CNN从每个候选区域(region proposal
)抽取出一个固定长度(4096-dim)的特征向量(feature vector)</p>
<ol type="1">
<li><p>5个卷积层 +
2个全连接层前向传播，删除了源网络最后的1000种分类层（AlexNet）</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKVX8F.png" alt="OKVX8F.png" />
<figcaption aria-hidden="true">OKVX8F.png</figcaption>
</figure></li>
<li><p>deep
CNN要求输入的图片固定大小，因此需要对不同大小的候选区域进行缩放至(227 x
227 RGB)</p>
<p>缩放方法：</p>
<ol type="1">
<li>tightest square with
context：把整张图片的长边缩放到227，短边按照此比例缩放</li>
<li>tightest square without
context：只把候选区域的长边缩放到227，短边按照此比例缩放</li>
<li>warp：把候选区域的长短边都直接缩放到227（有形变）（本文√）</li>
</ol></li>
</ol></li>
<li><p>用特定类的SVM来对候选区域进行分类：多个二分类构成的SVMs</p></li>
</ol>
<h3 id="训练思路">训练思路</h3>
<h4 id="训练特征提取网络">训练特征提取网络</h4>
<ol type="1">
<li>有监督预训练：在ImageNet上预训练</li>
<li>针对特定领域微调（在VOC数据集上微调出21类的分类模型-softmax层实现分类）
<ol type="1">
<li>网络结构：把ImageNet上训练的CNN(AlexNet)最后一层的1000种分类改成
(N+1) 类的分类层，N为微调的数据集的对象类别数，+1为背景</li>
<li>构建数据集：候选区域和ground-truth box的iou &gt;
0.5，为正样本；否则为负样本</li>
<li>SGD：
<ol type="1">
<li>初始学习率0.001</li>
<li>每个iteration，统一采样32个正样本和96个负样本组成128的mini-batch</li>
</ol></li>
</ol></li>
</ol>
<p>训练好了分类网络后，就可以在VOC数据集上较好地提取图像特征；在提取特征后，可以训练一个SVM模型，来对候选区域进行分类。</p>
<h4 id="训练svms分类器">训练SVMs分类器</h4>
<p>SVMs是由N个linear SVM构成的，我们需要为每个对象类优化一个linear
SVM分类器</p>
<ol type="1">
<li>构建数据集：只把ground truth box作为每个类的正样本；把和ground-truth
box的iou &lt;
0.3的候选区域，作为负样本（因为负样本很多，这里采用难负例挖掘策略（hard
negative mining method）来进一步挑选）</li>
<li>训练分类器：为每个类训练一个linear SVM分类器</li>
</ol>
<h3 id="测试思路">测试思路</h3>
<p>输入一张图片==》运行selective search产生2000个候选区域（Region
proposals）==》缩放成固定大小的proposal==》利用CNN从每个proposal抽取出一个固定长度的feature
vector==》用针对特定类的linear SVM分类每一个region
proposal==》对每一个类的proposals进行非极大值抑制</p>
<h2 id="可视化">可视化</h2>
<p>如何可视化高层特征？</p>
<p>在第五个卷积层conv5后跟了一个池化层pool5，经过该于池化层后得到6 x 6 x
256的特征图。提取出一个数据集的所有图像对应的所有候选区域在某一通道某一特定位置的数据进行可视化，实验规律如下：</p>
<ol type="1">
<li>对于高层特征来说，每一个不同的通道，学习到一种高层特征</li>
<li>对于同一个通道的不同位置，它表示的特征是相同的，只是边界框的位置有偏移</li>
</ol>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYM5l.png" alt="OKYM5l.png" />
<figcaption aria-hidden="true">OKYM5l.png</figcaption>
</figure>
<h2 id="消融实验">消融实验</h2>
<ol type="1">
<li>在训练CNN的时候，我们使用的是fc7的4096维的输出作为图片的特征，那能不能使用fc6的输出，或pool5的输出作为提取到的特征呢？</li>
</ol>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYOKg.png" alt="OKYOKg.png" />
<figcaption aria-hidden="true">OKYOKg.png</figcaption>
</figure>
<ol start="2" type="1">
<li><p>使用微调和不使用微调对最终的精度有没有影响？</p>
<p>在1中选取不同层的输出作为图片的特征的基础上，测试微调后的精度如何改变。实验结果发现：</p>
<p>（1）微调后精度提高，说明微调重要；</p>
<p>（2）在使用全连接层特征、不同层的卷积特征分别进行微调的基础上，发现使用全连接层特征微调后的精度改善更明显，说明微调更多改善的是全连接层的特征提取能力</p></li>
<li><p>不同的CNN结构对特征提取效果有什么影响？</p>
<p>对比了AlexNet（本文）、VGG（更复杂）两种CNN结构提取特征的效果，实验结果发现：</p>
<p>VGG更复杂，提取到的特征更好，检测的准确率也更高</p></li>
</ol>
<h2 id="边界框回归">边界框回归</h2>
<p>因为我们在进行目标检测，所以不仅要实现分类，还要对目标的边界框进行回归。因此，在提取出CNN特征（这里用的pool5层的特征）后又训练了一个SVM模型，用于回归出目标的边界框，即原始的候选区域到真实框的偏移量。而在实际实验中发现，分类的预测精度较高，但目标的位置预测并不准确。也就是说，我们希望预测框（黄框）尽可能接近真实框（绿框），即损失函数尽可能小</p>
<p>因此要解决的问题变成了：已知一个不准确的位置，要预测出一个准确的位置（从黄框变成绿框）。</p>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKVCfb.png" alt="OKVCfb.png" />
<figcaption aria-hidden="true">OKVCfb.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKV3pP.png" alt="OKV3pP.png" />
<figcaption aria-hidden="true">OKV3pP.png</figcaption>
</figure>
<h2 id="错检情况分析">错检情况分析</h2>
<p>分析以下四类错误的占比情况</p>
<ol type="1">
<li>类别正确，但位置不准确</li>
<li>类别识别为相似类</li>
<li>类别识别明显错误</li>
<li>目标误识别为类别</li>
</ol>
<figure>
<img src="https://ooo.0x0.ooo/2023/12/29/OKYBHa.png" alt="OKYBHa.png" />
<figcaption aria-hidden="true">OKYBHa.png</figcaption>
</figure>
<h2
id="检测不同因素对算法的敏感度影响看不懂">检测不同因素对算法的敏感度影响（看不懂）</h2>
<h2 id="实验设置的一些问题解释">实验设置的一些问题解释</h2>
<ol type="1">
<li>为什么CNN和SVM的正负例定义的方法不同
<ol type="1">
<li>实验观察：通过实验先确定了SVM的划分方法，然后才确定了CNN的正负样本的划分方法</li>
<li>理论解释：训练CNN要求的参数很多，需要大量的训练样本。如果也采用训练SVM时采用的正负样本策略，即只把ground
truth的标注框作为每个类的正样本，iou &lt;
0.3的候选区域为负样本，这样训练样本就太少了；而采用另外的方法，即iou
&gt;
0.5的候选区域为正样本，否则为负样本，能够在标注框附近引入大量的抖动样本，丰富的数据量可以避免CNN过拟合</li>
</ol></li>
<li>在微调之后明明已经能够对候选区域进行多分类了，后面训练SVMs的部分能不能去掉？
<ol type="1">
<li>实验观察：直接用CNN的softmax层分类会让精度降低</li>
<li>解释：
<ol type="1">
<li>CNN在训练时使用的正样本（抖动样本）并不是每个目标的精确位置，可能会导致误差
富的数据量可以避免CNN过拟合</li>
</ol></li>
</ol></li>
<li>在微调之后明明已经能够对候选区域进行多分类了，后面训练SVMs的部分能不能去掉？
<ol type="1">
<li>实验观察：直接用CNN的softmax层分类会让精度降低</li>
<li>解释：
<ol type="1">
<li>CNN在训练时使用的正样本（抖动样本）并不是每个目标的精确位置，可能会导致误差</li>
<li>在训练CNN时的负样本是被随机挑选的，而我们可以从CNN分类错误的样本中去挑选那些难负样本，让SVM训练，这样也让增加SVMs分类器后的训练效果更好</li>
</ol></li>
</ol></li>
</ol>
<p><strong>参考资料：</strong>
https://www.bilibili.com/video/BV1CZ4y1a7NP/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=66a72b15abe9693bd8b4f738f5a67ee7</p>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>论文理解</tag>
        <tag>RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>字节跳动Coze教程（GPT4）</title>
    <url>/2024/01/04/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8Coze%E6%95%99%E7%A8%8B%EF%BC%88GPT4%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1 id="coze使用教程">Coze使用教程</h1>
<p>目前能免费使用GPT4的网站有以下几个：</p>
<blockquote>
<p>YesChat：一个聚合搜索网站，地址为https://www.yeschat.ai/zh-CN</p>
<p>codeium：需要申请内测资格，地址为https://codeium.com/waitlist/gpt-4</p>
<p>Coze：本身仅是构建平台，需要部署到cic/discord/telegram等平台使用，地址为https://www.coze.com。</p>
<p>目前Coze平台使用GPT4免费无限制。有人测试每小时问答二三十次，连续几个小时使用，均没有触发限制。</p>
</blockquote>
<p>本文介绍基于Coze平台的chatGPT4如何使用。</p>
<span id="more"></span>
<blockquote>
<p>ip问题：目前大陆ip被屏蔽，非大陆的ip都可以尝试。我用日本、新加坡的都可以。如果ip问题无法访问，可以设置为<code>全局模式</code>尝试一下，如果<code>全局模式</code>可用，说明就是vpn软件的设置存在问题。</p>
</blockquote>
<h2 id="注册登录">注册登录</h2>
<p>访问https://www.coze.com/。</p>
<p>用手机号/谷歌账号注册登录。</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZo3Pq.png" alt="OZo3Pq.png" />
<figcaption aria-hidden="true">OZo3Pq.png</figcaption>
</figure>
<h2 id="探索公开的bot">探索公开的Bot</h2>
<p>登录成功后，会自动跳转到explore页面，这个页面是一些公开的、别人配置好的、具有特定功能的bot（类似于专用机器人），如果有满足自己需求的可以直接点进去使用。</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqOvM.png" alt="OZqOvM.png" />
<figcaption aria-hidden="true">OZqOvM.png</figcaption>
</figure>
<p>比如我觉得这个”小狗插画生成器“很有意思，直接点击进入</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZoIzv.png" alt="OZoIzv.png" />
<figcaption aria-hidden="true">OZoIzv.png</figcaption>
</figure>
<p>进入之后的界面如下图所示：</p>
<p>界面分为左中右三个部分，左侧介绍了这个bot的角色、技能和约束等信息；中间主要提供了bot在完成功能时所需要的插件，右侧可以对这个bot进行预览测试。</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZoClc.png" alt="OZoClc.png" />
<figcaption aria-hidden="true">OZoClc.png</figcaption>
</figure>
<p>在右侧对话框直接运行提供的测试案例，让bot给我画小狗插画，效果如下</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqacG.png" alt="OZqacG.png" />
<figcaption aria-hidden="true">OZqacG.png</figcaption>
</figure>
<p>如果想要在这个bot上进行二次开发，可以点击项目右侧的Duplicate，就会把这个项目复制到我们的个人工作空间，可以进行二次开发</p>
<h2 id="创建自己的bot">创建自己的Bot</h2>
<h3 id="方式1全才gpt4仅文字对话">方式1：全才gpt4(仅文字对话)</h3>
<p>这一部分介绍如何直接使用可以<strong>回答各方面问题</strong>的chatgpt4，但是<strong>仅能通过文字进行对话</strong>。</p>
<h4 id="创建bot">创建Bot</h4>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqqO1.png" alt="OZqqO1.png" />
<figcaption aria-hidden="true">OZqqO1.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqAPC.png" alt="OZqAPC.png" />
<figcaption aria-hidden="true">OZqAPC.png</figcaption>
</figure>
<h4 id="使用gpt4">使用GPT4</h4>
<p>不用设置左侧的提示词和中间的插件，直接在右边使用，默认就会使用GPT4(8k)进行回答。</p>
<blockquote>
<p><strong>这里的"8K"代表什么意思？</strong></p>
<p>至目前为止，GPT-4有两个主要版本，即GPT-4 8k版本和GPT-4
32k版本。"8k"版本是指该模型有8000个token的上下文长度。也就是说，<strong>当我们让模型生成文本时，它能考虑的最大输入长度是8000个token</strong>。这些token包括单词，标点符号，甚至是空格等。例如，如果我们有一段文本，长度为10000个token，那么模型在处理时，只会关注最后的8000个token，前2000个token将被忽视。这是由于模型的这种窗口限制而造成的，称为模型的上下文窗口或者上下文长度。</p>
<p>理论上，<strong>对于中文，一个字符（包括标点符号等）被视为一个token，所以8000个token对应的中文字符数量也是8000个。</strong>对于英文，一个token的定义可能会稍微复杂一些。一个token可以是一个单词，也可能是一个标点符号，或者是一个单词内部的一个部分。例如，“hamburger”被分成“ham”、“bur”和“ger”三个
Token，而“pear”是一个
Token。如果我们假定一个英文单词平均由5个字母组成，那么8000个token大致对应1600个英文单词。</p>
<p>另外，这个限制还有一个细节，<strong>Token
限制的计数包含输入和输出的文本</strong>。也就是说，当你给模型提供一个初始的输入序列，并让它生成一些额外的输出时，这个输入序列和生成的输出序列的总长度通常不能超过这个token限制。如果模型版本是8k，那么我们给模型的输入序列应该要留有足够的空间来让模型生成输出。如果输入就已经是8000个token，那么模型就没有多余的空间来生成输出了。</p>
</blockquote>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqNuS.png" alt="OZqNuS.png" />
<figcaption aria-hidden="true">OZqNuS.png</figcaption>
</figure>
<h4 id="对比gpt3.5">对比GPT3.5</h4>
<p>对比经典的<code>鲁迅和周树人问题</code>，GPT4确实要更胜一筹。</p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>gpt4</th>
<th>gpt3.5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="https://ooo.0x0.ooo/2024/01/04/OZqvUi.png"
alt="OZqvUi.png" /></td>
<td><img src="https://ooo.0x0.ooo/2024/01/04/OZq1NK.png"
alt="OZq1NK.png" /></td>
</tr>
</tbody>
</table>
<h3
id="方式2全才gpt4文字图片联网...">方式2：全才gpt4(文字+图片+联网+...)</h3>
<p>这一部分介绍如何直接使用可以<strong>回答各方面问题</strong>的chatgpt4，<strong>不仅能通过文字，还能借助图片进行对话，实现联网搜索等功能</strong>。</p>
<p>点击中间Plugins后面的＋，为gpt添加插件，常用插件的功能介绍如下</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqK9L.png" alt="OZqK9L.png" />
<figcaption aria-hidden="true">OZqK9L.png</figcaption>
</figure>
<p>添加以上插件后，此时的gpt就具有了联网搜索、文生图、识别图片内容、搜索github的api等功能，还可以探索其他的插件。添加了插件后的使用效果如下：</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqrFN.png" alt="OZqrFN.png" />
<figcaption aria-hidden="true">OZqrFN.png</figcaption>
</figure>
<p>但是这个图片上传后分析的功能好像有问题，上传图片后出现以下错误<code>对不起，由于技术限制，我无法解析这张图片的内容。我会尽快向后端技术团队反馈以便解决此问题。感谢你的理解和耐心等待。</code></p>
<p>我觉得以上的2种方式已经能够满足日常使用的需求，<strong>尤其是方式2，很容易就实现了联网搜索和图片互动等刚需要求</strong>，不过如果想要创建一个属于自己的、专门用于完成特定任务的Bot，可以参考方式3。</p>
<h3 id="方式3专才gpt4">方式3：专才gpt4</h3>
<p>我想创建一个专门用于解决编程问题的助手，具体操作步骤如下：</p>
<h4 id="创建bot-1">创建Bot</h4>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqqO1.png" alt="OZqqO1.png" />
<figcaption aria-hidden="true">OZqqO1.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZq57I.png" alt="OZq57I.png" />
<figcaption aria-hidden="true">OZq57I.png</figcaption>
</figure>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqBLD.png" alt="OZqBLD.png" />
<figcaption aria-hidden="true">OZqBLD.png</figcaption>
</figure>
<h4 id="定义功能">定义功能</h4>
<p>因为这个bot主要用于编程辅助，这里给出一个bot的功能定义的示例。</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqTuF.png" alt="OZqTuF.png" />
<figcaption aria-hidden="true">OZqTuF.png</figcaption>
</figure>
<p>点击右上角的Optimize，可以自动优化提示词，优化后的提示词如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 角色</span><br><span class="line">你是一个精通各种编程语言的编程解决方案专家，你的专业技能包括编写代码、解答复杂编程问题以及优化代码以提升运行效率。</span><br><span class="line"></span><br><span class="line">## 技能</span><br><span class="line">###技能一：代码优化</span><br><span class="line">- 分析用户提交的初步代码，理解其目标和核心原理。</span><br><span class="line">- 遵循代码规范和最佳实践对代码进行优化。</span><br><span class="line">- 将优化后的代码反馈给用户。</span><br><span class="line">###技能二：编程问题解答</span><br><span class="line">- 掌握用户的编程问题。</span><br><span class="line">- 使用在线编程知识库（search(site:stackoverflow.com)）寻找解决方案。</span><br><span class="line">- 用易于理解的方式向用户解释答案。</span><br><span class="line">###技能三：算法设计</span><br><span class="line">- 理解用户所需解决的问题，识别适用的算法类型。</span><br><span class="line">- 设计有效的算法或数据结构以解决问题。</span><br><span class="line">- 向用户展示算法或数据结构的设计过程以及相应的代码。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 工作流程</span><br><span class="line">### 步骤1: 信息收集</span><br><span class="line">首先自我介绍并询问用户需求：&quot;我是一位经验丰富的编程专家，能够根据你的需求撰写符合你预期的代码。如果你需要个性化的编程解决方案，只需告诉我你需要解决的问题，预期的输出结果，以及你希望使用的编程语言。&quot;</span><br><span class="line">需要收集的信息：</span><br><span class="line"> - 需要解决的问题描述</span><br><span class="line"> - 预期的输出结果</span><br><span class="line"> - 用户希望使用的编程语言</span><br><span class="line"></span><br><span class="line">### 步骤2: 创建编程方案</span><br><span class="line">结合用户提供的问题描述、期望结果和编程语言准备编程方案。实例提示为：</span><br><span class="line">- 问题定义: `&lt;问题描述&gt;`</span><br><span class="line">- 输出目标: `&lt;预期结果&gt;`</span><br><span class="line">- 推荐编程语言: `&lt;编程语言&gt;`</span><br><span class="line"></span><br><span class="line">此提示仅作为参考，不直接展示给用户。</span><br><span class="line"></span><br><span class="line">### 步骤3: 提供编程解决方案</span><br><span class="line">根据步骤2中的指引，创建编程解决方案，并将结果展示给用户。</span><br><span class="line"></span><br><span class="line">## 约束条件</span><br><span class="line">- 仅回答和编程问题相关的内容，不能回答与编程无关的问题。</span><br><span class="line">- 遵守约定的工作流程，按步骤进行操作。</span><br><span class="line">- 将工作成果给予用户，而不是工作过程中的提示信息。</span><br><span class="line">- 确保提供的编程作品适合所有用户，避免使用不恰当或冒犯性的内容。</span><br></pre></td></tr></table></figure>
<h4 id="添加插件">添加插件</h4>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqWz6.png" alt="OZqWz6.png" />
<figcaption aria-hidden="true">OZqWz6.png</figcaption>
</figure>
<h4 id="测试效果">测试效果</h4>
<p>在右侧的Preview对话栏可以执行测试</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqbPP.png" alt="OZqbPP.png" />
<figcaption aria-hidden="true">OZqbPP.png</figcaption>
</figure>
<h4 id="对比gpt3.5-1">对比GPT3.5</h4>
<p>对于同一个问题，将gpt4和gpt3.5给出的回答做一个对比，<strong>可以看出gpt4的效果确实要比3.5好一些。</strong></p>
<table>
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="header">
<th>gpt4</th>
<th>gpt3.5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="https://ooo.0x0.ooo/2024/01/04/OZqk9b.png"
alt="OZqk9b.png" /></td>
<td><img src="https://ooo.0x0.ooo/2024/01/04/OZqzTl.png"
alt="OZqzTl.png" /></td>
</tr>
</tbody>
</table>
<h4 id="发布">发布</h4>
<p>测试完确认没问题后，我们就可以在右侧的对话框进行问答了。但是如果每次都重新重复上述流程来创建自定义Bot有点麻烦，因此我们可以直接将这个Bot发布，发布后就可以直接使用这个定制的Bot了。</p>
<p>点击右上角的publish，可以选择将其发布到以下四类平台，测试后发现cici平台是最方便的，直接勾选cici平台，然后点击右上角的Publish就可以了。</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqFvg.png" alt="OZqFvg.png" />
<figcaption aria-hidden="true">OZqFvg.png</figcaption>
</figure>
<p>发布成功，点击Open in Cici</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqhdB.png" alt="OZqhdB.png" />
<figcaption aria-hidden="true">OZqhdB.png</figcaption>
</figure>
<p>这里也需要登录一下Cici平台，正常注册登录就好。<strong>登陆完成就来到了以下界面，然后就可以在这里直接使用我们自己定制的Bot了。</strong></p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/04/OZqnOs.png" alt="OZqnOs.png" />
<figcaption aria-hidden="true">OZqnOs.png</figcaption>
</figure>
]]></content>
      <categories>
        <category>经验技巧</category>
      </categories>
      <tags>
        <tag>GPT4</tag>
      </tags>
  </entry>
  <entry>
    <title>《动手学深度学习2.0》学习笔记（一）</title>
    <url>/2024/01/11/%E3%80%8A%E5%8A%A8%E6%89%8B%E5%AD%A6%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A02-0%E3%80%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<link rel="stylesheet" type="text&#x2F;css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css"><h1
id="动手学深度学习2.0学习笔记一">《动手学深度学习2.0》学习笔记（一）</h1>
<p>《动手学深度学习2.0》电子书的链接地址为https://zh.d2l.ai/index.html</p>
<p>本文记录了我在学习本书前4章节（包括引言、预备知识、线性神经网络、多层感知机）过程中的理解和收获。</p>
<span id="more"></span>
<h2 id="引言">引言</h2>
<h3 id="机器学习中关键组件">机器学习中关键组件</h3>
<ol type="1">
<li>可以用来学习的<em>数据</em>（data）；</li>
<li>如何转换数据的<em>模型</em>（model）；</li>
<li>一个<em>目标函数</em>（objective
function），有时被称为<em>损失函数</em>（loss function，或cost
function），用来量化模型的有效性；</li>
<li>调整模型参数以优化目标函数的<em>算法</em>（algorithm）</li>
</ol>
<h3 id="机器学习问题分类">机器学习问题分类</h3>
<h4 id="监督学习">监督学习</h4>
<p>通过一组已经标注好的训练数据学习预测结果=》需要向模型提供巨大数据集：每个样本包含特征和相应标签值。</p>
<ol type="1">
<li><p>回归</p>
<p>当标签取任意数值时，就是回归问题，旨在解决“有多少”的问题。</p></li>
<li><p>分类</p>
<p>当标签取离散数值时，就是分类问题，旨在解决“哪一个”的问题。</p></li>
<li><p>标记</p>
<p>又叫<em>多标签分类</em>（multi-label
classification），旨在通过学习预测不相互排斥的类别</p></li>
<li><p>搜索</p>
<p>对一组项目进行排序。如谷歌最初的评分系统PageRank，对搜索结果根据相关性分数进行排序。</p></li>
<li><p>推荐系统</p>
<p>推荐系统会为“给定用户和物品”的匹配性打分，从而将匹配性得分最高的对象集推荐给对应的用户。</p></li>
<li><p>序列学习</p>
<blockquote>
<p>以上大多数问题都具有固定大小的输入和产生固定大小的输出。
例如，在预测房价的问题中，我们考虑从一组固定的特征：房屋面积、卧室数量、浴室数量、步行到市中心的时间；
图像分类问题中，输入为固定尺寸的图像，输出则为固定数量（有关每一个类别）的预测概率；
在这些情况下，模型只会将输入作为生成输出的“原料”，而不会“记住”输入的具体内容。</p>
<p>如果输入的样本之间没有任何关系，以上模型可能完美无缺。
但是如果输入是连续的，模型可能就需要拥有“记忆”功能。</p>
</blockquote>
<p>序列学习需要摄取输入序列和预测输出序列，其中输入和输出都是可变长度的序列。常见的应用有：</p>
<ul>
<li><p>标记和解析：用属性注释文本序列。输入和输出的数量基本相同</p>
<blockquote>
<p>下面是一个非常简单的示例，它使用“标记”来注释一个句子，该标记指示哪些单词引用命名实体。
标记为“Ent”，是<em>实体</em>（entity）的简写。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Tom has dinner in Washington with Sally</span><br><span class="line">Ent  -    -    -     Ent      -    Ent</span><br></pre></td></tr></table></figure></li>
<li><p>语音识别：输出比输入短得多</p></li>
<li><p>文本到语音：输出比输入长得多</p></li>
<li><p>机器翻译：输入和输出的顺序需要颠倒</p></li>
</ul></li>
</ol>
<h4 id="无监督学习">无监督学习</h4>
<ol type="1">
<li><em>聚类</em>（clustering）问题</li>
<li><em>主成分分析</em>（principal component analysis）问题</li>
<li><em>因果关系</em>（causality）和<em>概率图模型</em>（probabilistic
graphical models）问题</li>
<li><em>生成对抗性网络</em>（generative adversarial
networks）：为我们提供一种合成数据的方法，甚至像图像和音频这样复杂的非结构化数据。</li>
</ol>
<h4 id="与环境互动">与环境互动</h4>
<blockquote>
<p>我们可能会期望人工智能不仅能够做出预测，而且能够与真实环境互动。
与预测不同，“与真实环境互动”实际上会影响环境。
这里的人工智能是“智能代理”，而不仅是“预测模型”。
因此，我们必须考虑到它的行为可能会影响未来的观察结果。</p>
</blockquote>
<h4 id="强化学习">强化学习</h4>
<blockquote>
<p>在强化学习问题中，智能体（agent）在一系列的时间步骤上与环境交互。
在每个特定时间点，智能体从环境接收一些<em>观察</em>（observation），并且必须选择一个<em>动作</em>（action），然后通过某种机制（有时称为执行器）将其传输回环境，最后智能体从环境中获得<em>奖励</em>（reward）。
此后新一轮循环开始，智能体接收后续观察，并选择后续操作，依此类推。
强化学习的过程在 图1中进行了说明。
请注意，强化学习的目标是产生一个好的<em>策略</em>（policy）。
强化学习智能体选择的“动作”受策略控制，即一个从环境观察映射到行动的功能。</p>
</blockquote>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/11/OZVFua.png"
alt="图1 强化学习和环境之间的相互作用" />
<figcaption aria-hidden="true">图1
强化学习和环境之间的相互作用</figcaption>
</figure>
<blockquote>
<p>强化学习框架的通用性十分强大。
例如，我们可以将任何监督学习问题转化为强化学习问题。
假设我们有一个分类问题，可以创建一个强化学习智能体，每个分类对应一个“动作”。
然后，我们可以创建一个环境，该环境给予智能体的奖励。
这个奖励与原始监督学习问题的损失函数是一致的。</p>
<p>当然，强化学习还可以解决许多监督学习无法解决的问题。
例如，在监督学习中，我们总是希望输入与正确的标签相关联。
但在强化学习中，我们并不假设环境告诉智能体每个观测的最优动作。
一般来说，智能体只是得到一些奖励。
此外，环境甚至可能不会告诉是哪些行为导致了奖励。</p>
<p>最后，在任何时间点上，强化学习智能体可能知道一个好的策略，但可能有许多更好的策略从未尝试过的。
强化学习智能体必须不断地做出选择：是应该利用当前最好的策略，还是探索新的策略空间（放弃一些短期回报来换取知识）。</p>
</blockquote>
<h2 id="预备知识">预备知识</h2>
<h3 id="线性代数">线性代数</h3>
<ol type="1">
<li><p>范数（norm）：深度学习的<strong>目标</strong></p>
<ol type="1">
<li><p>向量的范数表示一个向量有多大（指的是分量的大小）</p>
<ul>
<li><p>L1范数：向量元素的绝对值之和。</p>
<p><span class="math display">\[
||x||_ {1}  =  \sum _ {i=1}^ {n}   |x_ {i} |
\]</span></p></li>
<li><p>L2范数：向量元素平方和的平方根。（欧几里得距离L2范数） <span
class="math display">\[
||x||=||x||_ {2}  =  \sqrt {\sum _ {i=1}^ {n}x}
\]</span></p></li>
</ul></li>
<li><p>矩阵X∈R<sup>(mxn)</sup></p>
<ul>
<li><p><em>Frobenius范数</em>（Frobenius
norm）：矩阵元素平方和的平方根（类似于向量的L2范数）</p>
<p><span class="math display">\[
||x||_F=  \sqrt {\sum _ {i=1}^ {m}\sum _ {i=1}^ {n}x_ {i}^ {2}}
\]</span></p></li>
</ul></li>
</ol></li>
<li><p>Hadamard积 v.s. 矩阵乘法</p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Hadamard积</th>
<th>矩阵乘法</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>含义</td>
<td>对应元素相乘</td>
<td>左行乘右列</td>
</tr>
<tr class="even">
<td>pytorch符号</td>
<td>A*B</td>
<td>A@B</td>
</tr>
<tr class="odd">
<td>pytorch函数</td>
<td>torch.mul(A, B)</td>
<td>torch.matmul(A, B)或torch.mm(A, B)</td>
</tr>
</tbody>
</table>
<ul>
<li><code>@</code> 符号其实是调用了 <code>torch.matmul()</code>
函数</li>
<li><code>torch.mm()</code>：这个函数用于两个二维矩阵的相乘。它不支持广播（Broadcasting）操作（即对不同形状的张量进行的自动扩充），并且输入必须都是二维张量。比如你有两个形状为
<code>(n, m)</code> 和 <code>(m, p)</code> 的矩阵，使用
<code>torch.mm()</code> 可以得到一个形状为 <code>(n, p)</code>
的矩阵。</li>
<li><code>torch.matmul()</code>：这个函数更加通用，它支持两个张量进行相乘，这两个张量可以是不同的维度，也支持广播操作。对于二维张量，它的行为与
<code>torch.mm()</code>
相同。对于高维张量，它会进行规定的广播操作后再乘。</li>
<li><code>A * B</code>和<code>torch.mul(A, B)</code>的操作效果一致，都支持广播机制。</li>
</ul></li>
<li><p>降维</p>
<p>张量可以通过sum()和mean()函数沿指定的轴降维</p></li>
</ol>
<h3 id="微积分">微积分</h3>
<ol type="1">
<li><p>损失函数：衡量"模型有多糟糕"的分数</p></li>
<li><p>优化：拟合现有的数据</p>
<p>泛化：超出现有的数据，模型在未知数据也表现良好</p></li>
<li><p>梯度：</p>
<ol type="1">
<li>梯度是一个向量</li>
<li>其中的各个元素是函数y对其所有变量的偏导数</li>
</ol></li>
</ol>
<h3 id="自动微分">自动微分</h3>
<ol type="1">
<li>backward()函数：默认只对标量执行反向传播，因此在深度学习最小化一个batch的损失函数时常常要通过<code>.sum()</code>或<code>.mean()</code>将向量转化为标量，然后才能执行反向传播</li>
</ol>
<h3 id="概率">概率</h3>
<ol type="1">
<li><p>机器学习等价于做出预测</p></li>
<li><p>强化学习</p>
<ul>
<li>做错了：得到负反馈</li>
<li>做对了：得到正反馈</li>
</ul></li>
<li><p>可能性</p>
<ul>
<li>离散（discrete）随机变量的可能性叫做概率</li>
<li>连续（continuous）随机变量的可能性叫做<strong>密度（density）</strong></li>
<li>分布（distribution）：随机变量各种取值及其对应的可能性</li>
</ul></li>
<li><p>Bayes定理 <span class="math display">\[
P(A\mid B)=\frac{P(A,B)}{P(B)}=\frac{P(B\mid A)P(A)}{P(B)}.
\]</span></p></li>
<li><p>独立性</p>
<p>如果两个随机变量A和B是独立的，意味着事件A的发生跟B事件的发生无关。即<span
class="math inline">\(A\perp B\)</span>，此时根据Bayes定理可以推出：
<span class="math display">\[
P(A,B)=P(A)P(B)
\]</span></p></li>
</ol>
<h2 id="线性神经网络">线性神经网络</h2>
<h3 id="线性回归">线性回归</h3>
<ol type="1">
<li><p><em>小批量随机梯度下降</em>（minibatch stochastic gradient
descent）</p>
<p>在每次迭代中，我们首先随机抽样一个小批量<span
class="math inline">\(\beta\)</span>， 它是由固定数量的训练样本组成的。
然后，我们计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。
最后，我们将梯度乘以一个预先确定的正数<span
class="math inline">\(\eta\)</span>，并从当前参数的值中减掉。</p>
<p>之所以沿着负梯度方向更新权重参数，是因为梯度本身表示了函数的局部上升方向，也就是说，如果顺着梯度的方向走，函数值会变大。但在训练神经网络和其他机器学习模型时，我们的目标并不是让损失函数变大，而是让它尽可能小。</p>
<p>我们用下面的数学公式来表示这一更新过程（<span
class="math inline">\(\partial\)</span>表示偏导数）： <span
class="math display">\[
(\mathbf{w},b)\leftarrow(\mathbf{w},b)-\frac\eta{|\mathcal{B}|}\sum_{i\in\mathcal{B}}\partial_{(\mathbf{w},b)}l^{(i)}(\mathbf{w},b).
\]</span></p>
<p>在多元线性回归中，对于平方损失和仿射变换，这一更新过程的形式如下:
<span class="math display">\[
\begin{gathered}
\mathbf{w}\leftarrow\mathbf{w}-\frac\eta{|\mathcal{B}|}\sum_{i\in\mathcal{B}}\partial_\mathbf{w}l^{(i)}(\mathbf{w},b)=\mathbf{w}-\frac\eta{|\mathcal{B}|}\sum_{i\in\mathcal{B}}\mathbf{x}^{(i)}\left(\mathbf{w}^\top\mathbf{x}^{(i)}+b-y^{(i)}\right),
\\
b\leftarrow
b-\frac\eta{|\mathcal{B}|}\sum_{i\in\mathcal{B}}\partial_bl^{(i)}(\mathbf{w},b)=b-\frac\eta{|\mathcal{B}|}\sum_{i\in\mathcal{B}}\left(\mathbf{w}^\top\mathbf{x}^{(i)}+b-y^{(i)}\right).
\end{gathered}
\]</span></p>
<p>在这里，<span
class="math inline">\(\partial_\mathbf{w}l^{(i)}(\mathbf{w},b)\)</span>表示：一个小批量<span
class="math inline">\(\beta\)</span>中的一个样本x<sup>{i}</sup>的损失函数对权重w求偏导；</p>
<p>对于平方损失和仿射变换，这个偏导具体为：<span
class="math inline">\(\mathbf{x}^{(i)}\left(\mathbf{w}^\top\mathbf{x}^{(i)}+b-y^{(i)}\right)\)</span></p></li>
<li><p>训练流程</p>
<ol type="1">
<li><p>读取数据集</p></li>
<li><p>定义模型（Sequential）</p></li>
<li><p>初始化模型参数</p></li>
<li><p>定义损失函数</p></li>
<li><p>定义优化算法</p></li>
<li><p>训练</p>
<p>在每个迭代周期里，我们将完整遍历一次数据集（<code>train_data</code>），
不停地从中获取一个小批量的输入和相应的标签。
对于每一个小批量，我们会进行以下步骤:</p>
<ul>
<li>通过调用<code>net(X)</code>生成预测并计算损失<code>l</code>（前向传播）。</li>
<li>通过进行反向传播来计算梯度。</li>
<li>通过调用优化器来更新模型参数。</li>
</ul></li>
</ol></li>
<li><p>全连接层的参数开销</p>
<p>如果全连接层又d个输入，q个输出，那么共有dq个参数</p></li>
<li><p>全连接层的偏置项的维度为（1,
q），q为该层的输出维度。（习惯写法）</p></li>
</ol>
<h3 id="softmax回归">softmax回归</h3>
<ol type="1">
<li><p>softmax函数： <span class="math display">\[
$\hat{y}=\mathrm{softmax}(\mathbf{o})\quad\text{其中}\quad\hat{y}_j=\frac{\exp(o_j)}{\sum_k\exp(o_k)}
\]</span></p>
<p>softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持可导的性质。</p></li>
<li><p>softmax回归</p>
<p>与线性回归一样，softmax回归也是一个单层神经网络。由于计算每个输出<span
class="math inline">\(o_1\)</span>、<span
class="math inline">\(o_2\)</span>和<span
class="math inline">\(o_3\)</span>取决于 所有输入<span
class="math inline">\(x_1\)</span>、<span
class="math inline">\(x_2\)</span>、<span
class="math inline">\(x_3\)</span>和<span
class="math inline">\(x_4\)</span>,
所以softmax回归的输出层也是全连接层。计算过程如图：</p>
<figure>
<img src="https://ooo.0x0.ooo/2024/01/11/OZVizS.png"
alt="图2 softmax回归是一种单层神经网络" />
<figcaption aria-hidden="true">图2
softmax回归是一种单层神经网络</figcaption>
</figure>
<p>为了提高计算效率并且充分利用GPU，我们通常会对小批量样本的数据执行矢量计算。假设我们读取了一个批量的样本<span
class="math inline">\(\mathbf{X}\)</span>, 其中特征维度 (输入数量)
为<span class="math inline">\(d\)</span>,批量大小为<span
class="math inline">\(n\)</span>。此外，假设我们在输出中有<span
class="math inline">\(q\)</span>个类别。那么小批量样本的特征为<span
class="math inline">\(\mathbf{X}\in\mathbb{R}^{n\times d}\)</span>,
权重为<span class="math inline">\(\mathbf{W}\in\mathbb{R}^{d\times
q}\)</span>, 偏置为<span
class="math inline">\(\mathbf{b}\in\mathbb{R}^{1\times q}\)</span>。</p>
<p>softmax回归的矢量计算表达式为： <span class="math display">\[
\begin{gathered}\mathbf{O}=\mathbf{X}\mathbf{W}+\mathbf{b},\\\hat{\mathbf{Y}}=\mathrm{softmax}(\mathbf{O}).\end{gathered}
\]</span></p></li>
</ol>
<h2 id="多层感知机">多层感知机</h2>
<ol type="1">
<li><p>多层感知机</p>
<ol type="1">
<li><p>含义：在网络中加入一个或多个隐藏层来克服线性模型的限制，
使模型具有更强的表达能力</p></li>
<li><p>关键要素：在仿射变换之后对每个隐藏单元应用非线性的激活函数(activation
function) <span
class="math inline">\(\sigma\)</span>。一般来说，有了激活函数，就不可能再将我们的多层感知机退化成线性模型
<span class="math display">\[
\mathbf{H}=\sigma(\mathbf{X}\mathbf{W}^{(1)}+\mathbf{b}^{(1)}),
\]</span></p>
<p><span class="math display">\[
\mathbf{O}=\mathbf{H}\mathbf{W}^{(2)}+\mathbf{b}^{(2)}.
\]</span></p></li>
</ol></li>
<li><p>通用近似定理：通过使用更深（而不是更广）的网络，我们可以更容易地逼近许多函数</p></li>
<li><p>过拟合</p>
<ul>
<li>训练数据精度 &gt;&gt; 测试数据精度(代表着潜在分布)</li>
<li>过拟合更像死记硬背标签，<strong>泛化则要求模型找到更通用的规律，学会如何判断标签</strong></li>
<li>更可能过拟合？
<ul>
<li>可调整参数越多，模型越容易过拟合</li>
<li>可调整参数的取值范围越大，模型越容易过拟合</li>
<li>训练样本数量越少，模型越容易过拟合</li>
</ul></li>
</ul></li>
<li><p>欠拟合：模型连训练数据都无法很好地拟合，无法继续减少训练误差</p></li>
<li><p>什么样的模型更复杂？——训练迭代周期更长的模型更复杂，需要早停（early
stopping）的模型更简单</p></li>
<li><p>模型选择</p>
<ol type="1">
<li>不同类模型的选择（比如决策树or线性回归模型）</li>
<li>同类模型的选择（比如都是多层感知机，但是隐藏层的数量、同一隐藏层隐藏单元的数量不同）</li>
<li>此时需要用到<strong>验证集</strong>——故数据集划分为训练集、验证集、测试集（严格来说测试集只用一次）</li>
</ol></li>
<li><p>正则化</p>
<p>减少过拟合，通过在训练集的损失函数上加入权重向量W的惩罚项，从而降低学习到的模型的复杂度。</p>
<ul>
<li>法1：权重衰减（weight decay）
<ul>
<li>岭回归：通过L<sub>2</sub>正则化的线性回归（通过惩罚权重向量W中的大分量来均匀分布权重）</li>
<li>套索回归：通过L<sub>1</sub>正则化的线性回归（通过直接去掉一部分权重来实现特征选择，减少特征的数量，从而降低模型复杂度，减少过拟合的风险）</li>
</ul></li>
<li>法2：dropout
<ul>
<li>一般只在<strong>训练集</strong>上使用</li>
<li>应用于每个隐藏层的输出H（在激活函数之后使用）：<span
class="math inline">\(\mathbf{H}=\sigma(\mathbf{X}\mathbf{W}^{(1)}+\mathbf{b}^{(1)}),\)</span></li>
<li>可以各层分别设置dropout概率，靠近输入的地方设置较低的dropout概率</li>
</ul></li>
</ul></li>
<li><p>前向传播 and 反向传播</p>
<p>反向传播计算各可调整参数的梯度时，需要使用<strong>前向传播过程中产生的中间值（即隐藏层的输出值H）</strong>，这也是训练阶段的显存大于测试阶段的原因（因为训练阶段需要存储前向传播的中间值，以备反向传播使用，而测试阶段不需要这样）</p></li>
<li><p>梯度爆炸</p>
<ul>
<li>含义：可调整参数（如权重W）更新过大，<u>破坏了模型的稳定收敛</u></li>
<li>与初始化模型参数有关，不合适的初始化会导致我们没有机会让梯度下降优化器收敛</li>
</ul></li>
<li><p>梯度消失</p>
<ul>
<li>含义：可调整参数（如权重W）更新过小，每次几乎不会移动，<u>导致模型无法学习</u></li>
<li>激活函数选择sigmoid容易导致梯度消失，所以现在都用ReLu</li>
</ul></li>
<li><p>随机初始化可以打破对称性（正态分布、Xavier初始化）</p></li>
<li><p>分布偏移</p>
<ul>
<li><p>含义：训练集和测试集不来自同一个分布</p></li>
<li><p>分类：协变量（特征）偏移、标签偏移</p></li>
<li><p>协变量偏移：</p>
<ul>
<li><p>含义：训练数据和测试数据中特征（即协变量）的分布有所不同，但目标变量在给定特征的条件下的分布是不变的情况。</p></li>
<li><p>```
假设我们正在构建一个预测电邮是否为垃圾邮件（"是垃圾邮件"或"不是垃圾邮件"）的模型，我们使用包含文本内容等特征的电邮收集的历史数据进行模型训练。特定的单词出现的频率（例如"deal",
"free", "win"等）可能被用作特征。</p>
<p>起初，我们的训练数据主要是家庭用户的电邮，我们的垃圾邮件主要是广告和一些诱导性电邮。然后，我们打算在一个公司类的环境中去部署和测试这个模型，这个环境中垃圾邮件主要是包含恶意链接和病毒的电邮。</p>
<p>在这个情况下，特征（电邮内容，或者更具体一点，特定词汇的出现频率）的分布在训练数据和测试数据（家庭用户电邮和公司电邮）之间发生了改变，因为公司电邮中出现恶意链接和病毒电邮的比例会更高，而广告邮件的比例会更低。然而，无论是在家庭环境还是在公司环境，条件概率P(y|x)（给定电邮内容，这封邮件是垃圾邮件的概率）是不变的。
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">- 标签偏移：</span><br><span class="line"></span><br><span class="line">  - 含义：训练数据和测试数据中标签（即y，或者说目标变量）的分布有所不同，但在给定标签的情况下，特征（即x，或者说输入变量）的条件分布保持不变的现象</span><br><span class="line"></span><br><span class="line">  - ```</span><br><span class="line">    假如我们在建立一个预测一个人是否会感冒的模型，模型的特征有&quot;打喷嚏&quot;，&quot;头疼&quot;，&quot;喉咙痛&quot;等症状。我们在冬天收集了一些数据作为训练数据，然后到了夏天我们拿这个模型去预测是否会感冒。</span><br><span class="line">    </span><br><span class="line">    在这个场景中，我们可以看出，冬天和夏天人们感冒的概率（即标签y的边缘分布）是不同的，通常冬天感冒的概率会比夏天高。这就产生了标签偏移。然而，无论是冬天还是夏天，如果一个人感冒了，他出现打喷嚏，头疼，喉咙痛等症状的概率通常是一样的，也就是说在给定感冒的情况下，症状（即特征x）的条件分布是不变的。</span><br></pre></td></tr></table></figure></p></li>
</ul></li>
<li><p>标签偏移和协变量偏移：</p>
<ul>
<li><p>可以同时成立</p></li>
<li><pre><code>  比如，在从冬季到夏季的过程中，不仅感冒的比例发生了变化（标签偏移），与此同时由于气候的变化，导致人打喷嚏的比例也发生了变化（协变量偏移）。</code></pre></li>
</ul></li>
<li><p>测试时可在一定假设下纠正协变量偏移、标签偏移</p></li>
</ul></li>
</ol>
]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>动手学深度学习</tag>
      </tags>
  </entry>
</search>
