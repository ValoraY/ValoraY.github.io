<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Fast RCNN论文理解</title>
    <url>/2023/12/29/Fast-RCNN%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="Fast-RCNN论文理解"><a href="#Fast-RCNN论文理解" class="headerlink" title="Fast RCNN论文理解"></a>Fast RCNN论文理解</h1><p>在Fast RCNN提出前，目标检测领域效果较好的算法是RCNN和SPPnet，因此本文主要将Fast RCNN的改进与这两种算法进行对比。</p>
<h2 id="RCNN和SPPnet的缺点"><a href="#RCNN和SPPnet的缺点" class="headerlink" title="RCNN和SPPnet的缺点"></a>RCNN和SPPnet的缺点</h2><h3 id="RCNN的缺点"><a href="#RCNN的缺点" class="headerlink" title="RCNN的缺点"></a>RCNN的缺点</h3><ol>
<li><p>训练是多阶段的</p>
<span id="more"></span>

<ol>
<li>首先，在候选区域上微调ConvNet</li>
<li>然后，对ConvNet产生的特征训练SVMs分类器，用来代替微调的CNN网络学到的softmax分类器</li>
<li>最后，学习边界框回归网络</li>
</ol>
</li>
<li><p>训练耗费时间和空间</p>
<ol>
<li>为了训练SVM分类器和边界框回归网络，从ConvNet抽取到的候选区域的特征要先被写入磁盘</li>
<li>耗时：<strong>RCNN对每个候选区域都执行ConvNet前向传播来提取特征，没有共享计算</strong></li>
</ol>
</li>
<li><p>测试很慢</p>
<ol>
<li>每张测试图片要先获取2000个候选区域，再对每个区域抽取特征，耗时很长</li>
</ol>
</li>
</ol>
<h3 id="SPPnet的缺点"><a href="#SPPnet的缺点" class="headerlink" title="SPPnet的缺点"></a>SPPnet的缺点</h3><h4 id="SPPnet对RCNN的改进"><a href="#SPPnet对RCNN的改进" class="headerlink" title="SPPnet对RCNN的改进"></a>SPPnet对RCNN的改进</h4><p>SPPnet对RCNN进行了改进，引入了一个空间金字塔池化层(SPP layer)，这个层的本质是：通过采用动态的池化核尺寸，来限制最终特征输出尺寸的最大池化层(max pooling layer)。从而使网络借助该层可以把不同大小的候选区域特征图转换成特定大小的输出。</p>
<p>因此该网络的运行流程大致如下：</p>
<p>输入整张图片进行前向传播，计算一个卷积特征图&#x3D;&gt;从这个共享特征图抠出每个候选区域的特征图&#x3D;&gt;通过SPP layer把不同大小的候选区域特征图转换成特定大小的输出&#x3D;&gt;对特征向量进行分类。</p>
<p>这种做法只需要对整张图片做一次前向传播，得到整张图片的特征图，再从中抠出不同候选区域的特征图即可，不用像RCNN一样对2000张候选区域图像做2000次前向传播，实现了通过共享计算来加速，解决了RCNN预测时速度慢的问题</p>
<h4 id="SPPnet的缺点-1"><a href="#SPPnet的缺点-1" class="headerlink" title="SPPnet的缺点"></a>SPPnet的缺点</h4><ol>
<li>训练是多阶段的：抽取特征&#x3D;&#x3D;》微调网络&#x3D;&#x3D;》训练SVMs分类器&#x3D;&#x3D;》训练边界框回归</li>
<li>耗费时间和空间：因为要额外训练SVMs分类器和边界框回归网络，所以CNN得出的特征仍然要被写入磁盘</li>
<li>SPPnet的微调算法部分不能更新卷积层的参数，限制了深层网络的精度</li>
</ol>
<h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><ol>
<li>精度更高（比RCNN、SPPnet）</li>
<li>训练使用多任务损失函数(multi-task loss)实现单阶段的训练</li>
<li>训练可以更新所有的网络层</li>
<li>不需要磁盘进行特征缓存</li>
</ol>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><h3 id="总体流程"><a href="#总体流程" class="headerlink" title="总体流程"></a>总体流程</h3><p><img src="https://ooo.0x0.ooo/2023/12/29/OKYAJv.png" alt="OKYAJv.png"></p>
<p>输入一整张图片和一套候选区域（也叫ROIs）&#x3D;&gt;Deep ConvNet（卷积+池化）得到整体的特征图&#x3D;&gt;根据候选区域在原图中的位置，使用ROI投影，获取到候选区域的特征图&#x3D;&gt;针对每个候选区域，用ROI池化层把尺寸不固定的候选区域特征图转换成特定尺寸的特征图（如7 x 7）&#x3D;&gt;接上2个全连接层，得到每个候选区域的特征向量&#x3D;&gt;再接上两个并列的全连接层，获得两个输出：</p>
<ol>
<li>利用softmax预测类别（对K+1个类别）</li>
<li>产生每个类别对应的边界框坐标（(K+1)*4）</li>
</ol>
<h3 id="与SPPnet的区别"><a href="#与SPPnet的区别" class="headerlink" title="与SPPnet的区别"></a>与SPPnet的区别</h3><ol>
<li>SPPnet在ConvNet之后接上了SPP layer（空间金字塔池化层），用来把不同尺寸的候选区域特征图转换为特定大小的输出；而Fast RCNN在ConvNet之后接上了ROI pooling layer（ROI池化层），用于把不同尺寸的候选区域特征图转换成特定尺寸的特征图</li>
<li>SPPnet在提取到图像的CNN特征后，又额外训练SVM进行分类和回归；而Fast RCNN就是直接接了两个并行的全连接层做分类和回归</li>
</ol>
<h3 id="组成部分及实现步骤"><a href="#组成部分及实现步骤" class="headerlink" title="组成部分及实现步骤"></a>组成部分及实现步骤</h3><h4 id="ROI池化层"><a href="#ROI池化层" class="headerlink" title="ROI池化层"></a>ROI池化层</h4><p>用最大池化把感兴趣区域的特征转换成特定大小的特征图（如7 x 7），是spatial pyramid pooling layer只有一个金字塔层时的特例</p>
<h4 id="初始化Fast-RCNN"><a href="#初始化Fast-RCNN" class="headerlink" title="初始化Fast RCNN"></a>初始化Fast RCNN</h4><p>从在ImageNet上预训练好的图像分类模型（AlexNet）上初始化一个Fast RCNN，改造步骤为;</p>
<p>（1）首先，把Conv Net之后最后一层的最大池化层替换为一个ROI池化层</p>
<p>（2）其次，网络的最后一个全连接层和softmax层替换为两个并行的全连接层（一个分支用来预测K+1个类别，一个分支用来预测边界框回归）</p>
<p>（3）最后，网络要接受两个数据输入：a list of images和 a list of ROIs in those images</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYrxY.png" alt="OKYrxY.png"></p>
<h4 id="微调模型"><a href="#微调模型" class="headerlink" title="微调模型"></a>微调模型</h4><p>即：通过反向传播来训练整个网络的权重</p>
<p>（1）为什么SPPnet不能更新空间金字塔池化层前的权重？</p>
<p>根本原因：当训练样本（ROIs）来自于不同的图片时，通过空间金字塔池化层（SPP layer）的反向传播是无效的。（至于为啥无效，没看懂解释）</p>
<p>（2）Fast RCNN是怎么有效训练的？（通过反向传播来训练整个网络的权重）</p>
<ul>
<li>mini-batch 分层采样：SGD的mini-batches是被分层采样的，先采样N个图片，然后从每张图片中采样R&#x2F;N个ROIs。这样，来自同一张图片的ROIs就能在前向传播和后向传播中共享计算和内存。论文中取N&#x3D;2，R&#x3D;128。即每次采样2张图片，从每张图片采样64个ROI。</li>
<li>精简训练过程：用一个微调阶段共同优化一个softmax分类器和边界框回归器</li>
</ul>
<p>（3）multi-task loss</p>
<p>multi-task loss &#x3D; 类别损失 + 框回归损失</p>
<ul>
<li>类别损失</li>
</ul>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKY7Hp.png" alt="OKY7Hp.png"></p>
<ul>
<li>框回归损失</li>
</ul>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYNXU.png" alt="OKYNXU.png"></p>
<p>（4）mini-batch 分层采样</p>
<p>（5）通过ROI池化层反向传播</p>
<p>（6）SGD 超参数</p>
<h4 id="目标的尺度不变性"><a href="#目标的尺度不变性" class="headerlink" title="目标的尺度不变性"></a>目标的尺度不变性</h4><p>（1）含义：如果有两个内容相同的目标，唯一区别是一个目标比较小，一个目标比较大，如果网络能将这两个目标都识别出来，说明网络具有较好的尺度不变性</p>
<p>（2）两种策略：</p>
<ul>
<li>单尺度训练：每张图片都被处理成预定义好的图片尺寸来进行训练和预测。让网络来直接学会尺度不变性</li>
<li>多尺度训练：在训练期间，每一张图片都被随机采样成特定的尺度。这也是一种数据增强的手段</li>
</ul>
<h3 id="测试流程"><a href="#测试流程" class="headerlink" title="测试流程"></a>测试流程</h3><p>接收输入（一张图片和这张图片中的一系列候选区域），输入网络就能预测出候选区域的类别和精确坐标</p>
<h3 id="截断的奇异值分解"><a href="#截断的奇异值分解" class="headerlink" title="截断的奇异值分解"></a>截断的奇异值分解</h3><p>能够减少全连接层的参数，从而加速全连接层</p>
<h3 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h3><p>更换不同的CNN网络结构（AlexNet、VGG_CNN_M_1024、VGG16），对比实验结果（精度和测试时间）。</p>
<p>此外，还关注了一个问题：对于SPPnet中不太深的ConvNet，只微调全连接层就足以获得较好的精度，然而论文在这里假设：对于很深的网络，上述结论不成立。进而提出了一个问题：微调哪些层的效果更好？</p>
<p>实验结果是：微调卷积层精度高于只微调全连接层</p>
<h3 id="模型的设计评估"><a href="#模型的设计评估" class="headerlink" title="模型的设计评估"></a>模型的设计评估</h3><h4 id="多任务训练是否有效"><a href="#多任务训练是否有效" class="headerlink" title="多任务训练是否有效"></a>多任务训练是否有效</h4><p>多任务训练：指同时训练分类和边界框回归任务，共同调整一套参数</p>
<p>多阶段训练：指分类和边界框回归分成两个阶段进行训练，先训练分类，训练好后冻结参数，再额外训练一个边界框回归分支，也会利用第二个分支的回归结果</p>
<p>实验结果表明：多任务的训练结果比多阶段的要好</p>
<h4 id="单尺度还是多尺度训练？"><a href="#单尺度还是多尺度训练？" class="headerlink" title="单尺度还是多尺度训练？"></a>单尺度还是多尺度训练？</h4><p>单尺度训练：把短边固定到600像素</p>
<p>多尺度训练：把短边固定到5种像素</p>
<p>结果：多尺度精度更高</p>
<h4 id="是否需要更多训练数据"><a href="#是否需要更多训练数据" class="headerlink" title="是否需要更多训练数据"></a>是否需要更多训练数据</h4><p>扩增2007数据集，精度会提高。不会出现传统模型出现的精度饱和的情况</p>
<h4 id="SVM是不是比softmax好？"><a href="#SVM是不是比softmax好？" class="headerlink" title="SVM是不是比softmax好？"></a>SVM是不是比softmax好？</h4><p>实验结果：Fast RCNN中，直接用softmax效果比好</p>
<h4 id="候选区域是不是越多越好？"><a href="#候选区域是不是越多越好？" class="headerlink" title="候选区域是不是越多越好？"></a>候选区域是不是越多越好？</h4><p>实验结果：候选区域越多，精度先提升后下降</p>
<p>参考资料：</p>
<blockquote>
<p><a href="https://www.bilibili.com/video/BV1y94y1Q7QJ/?spm_id_from=333.880.my_history.page.click&vd_source=66a72b15abe9693bd8b4f738f5a67ee7">https://www.bilibili.com/video/BV1y94y1Q7QJ/?spm_id_from=333.880.my_history.page.click&amp;vd_source=66a72b15abe9693bd8b4f738f5a67ee7</a></p>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>Fast RCNN</tag>
        <tag>论文理解</tag>
      </tags>
  </entry>
  <entry>
    <title>FastRCNN代码复现</title>
    <url>/2023/12/29/FastRCNN%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<h1 id="Fast-RCNN代码复现"><a href="#Fast-RCNN代码复现" class="headerlink" title="Fast RCNN代码复现"></a>Fast RCNN代码复现</h1><p>项目源代码下载地址：</p>
<blockquote>
<p>Fast-R-CNN-pytorch-master<br><a href="https://www.alipan.com/s/FqYEYzqCe7k">https://www.alipan.com/s/FqYEYzqCe7k</a> 提取码:ue87 点击链接保存，或者复制本段内容，打开「阿里云盘」APP ，无需下载极速在线查看，视频原画倍速播放。</p>
</blockquote>
<span id="more"></span>


<p>项目目录如下;</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYKlq.png" alt="OKYKlq.png"></p>
<p>对Fast RCNN的论文理解见专栏的上篇内容，本文介绍Fast RCNN的代码复现。基本流程如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">利用coco2017数据集训练Fast-RCNN模型（训练过程详细步骤记录）：</span><br><span class="line"></span><br><span class="line">（1）初始化COCO数据集</span><br><span class="line"></span><br><span class="line">（2）构造训练集和验证集：利用选择搜索算法（selective-search）生成一定数量的候选框，将候选框与gound-truth进行IOU（交并比）计算，如果IoU大于等于0.5，则认为候选区域是正样本，0.1&lt;IoU&lt;0.5，则认为候选区域是负样本</span><br><span class="line"></span><br><span class="line">（3）设置ROI Pooling模块、特征提取网络模型。利用ROIPlooing方法，从共享特征图抠出各个候选区域特征图</span><br><span class="line"></span><br><span class="line">（4）设置输出为一个分类分支（类别类数+背景类（1））与回归分支</span><br><span class="line"></span><br><span class="line">（5）设置多目标损失函数：交叉熵损失与回归损失</span><br><span class="line"></span><br><span class="line">（6）训练网络模型</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="初始化COCO数据集"><a href="#初始化COCO数据集" class="headerlink" title="初始化COCO数据集"></a>初始化COCO数据集</h4><p><strong>COCOdataset.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> PIL</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    COCO数据集的处理</span></span><br><span class="line"><span class="string">    1、读取数据</span></span><br><span class="line"><span class="string">    2、数据的预处理</span></span><br><span class="line"><span class="string">    3、数据的加载</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">	需要修改内容：COCO数据集的存放路径、加载训练集还是验证集(mode为&quot;train&quot;or&quot;val&quot;)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">COCOdataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="comment"># todo：注意修改coco数据集的存放路径</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, <span class="built_in">dir</span>=<span class="string">&#x27;D:\\WritePapers\\object_detection_basics\\Datasets\\COCO2017\\&#x27;</span>, mode=<span class="string">&#x27;train&#x27;</span>,</span></span><br><span class="line"><span class="params">                 transform=transforms.Compose(<span class="params">[transforms.ToTensor(<span class="params"></span>),</span></span></span><br><span class="line"><span class="params"><span class="params">                                               transforms.Normalize(<span class="params">[<span class="number">0.485</span>, <span class="number">0.456</span>, -<span class="number">.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]</span>)]</span>)</span>):</span><br><span class="line">        <span class="comment"># transform执行2步操作：1、将PIL.Image转换为torch.Tensor，并自动将数据缩放到[0,1]之间；</span></span><br><span class="line">        <span class="comment"># 2.对图像进行标准化。这里的两个参数分别是RGB通道的均值和标准差。这个操作会按照每个通道进行标准化，即(image - mean) / std</span></span><br><span class="line">        <span class="comment"># transforms.Normalize([0.485, 0.456, -.406], [0.229, 0.224, 0.225])的两个参数分别是ImageNet数据集的统计得到的RGB通道的均值和标准差</span></span><br><span class="line">        <span class="comment"># 这样做的目的是使得模型的输入数据分布和预训练模型（项目使用了在ImageNet预训练的VGG19模型）的输入数据分布一致，从而可以更好地利用预训练模型。</span></span><br><span class="line">        <span class="keyword">assert</span> mode <span class="keyword">in</span> [<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;val&#x27;</span>], <span class="string">&#x27;mode must be \&#x27;train\&#x27; or \&#x27;val\&#x27;&#x27;</span></span><br><span class="line">        self.<span class="built_in">dir</span> = <span class="built_in">dir</span> <span class="comment"># self关键字代表类的实例</span></span><br><span class="line">        self.mode = mode <span class="comment"># train则加载训练集，val则加载验证集</span></span><br><span class="line">        self.transform = transform</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(self.<span class="built_in">dir</span>, <span class="string">&#x27;%s.json&#x27;</span> % self.mode), <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f: <span class="comment">#%s是一个字符串占位符。%操作符用于指定要插入的值==&gt;%s会被self.mode的值替换</span></span><br><span class="line">            self.ss_regions = json.load(f)</span><br><span class="line">        <span class="comment"># with语句并不创建一个新的作用域。在with语句块内部定义的变量，其作用域是包含with语句的那个作用域。</span></span><br><span class="line">        self.img_dir = os.path.join(self.<span class="built_in">dir</span>, <span class="string">&#x27;%s2017&#x27;</span> % self.mode)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.ss_regions) <span class="comment"># 说明ss_regions是一个列表，每个元素代表一张图片对应的region信息</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, i, max_num_pos=<span class="number">8</span>, max_num_neg=<span class="number">16</span></span>):</span><br><span class="line">        img = PIL.Image.<span class="built_in">open</span>(os.path.join(self.img_dir, <span class="string">&#x27;%012d.jpg&#x27;</span> %</span><br><span class="line">                                     self.ss_regions[i][<span class="string">&#x27;id&#x27;</span>]))</span><br><span class="line">        <span class="comment"># %012d是一个占位符，表示一个十二位的整数，不足十二位的部分会用0填充==&gt;%012d会被self.ss_regions[i][&#x27;id&#x27;]的值替换，self.ss_regions[i][&#x27;id&#x27;]是从JSON文件中读取的某张图片的ID</span></span><br><span class="line">        img = img.convert(<span class="string">&#x27;RGB&#x27;</span>) <span class="comment"># 将图片转换为RGB格式</span></span><br><span class="line">        img = img.resize([<span class="number">224</span>, <span class="number">224</span>])</span><br><span class="line">        pos_regions = self.ss_regions[i][<span class="string">&#x27;pos_regions&#x27;</span>] <span class="comment"># 获取正样本区域</span></span><br><span class="line">        neg_regions = self.ss_regions[i][<span class="string">&#x27;neg_regions&#x27;</span>] <span class="comment"># 获取负样本区域</span></span><br><span class="line">        <span class="keyword">if</span> self.transform != <span class="literal">None</span>: <span class="comment"># 如果设置了图像预处理方法</span></span><br><span class="line">            img = self.transform(img)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(pos_regions) &gt; max_num_pos: <span class="comment"># 如果正样本区域的数量大于最大数量,随机选择一部分正样本区域</span></span><br><span class="line">            pos_regions = random.sample(pos_regions, max_num_pos)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(neg_regions) &gt; max_num_neg:</span><br><span class="line">            neg_regions = random.sample(neg_regions, max_num_neg)</span><br><span class="line">        regions = pos_regions + neg_regions <span class="comment"># 合并正样本区域和负样本区域</span></span><br><span class="line">        random.shuffle(regions) <span class="comment"># 随机打乱区域</span></span><br><span class="line">        rects = [] <span class="comment"># 初始化矩形列表</span></span><br><span class="line">        rela_locs = []  <span class="comment"># 初始化相对位置列表</span></span><br><span class="line">        cats = [] <span class="comment"># 初始化类别列表</span></span><br><span class="line">        <span class="keyword">for</span> region <span class="keyword">in</span> regions:<span class="comment"># 遍历第i张图片的得到的区域（包括正样本和负样本区域）</span></span><br><span class="line">            rects.append(region[<span class="string">&#x27;rect&#x27;</span>]) <span class="comment"># 将区域的矩形信息添加到矩形列表中</span></span><br><span class="line">            p_rect = region[<span class="string">&#x27;rect&#x27;</span>] <span class="comment"># 获取区域的矩形信息</span></span><br><span class="line">            g_rect = region[<span class="string">&#x27;gt_rect&#x27;</span>] <span class="comment"># 获取区域的真实矩形信息</span></span><br><span class="line">            t_x = (g_rect[<span class="number">0</span>] + g_rect[<span class="number">2</span>] - p_rect[<span class="number">0</span>] - p_rect[<span class="number">2</span>]) / <span class="number">2</span> / (p_rect[<span class="number">2</span>] - p_rect[<span class="number">0</span>])</span><br><span class="line">            t_y = (g_rect[<span class="number">1</span>] + g_rect[<span class="number">3</span>] - p_rect[<span class="number">1</span>] - p_rect[<span class="number">3</span>]) / <span class="number">2</span> / (p_rect[<span class="number">3</span>] - p_rect[<span class="number">1</span>])</span><br><span class="line">            t_w = math.log((g_rect[<span class="number">2</span>] - g_rect[<span class="number">0</span>]) / (p_rect[<span class="number">2</span>] - p_rect[<span class="number">0</span>]))</span><br><span class="line">            t_h = math.log((g_rect[<span class="number">3</span>] - g_rect[<span class="number">1</span>]) / (p_rect[<span class="number">3</span>] - p_rect[<span class="number">1</span>]))</span><br><span class="line">            rela_locs.append([t_x, t_y, t_w, t_h]) <span class="comment"># 将区域的相对位置信息添加到相对位置列表中</span></span><br><span class="line">            cats.append(region[<span class="string">&#x27;category&#x27;</span>]) <span class="comment"># 将区域的类别信息添加到类别列表中</span></span><br><span class="line">        roi_idx_len = <span class="built_in">len</span>(regions) <span class="comment"># 获取区域的数量</span></span><br><span class="line">        <span class="keyword">return</span> img, rects, roi_idx_len, rela_locs, cats</span><br><span class="line"></span><br><span class="line"><span class="comment"># dataset = COCOdataset()</span></span><br><span class="line"><span class="comment"># print(dataset[1][0].shape)</span></span><br><span class="line"><span class="comment"># print(dataset[1][1])</span></span><br><span class="line"><span class="comment"># from torch.utils.data import DataLoader</span></span><br><span class="line"><span class="comment"># dataloader = DataLoader(dataset, batch_size=2)</span></span><br><span class="line"><span class="comment"># print(next(iter(dataloader))[1])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    dataset = COCOdataset()</span><br><span class="line">    <span class="built_in">print</span>(dataset.__len__())</span><br><span class="line">    img, rects, roi_idx_len, rela_locs, cats = dataset.__getitem__(<span class="number">10</span>)</span><br><span class="line">    <span class="built_in">print</span>(img, rects, roi_idx_len, rela_locs, cats)</span><br><span class="line">    <span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">    loader = DataLoader(dataset, batch_size=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i, temp <span class="keyword">in</span> <span class="built_in">enumerate</span>(loader):</span><br><span class="line">        <span class="built_in">print</span>(i,<span class="built_in">type</span>(temp))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="构造训练集和验证集"><a href="#构造训练集和验证集" class="headerlink" title="构造训练集和验证集"></a>构造训练集和验证集</h4><p><strong>利用选择搜索算法（selective-search）生成一定数量的候选框，将候选框与gound-truth进行IOU（交并比）计算，如果IoU大于等于0.5，则认为候选区域是正样本，0.1&lt;IoU&lt;0.5，则认为候选区域是负样本</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse <span class="comment"># 导入argparse模块，用于处理命令行参数</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> sys <span class="comment"># 导入sys模块，用于处理Python运行时环境</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> progressbar <span class="keyword">import</span> * <span class="comment"># 导入progressbar模块，用于显示进度条</span></span><br><span class="line"><span class="keyword">from</span> pycocotools.coco <span class="keyword">import</span> COCO <span class="comment"># 导入pycocotools模块，用于处理COCO数据集</span></span><br><span class="line"><span class="keyword">from</span> selectivesearch <span class="keyword">import</span> selective_search <span class="comment"># 从selectivesearch模块导入selective_search函数，用于进行选择性搜索</span></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io, util, color <span class="comment"># 从selectivesearch模块导入selective_search函数，用于进行选择性搜索</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_iou</span>(<span class="params">a, b</span>): <span class="comment"># 定义计算IoU（交并比）的函数，输入参数为两个矩形框</span></span><br><span class="line">    <span class="comment"># 矩形框的格式为：[左上角x坐标，左上角y坐标，宽度，高度]</span></span><br><span class="line">    a_min_x, a_min_y, a_delta_x, a_delta_y = a</span><br><span class="line">    b_min_x, b_min_y, b_delta_x, b_delta_y = b</span><br><span class="line">    a_max_x = a_min_x + a_delta_x</span><br><span class="line">    a_max_y = a_min_y + a_delta_y</span><br><span class="line">    b_max_x = b_min_x + b_delta_x</span><br><span class="line">    b_max_y = b_min_y + b_delta_y</span><br><span class="line">    <span class="comment"># 如果两个矩形框没有交集，则IoU为0</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">min</span>(a_max_y, b_max_y) &lt; <span class="built_in">max</span>(a_min_y, b_min_y) <span class="keyword">or</span> <span class="built_in">min</span>(a_max_x, b_max_x) &lt; <span class="built_in">max</span>(a_min_x, b_min_x):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 计算交集的面积</span></span><br><span class="line">        intersect_area = (<span class="built_in">min</span>(a_max_y, b_max_y) - <span class="built_in">max</span>(a_min_y, b_min_y) + <span class="number">1</span>) * \</span><br><span class="line">            (<span class="built_in">min</span>(a_max_x, b_max_x) - <span class="built_in">max</span>(a_min_x, b_min_x) + <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 计算并集的面积</span></span><br><span class="line">        union_area = (a_delta_x + <span class="number">1</span>) * (a_delta_y + <span class="number">1</span>) + \</span><br><span class="line">            (b_delta_x + <span class="number">1</span>) * (b_delta_y + <span class="number">1</span>) - intersect_area</span><br><span class="line">        <span class="comment"># 返回IoU</span></span><br><span class="line">        <span class="keyword">return</span> intersect_area / union_area</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ss_img</span>(<span class="params">img_id, coco, cat_dict, args</span>): <span class="comment"># 定义selective_search函数，输入参数为图像id、COCO数据集、类别字典、命令行参数</span></span><br><span class="line">    img_path = os.path.join(args.data_dir, args.mode +</span><br><span class="line">                            <span class="string">&#x27;2017&#x27;</span>, <span class="string">&#x27;%012d.jpg&#x27;</span> % img_id) <span class="comment"># 获取图像的路径</span></span><br><span class="line">    coco_dict = &#123;cat[<span class="string">&#x27;id&#x27;</span>]: cat[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">                 <span class="keyword">for</span> cat <span class="keyword">in</span> coco.loadCats(coco.getCatIds())&#125;  <span class="comment"># 创建一个字典，将COCO数据集的类别ID映射到类别名</span></span><br><span class="line">    img = io.imread(img_path) <span class="comment"># 读取图像</span></span><br><span class="line">    <span class="keyword">if</span> img.ndim == <span class="number">2</span>:    <span class="comment"># 如果图像是灰度图，则将其转换为RGB图像</span></span><br><span class="line">        img = color.gray2rgb(img)</span><br><span class="line">    _, ss_regions = selective_search(   <span class="comment"># 对图像进行选择性搜索，获取候选区域</span></span><br><span class="line">        img, args.scale, args.sigma, args.min_size)         <span class="comment"># &#x27;rect&#x27;: (left, top, width, height)</span></span><br><span class="line">    anns = coco.loadAnns(coco.getAnnIds(</span><br><span class="line">        imgIds=[img_id], catIds=coco.getCatIds(catNms=args.cats))) <span class="comment"># 获取图像的标注信息</span></span><br><span class="line">    pos_regions = [] <span class="comment"># 初始化正样本区域列表</span></span><br><span class="line">    neg_regions = [] <span class="comment"># 初始化负样本区域列表</span></span><br><span class="line">    h = img.shape[<span class="number">0</span>] <span class="comment"># 获取图像的高度</span></span><br><span class="line">    w = img.shape[<span class="number">1</span>] <span class="comment"># 获取图像的宽度</span></span><br><span class="line">    <span class="keyword">for</span> region <span class="keyword">in</span> ss_regions: <span class="comment"># 遍历每个候选区域</span></span><br><span class="line">        <span class="keyword">for</span> ann <span class="keyword">in</span> anns: <span class="comment"># 遍历每个标注信息</span></span><br><span class="line">            iou = cal_iou(region[<span class="string">&#x27;rect&#x27;</span>], ann[<span class="string">&#x27;bbox&#x27;</span>]) <span class="comment"># 计算候选区域和标注区域的IoU</span></span><br><span class="line">            <span class="keyword">if</span> iou &gt;= <span class="number">0.1</span>: <span class="comment"># 如果IoU大于等于0.1，则认为候选区域是有效的</span></span><br><span class="line">                rect = <span class="built_in">list</span>(region[<span class="string">&#x27;rect&#x27;</span>]) <span class="comment"># 获取候选区域的矩形框</span></span><br><span class="line">                rect[<span class="number">0</span>] = rect[<span class="number">0</span>] / w <span class="comment"># 将矩形框的x坐标转换为相对于图像宽度的比例</span></span><br><span class="line">                rect[<span class="number">1</span>] = rect[<span class="number">1</span>] / h <span class="comment"># 将矩形框的y坐标转换为相对于图像高度的比例</span></span><br><span class="line">                rect[<span class="number">2</span>] = rect[<span class="number">0</span>] + rect[<span class="number">2</span>] / w <span class="comment"># 将矩形框的宽度转换为相对于图像宽度的比例</span></span><br><span class="line">                rect[<span class="number">3</span>] = rect[<span class="number">1</span>] + rect[<span class="number">3</span>] / h <span class="comment"># 将矩形框的高度转换为相对于图像高度的比例</span></span><br><span class="line">                gt_rect = <span class="built_in">list</span>(ann[<span class="string">&#x27;bbox&#x27;</span>]) <span class="comment"># 获取标注区域的矩形框</span></span><br><span class="line">                gt_rect[<span class="number">0</span>] = gt_rect[<span class="number">0</span>] / w <span class="comment"># 将矩形框的x坐标转换为相对于图像宽度的比例</span></span><br><span class="line">                gt_rect[<span class="number">1</span>] = gt_rect[<span class="number">1</span>] / h <span class="comment"># 将矩形框的y坐标转换为相对于图像高度的比例</span></span><br><span class="line">                gt_rect[<span class="number">2</span>] = gt_rect[<span class="number">0</span>] + gt_rect[<span class="number">2</span>] / w <span class="comment"># 将矩形框的宽度转换为相对于图像宽度的比例</span></span><br><span class="line">                gt_rect[<span class="number">3</span>] = gt_rect[<span class="number">1</span>] + gt_rect[<span class="number">3</span>] / h <span class="comment"># 将矩形框的高度转换为相对于图像高度的比例</span></span><br><span class="line">                <span class="keyword">if</span> iou &gt;= <span class="number">0.5</span>: <span class="comment"># 如果IoU大于等于0.5，则认为候选区域是正样本</span></span><br><span class="line">                    pos_regions.append(&#123;<span class="string">&#x27;rect&#x27;</span>: rect, </span><br><span class="line">                                        <span class="string">&#x27;gt_rect&#x27;</span>: gt_rect,</span><br><span class="line">                                        <span class="string">&#x27;category&#x27;</span>: cat_dict[coco_dict[ann[<span class="string">&#x27;category_id&#x27;</span>]]]&#125;)</span><br><span class="line">                <span class="keyword">else</span>: <span class="comment"># 否则，认为候选区域是负样本</span></span><br><span class="line">                    neg_regions.append(&#123;<span class="string">&#x27;rect&#x27;</span>: rect, </span><br><span class="line">                                        <span class="string">&#x27;gt_rect&#x27;</span>: gt_rect,</span><br><span class="line">                                        <span class="string">&#x27;category&#x27;</span>: <span class="number">0</span>&#125;)</span><br><span class="line">    <span class="keyword">return</span> pos_regions, neg_regions <span class="comment"># 返回正样本区域和负样本区域</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(<span class="string">&#x27;parser to create regions&#x27;</span>) <span class="comment"># 创建一个命令行参数解析器，用于处理命令行参数。</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;D:\\WritePapers\\object_detection_basics\\Datasets\\COCO2017\\&#x27;</span>) <span class="comment"># 指定COCO2017数据集的路径</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--mode&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;train&#x27;</span>)   <span class="comment"># train/val</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save_dir&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;D:\\WritePapers\\object_detection_basics\\Datasets\\COCO2017\\&#x27;</span>) <span class="comment">#指定保存结果的路径</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cats&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, nargs=<span class="string">&#x27;*&#x27;</span>, default=[</span><br><span class="line">                        <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>, <span class="string">&#x27;elephant&#x27;</span>, <span class="string">&#x27;bear&#x27;</span>, <span class="string">&#x27;zebra&#x27;</span>, <span class="string">&#x27;giraffe&#x27;</span>]) <span class="comment"># 指定需要处理的类别</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--scale&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">30.0</span>) <span class="comment"># 指定选择性搜索的尺度</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--sigma&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.8</span>) <span class="comment"># 指定选择性搜索的高斯平滑参数</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--min_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">50</span>) <span class="comment"># 指定选择性搜索的最小区域大小</span></span><br><span class="line">    args = parser.parse_args() <span class="comment"># 解析命令行参数，并将结果保存在args中</span></span><br><span class="line">    coco = COCO(os.path.join(args.data_dir, <span class="string">&#x27;annotations&#x27;</span>,</span><br><span class="line">                             <span class="string">&#x27;instances_%s2017.json&#x27;</span> % args.mode)) <span class="comment">#加载COCO2017数据集的标注信息</span></span><br><span class="line">    cat_dict = &#123;args.cats[i]: i+<span class="number">1</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(args.cats))&#125; <span class="comment"># 创建一个字典，将类别名称映射到类别ID</span></span><br><span class="line">    cat_dict[<span class="string">&#x27;background&#x27;</span>] = <span class="number">0</span> <span class="comment"># 将背景类别的ID设置为0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># get relavant image ids</span></span><br><span class="line">    <span class="keyword">if</span> args.mode == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">        num_cat = <span class="number">400</span> <span class="comment"># 如果运行模式为训练，则每个类别的图像数量设置为400</span></span><br><span class="line">    <span class="keyword">if</span> args.mode == <span class="string">&#x27;val&#x27;</span>:</span><br><span class="line">        num_cat = <span class="number">100</span> <span class="comment"># 如果运行模式为验证，则每个类别的图像数量设置为100</span></span><br><span class="line">    img_ids = []</span><br><span class="line">    cat_ids = coco.getCatIds(catNms=args.cats) <span class="comment"># 获取需要处理的类别的ID</span></span><br><span class="line">    <span class="keyword">for</span> cat_id <span class="keyword">in</span> cat_ids:</span><br><span class="line">        cat_img_ids = coco.getImgIds(catIds=[cat_id]) <span class="comment"># 获取该类别的所有图像ID</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(cat_img_ids) &gt; num_cat:</span><br><span class="line">            cat_img_ids = random.sample(cat_img_ids, num_cat) <span class="comment"># 如果该类别的图像数量大于num_cat，则随机选择num_cat个图像</span></span><br><span class="line">        img_ids += cat_img_ids <span class="comment"># 将选择的图像ID添加到图像ID列表</span></span><br><span class="line">    img_ids = <span class="built_in">list</span>(<span class="built_in">set</span>(img_ids)) <span class="comment"># 去除重复的图像ID</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># selective_search each image</span></span><br><span class="line">    <span class="comment"># [&#123;&#x27;id&#x27;: 1, &#x27;pos_regions&#x27;:[...], &#x27;neg_regions&#x27;:[...]&#125;, ...]</span></span><br><span class="line"></span><br><span class="line">    num_imgs = <span class="built_in">len</span>(img_ids) <span class="comment"># 获取图像的数量</span></span><br><span class="line">    ss_regions = [] <span class="comment"># 初始化选择性搜索的区域列表</span></span><br><span class="line">    p = ProgressBar(widgets=[<span class="string">&#x27;Progress: &#x27;</span>, Percentage(),</span><br><span class="line">                             <span class="string">&#x27; &#x27;</span>, Bar(<span class="string">&#x27;#&#x27;</span>), <span class="string">&#x27; &#x27;</span>, Timer(), <span class="string">&#x27; &#x27;</span>, ETA()]) <span class="comment"># 创建一个进度条</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> p(<span class="built_in">range</span>(num_imgs)): <span class="comment"># 遍历每个图像</span></span><br><span class="line">        img_id = img_ids[i] <span class="comment"># 获取当前图像的ID</span></span><br><span class="line">        pos_regions, neg_regions = ss_img(img_id, coco, cat_dict, args) <span class="comment"># 对当前图像进行选择性搜索，获取正样本区域和负样本区域</span></span><br><span class="line">        ss_regions.append(&#123;<span class="string">&#x27;id&#x27;</span>: img_id,</span><br><span class="line">                           <span class="string">&#x27;pos_regions&#x27;</span>: pos_regions,</span><br><span class="line">                           <span class="string">&#x27;neg_regions&#x27;</span>: neg_regions&#125;)<span class="comment"># 将当前图像的ID、正样本区域和负样本区域添加到选择性搜索的区域列表中</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># save</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(args.save_dir, <span class="string">&#x27;%s.json&#x27;</span> % args.mode), <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        json.dump(ss_regions, f) <span class="comment"># 将选择性搜索的区域列表保存为JSON格式</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="设置ROI-Pooling模块、特征提取网络模型及多目标损失函数"><a href="#设置ROI-Pooling模块、特征提取网络模型及多目标损失函数" class="headerlink" title="设置ROI Pooling模块、特征提取网络模型及多目标损失函数"></a>设置ROI Pooling模块、特征提取网络模型及多目标损失函数</h4><p><strong>ROI Plooing模块</strong><br><strong>roipooling.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ROIPooling</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, output_size</span>): <span class="comment"># 初始化函数，设置输出大小</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.maxpool = nn.AdaptiveMaxPool2d(output_size)  <span class="comment"># 创建一个自适应最大池化层，输出大小为output_size</span></span><br><span class="line">        self.size = output_size  <span class="comment"># 设置输出大小</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, imgs, rois, roi_idx</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param img: img:批次内的图像</span></span><br><span class="line"><span class="string">        :param rois: rois:[[单张图片内框体],[],[]]</span></span><br><span class="line"><span class="string">        :param roi_idx: [2]*6-------&gt;[2, 2, 2, 2, 2, 2]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        n = rois.shape[<span class="number">0</span>] <span class="comment"># 获取roi的数量</span></span><br><span class="line">        h = imgs.shape[<span class="number">2</span>] <span class="comment"># 获取图像的高度</span></span><br><span class="line">        w = imgs.shape[<span class="number">3</span>] <span class="comment"># 获取图像的宽度</span></span><br><span class="line"></span><br><span class="line">        x1 = rois[:, <span class="number">0</span>] <span class="comment"># 获取所有区域的左上角x坐标</span></span><br><span class="line">        y1 = rois[:, <span class="number">1</span>] <span class="comment"># 获取所有区域的左上角y坐标</span></span><br><span class="line">        x2 = rois[:, <span class="number">2</span>] <span class="comment"># 获取所有区域的右下角x坐标</span></span><br><span class="line">        y2 = rois[:, <span class="number">3</span>] <span class="comment"># 获取所有区域的右下角y坐标</span></span><br><span class="line"></span><br><span class="line">        x1 = np.floor(x1 * w).astype(<span class="built_in">int</span>) <span class="comment"># 将x1坐标转换为图像的实际坐标</span></span><br><span class="line">        x2 = np.ceil(x2 * w).astype(<span class="built_in">int</span>) <span class="comment"># 将x2坐标转换为图像的实际坐标</span></span><br><span class="line">        y1 = np.floor(y1 * h).astype(<span class="built_in">int</span>) <span class="comment"># 将y1坐标转换为图像的实际坐标</span></span><br><span class="line">        y2 = np.ceil(y2 * h).astype(<span class="built_in">int</span>) <span class="comment"># 将y2坐标转换为图像的实际坐标</span></span><br><span class="line"></span><br><span class="line">        res = [] <span class="comment"># 初始化结果列表</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n): <span class="comment"># 遍历每个区域</span></span><br><span class="line">            img = imgs[roi_idx[i]].unsqueeze(dim=<span class="number">0</span>) <span class="comment"># 获取第i个区域所在的图像</span></span><br><span class="line">            img = img[:, :, y1[i]:y2[i], x1[i]:x2[i]]  <span class="comment"># 对图像进行裁剪，只保留区域内的部分</span></span><br><span class="line">            img = self.maxpool(img) <span class="comment"># 对裁剪后的图像进行最大池化操作</span></span><br><span class="line">            res.append(img) <span class="comment"># 将处理后的图像添加到结果列表中</span></span><br><span class="line">        res = torch.cat(res, dim=<span class="number">0</span>) <span class="comment"># 将所有处理后的图像沿着批次维度拼接起来，最终res保存了所有池化后的ROI区域</span></span><br><span class="line">        <span class="keyword">return</span> res</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">    imgs = torch.randn(<span class="number">2</span>, <span class="number">10</span>, <span class="number">224</span>, <span class="number">224</span>) <span class="comment"># 创建一个随机的图像张量（batch_size, Channel, Height, Weight）</span></span><br><span class="line">    rois = np.array([[<span class="number">0.2</span>, <span class="number">0.2</span>, <span class="number">0.4</span>, <span class="number">0.4</span>],</span><br><span class="line">                    [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.7</span>, <span class="number">0.7</span>],</span><br><span class="line">                    [<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.3</span>]]) <span class="comment"># 创建一个随机的区域张量（x1, y1, x2, y2）</span></span><br><span class="line">    <span class="comment"># roi_idx表示每个区域（Region of Interest，ROI）所在的图像的索引</span></span><br><span class="line">    <span class="comment"># 表示有三个区域，前两个区域在第一张图像上（索引为0），第三个区域在第二张图像上（索引为1）</span></span><br><span class="line">    roi_idx = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">    r = ROIPooling((<span class="number">7</span>, <span class="number">7</span>)) <span class="comment"># (7, 7)表示池化后的输出大小为7x7。这意味着无论输入区域的大小如何，ROIPooling层都会将其池化为7x7的大小</span></span><br><span class="line">    <span class="built_in">print</span>(r.forward(imgs, rois, roi_idx).shape)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>fast_rcnn.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> .roipooling <span class="keyword">import</span> ROIPooling <span class="comment"># 从当前目录下的roipooling模块导入ROIPooling类</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">FastRCNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, num_classes</span>):<span class="comment"># 初始化方法，接收一个参数：类别数量</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.num_classes = num_classes <span class="comment"># 将类别数量保存为实例变量</span></span><br><span class="line">        vgg = torchvision.models.vgg19_bn(pretrained=<span class="literal">True</span>) <span class="comment"># 加载预训练的VGG19模型</span></span><br><span class="line">        <span class="comment"># 获取VGG19模型的特征提取部分：通过卷积和池化操作提取图像的特征</span></span><br><span class="line">        <span class="comment"># vgg.features.children(): vgg.features获取VGG19模型的特征提取部分，children()方法获取这部分的所有子模块。这些子模块是一系列的卷积层、激活函数和池化层。</span></span><br><span class="line">        <span class="comment"># list(vgg.features.children()): 将子模块的迭代器转换为列表</span></span><br><span class="line">        <span class="comment"># list(vgg.features.children())[:-1]: 使用切片操作获取除最后一个子模块外的所有子模块。在VGG19模型中，最后一个子模块是一个池化层。</span></span><br><span class="line">        <span class="comment"># *list(vgg.features.children())[:-1]: 使用*操作符将列表解包，这样每个子模块都会作为nn.Sequential的一个单独参数传入。</span></span><br><span class="line">        <span class="comment"># nn.Sequential(*list(vgg.features.children())[:-1]): nn.Sequential是一个容器，它按照在构造函数中传入的顺序保存各个模块。</span></span><br><span class="line">        self.features = nn.Sequential(*<span class="built_in">list</span>(vgg.features.children())[:-<span class="number">1</span>])</span><br><span class="line">        self.roipool = ROIPooling(output_size=(<span class="number">7</span>, <span class="number">7</span>)) <span class="comment"># 创建ROIPooling层，输出大小为7x7</span></span><br><span class="line">        <span class="comment"># vgg.classifier.children(): vgg.classifier获取VGG19模型的分类部分，children()方法获取这部分的所有子模块。这些子模块是一系列的全连接层、激活函数和Dropout层。</span></span><br><span class="line">        <span class="comment"># list(vgg.classifier.children())[:-1]: 使用切片操作获取除最后一个子模块外的所有子模块。在VGG19模型中，最后一个子模块是一个全连接层，用于输出每个类别的概率。</span></span><br><span class="line">        self.output = nn.Sequential(*<span class="built_in">list</span>(vgg.classifier.children())[:-<span class="number">1</span>]) <span class="comment"># 获取VGG19模型的分类部分</span></span><br><span class="line">        self.prob = nn.Linear(<span class="number">4096</span>, num_classes+<span class="number">1</span>)<span class="comment"># 创建一个线性层，用于输出每个类别的概率</span></span><br><span class="line">        self.loc = nn.Linear(<span class="number">4096</span>, <span class="number">4</span> * (num_classes + <span class="number">1</span>)) <span class="comment"># 创建一个线性层，用于输出每个类别的边界框位置</span></span><br><span class="line"></span><br><span class="line">        self.cat_loss = nn.CrossEntropyLoss() <span class="comment"># 创建交叉熵损失函数，用于计算类别损失</span></span><br><span class="line">        self.loc_loss = nn.SmoothL1Loss() <span class="comment"># 创建Smooth L1损失函数，用于计算位置损失</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img, rois, roi_idx</span>): <span class="comment"># 接收三个参数：图像、区域、区域索引</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param img: img:批次内的图像</span></span><br><span class="line"><span class="string">        :param rois: rois:[[单张图片内框体],[],[]]</span></span><br><span class="line"><span class="string">        :param roi_idx: [2]*6-------&gt;[2, 2, 2, 2, 2, 2]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        res = self.features(img) <span class="comment"># 对图像进行特征提取</span></span><br><span class="line">        res = self.roipool(res, rois, roi_idx) <span class="comment"># 对特征图进行ROIPooling</span></span><br><span class="line">        res = res.view(res.shape[<span class="number">0</span>], -<span class="number">1</span>) <span class="comment"># 将ROIPooling的结果展平</span></span><br><span class="line">        features = self.output(res) <span class="comment"># 对展平的结果进行分类</span></span><br><span class="line">        prob = self.prob(features) <span class="comment"># 计算每个类别的概率</span></span><br><span class="line">        loc = self.loc(features).view(-<span class="number">1</span>, self.num_classes+<span class="number">1</span>, <span class="number">4</span>) <span class="comment"># 计算每个类别的边界框位置</span></span><br><span class="line">        <span class="comment"># 输出的张量的形状就变成了(N, num_classes + 1, 4)，其中N是批次大小，num_classes + 1是类别数量（包括背景类别），4是边界框的参数数量。</span></span><br><span class="line">        <span class="comment"># 相当于最终输出是==&gt;每个图像都会输出：每个类别对应的一个边界框，这个边界框由4个参数确定。</span></span><br><span class="line">        <span class="keyword">return</span> prob, loc</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">loss</span>(<span class="params">self, prob, bbox, label, gt_bbox, lmb=<span class="number">1.0</span></span>): <span class="comment"># 计算损失的方法，接收五个参数：预测类别概率、预测边界框、真实类别标签、真实边界框、lambda</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        :param prob: 预测类别</span></span><br><span class="line"><span class="string">        :param bbox:预测边界框</span></span><br><span class="line"><span class="string">        :param label:真实类别</span></span><br><span class="line"><span class="string">        :param gt_bbox:真实边界框</span></span><br><span class="line"><span class="string">        :param lmb:</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        loss_cat = self.cat_loss(prob, label) <span class="comment"># 计算类别损失</span></span><br><span class="line">        lbl = label.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(label.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">4</span>) <span class="comment"># 将标签扩展为与边界框相同的形状 (N, 1, 4)，N：标签的数量 1：每个标签对应一个边界框 4：边界框的参数数量</span></span><br><span class="line">        mask = (label != <span class="number">0</span>).<span class="built_in">float</span>().view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>).expand(label.shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">4</span>) <span class="comment"># 将标签扩展为与边界框相同的形状</span></span><br><span class="line">        loss_loc = self.loc_loss(gt_bbox * mask, bbox.gather(<span class="number">1</span>, lbl).squeeze(<span class="number">1</span>) * mask) <span class="comment"># 计算位置损失</span></span><br><span class="line">        loss = loss_cat + lmb * loss_loc <span class="comment"># 计算总损失</span></span><br><span class="line">        <span class="keyword">return</span> loss, loss_cat, loss_loc <span class="comment"># 返回总损失、类别损失和位置损失</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="训练网络模型"><a href="#训练网络模型" class="headerlink" title="训练网络模型"></a>训练网络模型</h4><p><strong>train.py</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse <span class="comment"># 导入argparse模块，用于处理命令行参数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> dataset <span class="keyword">import</span> COCOdataset</span><br><span class="line"><span class="keyword">from</span> fast_rcnn <span class="keyword">import</span> FastRCNN</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义训练函数，输入参数为模型、训练数据集、优化器和命令行参数</span></span><br><span class="line"><span class="comment"># 训练时要用gpu，记得把参数--cuda的默认值改为True</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model, train_dataset, optimizer, args</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    num_batches = <span class="built_in">len</span>(train_dataset) // args.batch_size  <span class="comment"># 计算批次数量</span></span><br><span class="line">    indexes = np.random.shuffle(np.arange(<span class="built_in">len</span>(train_dataset))) <span class="comment"># 随机打乱数据集的索引</span></span><br><span class="line">    <span class="comment"># 初始化损失和准确率</span></span><br><span class="line">    loss_all = <span class="number">0</span></span><br><span class="line">    loss_cat_all = <span class="number">0</span></span><br><span class="line">    loss_loc_all = <span class="number">0</span></span><br><span class="line">    accuracy = <span class="number">0</span></span><br><span class="line">    num_samples = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历每个批次</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_batches):</span><br><span class="line">        <span class="comment"># 初始化图像、区域、ROI索引、相对位置和类别列表</span></span><br><span class="line">        imgs = []</span><br><span class="line">        rects = []</span><br><span class="line">        roi_idxs = []</span><br><span class="line">        rela_locs = []</span><br><span class="line">        cats = []</span><br><span class="line">        <span class="comment"># 遍历每个样本</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(args.batch_size):</span><br><span class="line">            <span class="comment"># img:原始图像; rect:建议框体;roi_idx_len:正负样本框体总数;rela_loc:调整后框体;cat:类别</span></span><br><span class="line">            img, rect, roi_idx_len, rela_loc, cat = train_dataset[i *</span><br><span class="line">                                                                 args.batch_size+j]</span><br><span class="line">            <span class="comment"># print(img, rect, roi_idx_len, gt_rect, cat)</span></span><br><span class="line">            <span class="comment"># 添加到对应的列表中</span></span><br><span class="line">            imgs.append(img.unsqueeze(<span class="number">0</span>))</span><br><span class="line">            rects += rect</span><br><span class="line">            rela_locs += rela_loc</span><br><span class="line">            roi_idxs += ([j] * roi_idx_len)   <span class="comment"># [2]*6-------&gt;[2, 2, 2, 2, 2, 2]</span></span><br><span class="line">            cats += cat</span><br><span class="line">        <span class="comment"># 将列表转换为张量或数组</span></span><br><span class="line">        imgs = torch.cat(imgs, dim=<span class="number">0</span>)</span><br><span class="line">        rects = np.array(rects)</span><br><span class="line">        rela_locs = torch.FloatTensor(rela_locs)</span><br><span class="line">        cats = torch.LongTensor(cats)</span><br><span class="line">        <span class="comment"># print(imgs, rects, roi_idxs, rela_locs, cats)</span></span><br><span class="line">        <span class="comment"># 如果使用CUDA，则将张量移动到GPU上</span></span><br><span class="line">        <span class="keyword">if</span> args.cuda:</span><br><span class="line">            imgs = imgs.cuda()</span><br><span class="line">            rela_locs = rela_locs.cuda()</span><br><span class="line">            cats = cats.cuda()</span><br><span class="line">        <span class="comment"># 清空梯度</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 前向传播，计算预测的概率和边界框</span></span><br><span class="line">        prob, bbox = model.forward(imgs, rects, roi_idxs)</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss, loss_cat, loss_loc = model.loss(prob, bbox, cats, rela_locs)</span><br><span class="line">        <span class="comment"># 反向传播，计算梯度</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        <span class="comment"># 更新参数</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># 更新损失和准确率</span></span><br><span class="line">        num_samples += <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_all += loss.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_cat_all += loss_cat.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_loc_all += loss_loc.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        accuracy += (torch.argmax(prob.detach(), dim=-<span class="number">1</span>) == cats).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="comment"># 返回模型、损失和准确率</span></span><br><span class="line">    <span class="keyword">return</span> model, loss_all/num_samples, loss_cat_all/num_samples, loss_loc_all/num_samples, accuracy/num_samples</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义测试函数，输入参数为模型、验证数据集和命令行参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">model, val_dataset, args</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    num_batches = <span class="built_in">len</span>(val_dataset) // args.batch_size <span class="comment"># 计算批次数量</span></span><br><span class="line">    indexes = np.random.shuffle(np.arange(<span class="built_in">len</span>(val_dataset))) <span class="comment"># 随机打乱数据集的索引</span></span><br><span class="line">    <span class="comment"># 初始化损失和准确率</span></span><br><span class="line">    loss_all = <span class="number">0</span></span><br><span class="line">    loss_cat_all = <span class="number">0</span></span><br><span class="line">    loss_loc_all = <span class="number">0</span></span><br><span class="line">    accuracy = <span class="number">0</span></span><br><span class="line">    num_samples = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 遍历每个批次</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_batches):</span><br><span class="line">        <span class="comment"># 初始化图像、区域、ROI索引、相对位置和类别列表</span></span><br><span class="line">        imgs = []</span><br><span class="line">        rects = []</span><br><span class="line">        roi_idxs = []</span><br><span class="line">        rela_locs = []</span><br><span class="line">        cats = []</span><br><span class="line">        <span class="comment"># 遍历每个样本</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(args.batch_size):</span><br><span class="line">            <span class="comment"># 加载图像、区域、ROI索引长度、相对位置和类别</span></span><br><span class="line">            img, rect, roi_idx_len, rela_loc, cat = val_dataset[i *</span><br><span class="line">                                                               args.batch_size+j]</span><br><span class="line">            <span class="comment"># print(img, rect, roi_idx_len, gt_rect, cat)</span></span><br><span class="line">            <span class="comment"># 添加到对应的列表中</span></span><br><span class="line">            imgs.append(img.unsqueeze(<span class="number">0</span>))</span><br><span class="line">            rects += rect</span><br><span class="line">            rela_locs += rela_loc</span><br><span class="line">            roi_idxs += ([j] * roi_idx_len)</span><br><span class="line">            cats += cat</span><br><span class="line">        <span class="comment"># 将列表转换为张量或数组</span></span><br><span class="line">        imgs = torch.cat(imgs, dim=<span class="number">0</span>)</span><br><span class="line">        rects = np.array(rects)</span><br><span class="line">        rela_locs = torch.FloatTensor(rela_locs)</span><br><span class="line">        cats = torch.LongTensor(cats)</span><br><span class="line">        <span class="comment"># print(imgs, rects, roi_idxs, rela_locs, cats)</span></span><br><span class="line">        <span class="comment"># 如果使用CUDA，则将张量移动到GPU</span></span><br><span class="line">        <span class="keyword">if</span> args.cuda:</span><br><span class="line">            imgs = imgs.cuda()</span><br><span class="line">            rela_locs = rela_locs.cuda()</span><br><span class="line">            cats = cats.cuda()</span><br><span class="line">        <span class="comment"># 前向传播，计算预测的概率和边界框</span></span><br><span class="line">        prob, bbox = model.forward(imgs, rects, roi_idxs)</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss, loss_cat, loss_loc = model.loss(prob, bbox, cats, rela_locs)</span><br><span class="line">        <span class="comment"># 更新损失和准确率</span></span><br><span class="line">        num_samples += <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_all += loss.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_cat_all += loss_cat.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        loss_loc_all += loss_loc.item() * <span class="built_in">len</span>(cats)</span><br><span class="line">        accuracy += (torch.argmax(prob.detach(), dim=-<span class="number">1</span>) == cats).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="comment"># 返回模型、损失和准确率</span></span><br><span class="line">    <span class="keyword">return</span> model, loss_all/num_samples, loss_cat_all/num_samples, loss_loc_all/num_samples, accuracy/num_samples</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(<span class="string">&#x27;parser for fast-rcnn&#x27;</span>) <span class="comment"># 创建一个命令行参数解析器</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">16</span>) <span class="comment"># 添加一个命令行参数--batch_size，用于指定批次大小，默认值为16</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>) <span class="comment"># 添加一个命令行参数--num_classes，用于指定类别数量，默认值为10</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--learning_rate&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">2e-4</span>) <span class="comment"># 添加一个命令行参数--learning_rate，用于指定学习率，默认值为2e-4</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">20</span>) <span class="comment"># 添加一个命令行参数--epochs，用于指定训练的轮数，默认值为20</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save_path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&#x27;./model/fast_rcnn.pkl&#x27;</span>) <span class="comment"># 添加一个命令行参数--save_path，用于指定模型保存的路径，默认值为&#x27;./model/fast_rcnn.pkl&#x27;</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cuda&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    args = parser.parse_args() <span class="comment"># 解析命令行参数，并将结果保存在args中</span></span><br><span class="line">    train_dataset = COCOdataset(mode=<span class="string">&#x27;train&#x27;</span>) <span class="comment"># 解析命令行参数，并将结果保存在args中</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-----------------&quot;</span>,train_dataset.__len__())</span><br><span class="line">    valid_dataset = COCOdataset(mode=<span class="string">&#x27;val&#x27;</span>) <span class="comment"># 创建一个COCOdataset实例，模式为&#x27;val&#x27;</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-----------------&quot;</span>, valid_dataset.__len__())</span><br><span class="line">    model = FastRCNN(num_classes=args.num_classes) <span class="comment"># 创建一个FastRCNN模型实例，类别数量为args.num_classes</span></span><br><span class="line">    <span class="keyword">if</span> args.cuda:<span class="comment"># 如果args.cuda为True，则将模型移动到GPU上</span></span><br><span class="line">        model.cuda()</span><br><span class="line">    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate) <span class="comment"># 创建一个Adam优化器，优化目标为模型的参数，学习率为args.learning_rate</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.epochs):<span class="comment"># 对于每一个训练轮次</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Epoch %d:&quot;</span> % epoch)<span class="comment"># 打印当前轮次</span></span><br><span class="line">        model, train_loss, train_loss_cat, train_loss_loc, train_accuracy = train(</span><br><span class="line">            model, train_dataset, optimizer, args) <span class="comment"># 调用train函数进行训练，并获取模型、总损失、类别损失、位置损失和准确率</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Train: loss=%.4f, loss_cat=%.4f, loss_loc=%.4f, accuracy=%.4f&quot;</span> %</span><br><span class="line">              (train_loss, train_loss_cat, train_loss_loc, train_accuracy))<span class="comment"># 打印训练的损失和准确率</span></span><br><span class="line">        model, valid_loss, valid_loss_cat, valid_loss_loc, valid_accuracy = test(</span><br><span class="line">            model, valid_dataset, args)<span class="comment"># 打印训练的损失和准确率</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Valid: loss=%.4f, loss_cat=%.4f, loss_loc=%.4f, accuracy=%.4f&quot;</span> %</span><br><span class="line">              (valid_loss, valid_loss_cat, valid_loss_loc, valid_accuracy))<span class="comment"># 打印验证的损失和准确率</span></span><br><span class="line"></span><br><span class="line">    torch.save(model.state_dict(), args.save_path) <span class="comment"># 将模型的状态字典保存到args.save_path指定的路径</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main() <span class="comment"># 如果当前脚本被直接运行，则调用main函数</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> skimage</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image, ImageDraw, ImageFont</span><br><span class="line"><span class="keyword">from</span> selectivesearch <span class="keyword">import</span> selective_search <span class="comment"># 从selectivesearch模块导入selective_search函数，用于进行选择性搜索</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> fast_rcnn <span class="keyword">import</span> FastRCNN</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试时如果用gpu，则：</span></span><br><span class="line"><span class="comment"># 1. 将模型加载到gpu上：trained_net = torch.load(args.model)，不加 map_location = &#x27;cpu&#x27;</span></span><br><span class="line"><span class="comment"># 2. 把参数--cuda的默认值改为True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义计算IoU（交并比）的函数，输入参数为两个矩形框</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cal_iou</span>(<span class="params">a, b</span>):</span><br><span class="line">    a_min_x, a_min_y, a_max_x, a_max_y = a</span><br><span class="line">    b_min_x, b_min_y, b_max_x, b_max_y = b</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">min</span>(a_max_y, b_max_y) &lt; <span class="built_in">max</span>(a_min_y, b_min_y) <span class="keyword">or</span> <span class="built_in">min</span>(a_max_x, b_max_x) &lt; <span class="built_in">max</span>(a_min_x, b_min_x):</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        intersect_area = (<span class="built_in">min</span>(a_max_y, b_max_y) - <span class="built_in">max</span>(a_min_y, b_min_y) + <span class="number">1</span>) * \</span><br><span class="line">            (<span class="built_in">min</span>(a_max_x, b_max_x) - <span class="built_in">max</span>(a_min_x, b_min_x) + <span class="number">1</span>)</span><br><span class="line">        union_area = (a_max_x - a_min_x + <span class="number">1</span>) * (a_max_y - a_min_y + <span class="number">1</span>) + \</span><br><span class="line">            (b_max_x - b_min_x + <span class="number">1</span>) * (b_max_y - b_min_y + <span class="number">1</span>) - intersect_area</span><br><span class="line">    <span class="keyword">return</span> intersect_area / union_area</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(<span class="string">&#x27;parser for testing fast-rcnn&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--jpg_path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                        default=<span class="string">&#x27;D:\\WritePapers\\object_detection_basics\\Datasets\\COCO2017\\val2017\\000000241326.jpg&#x27;</span>)<span class="comment"># 添加一个命令行参数--jpg_path，用于指定待测试的图像的路径，默认值为&#x27;/devdata/project/ai_learn/COCO2017/val2017/000000241326.jpg&#x27;</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save_path&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;sample.png&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save_type&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;png&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--model&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;./model/fast_rcnn.pkl&#x27;</span>) <span class="comment"># 添加一个命令行参数--model，用于指定模型的路径，默认值为&#x27;./model/fast_rcnn.pkl&#x27;</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num_classes&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--scale&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">30.0</span>) <span class="comment"># 添加一个命令行参数--scale，用于指定选择性搜索的尺度，默认值为30.0</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--sigma&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.8</span>) <span class="comment"># 添加一个命令行参数--sigma，用于指定选择性搜索的高斯平滑参数，默认值为0.8</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--min_size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">50</span>) <span class="comment"># 添加一个命令行参数--min_size，用于指定选择性搜索的最小区域大小，默认值为50</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cats&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, nargs=<span class="string">&#x27;*&#x27;</span>, default=[</span><br><span class="line">                        <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>, <span class="string">&#x27;elephant&#x27;</span>, <span class="string">&#x27;bear&#x27;</span>, <span class="string">&#x27;zebra&#x27;</span>, <span class="string">&#x27;giraffe&#x27;</span>]) <span class="comment"># 添加一个命令行参数--cats，用于指定需要处理的类别，默认值为一系列动物的名称</span></span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cuda&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">bool</span>, default=<span class="literal">False</span>)</span><br><span class="line">    args = parser.parse_args() <span class="comment"># 解析命令行参数，并将结果保存在args中</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># trained_net = torch.load(args.model) # 加载模型</span></span><br><span class="line">    trained_net = torch.load(args.model, map_location = <span class="string">&#x27;cpu&#x27;</span>) <span class="comment"># 加载模型</span></span><br><span class="line"></span><br><span class="line">    model = FastRCNN(num_classes=args.num_classes) <span class="comment"># 创建一个FastRCNN模型实例，类别数量为args.num_classes</span></span><br><span class="line">    model.load_state_dict(trained_net) <span class="comment"># 将加载的模型的状态字典加载到FastRCNN模型实例中</span></span><br><span class="line">    <span class="keyword">if</span> args.cuda: <span class="comment"># 如果args.cuda为True，则将模型移动到GPU上</span></span><br><span class="line">        model.cuda()</span><br><span class="line"></span><br><span class="line">    img = skimage.io.imread(args.jpg_path) <span class="comment"># 读取图像</span></span><br><span class="line">    h = img.shape[<span class="number">0</span>] <span class="comment"># 获取图像的高度</span></span><br><span class="line">    w = img.shape[<span class="number">1</span>] <span class="comment"># 获取图像的宽度</span></span><br><span class="line">    _, ss_regions = selective_search(</span><br><span class="line">        img, args.scale, args.sigma, args.min_size) <span class="comment"># 对图像进行选择性搜索，获取候选区域</span></span><br><span class="line">    rois = []</span><br><span class="line">    <span class="keyword">for</span> region <span class="keyword">in</span> ss_regions: <span class="comment"># 遍历每个候选区域</span></span><br><span class="line">        rect = <span class="built_in">list</span>(region[<span class="string">&#x27;rect&#x27;</span>]) <span class="comment"># 获取候选区域的矩形框</span></span><br><span class="line">        rect[<span class="number">0</span>] = rect[<span class="number">0</span>] / w <span class="comment"># 将矩形框的x坐标转换为相对于图像宽度的比例</span></span><br><span class="line">        rect[<span class="number">1</span>] = rect[<span class="number">1</span>] / h <span class="comment"># 将矩形框的y坐标转换为相对于图像高度的比例</span></span><br><span class="line">        rect[<span class="number">2</span>] = rect[<span class="number">0</span>] + rect[<span class="number">2</span>] / w <span class="comment"># 将矩形框的宽度转换为相对于图像宽度的比例</span></span><br><span class="line">        rect[<span class="number">3</span>] = rect[<span class="number">1</span>] + rect[<span class="number">3</span>] / h <span class="comment"># 将矩形框的高度转换为相对于图像高度的比例</span></span><br><span class="line">        rois.append(rect) <span class="comment"># 将处理后的矩形框添加到列表中</span></span><br><span class="line">    img = Image.fromarray(img) <span class="comment"># 将图像数组转换为PIL图像</span></span><br><span class="line">    img_tensor = img.resize([<span class="number">224</span>, <span class="number">224</span>]) <span class="comment"># 将图像大小调整为224x224</span></span><br><span class="line">    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([</span><br><span class="line">                                   <span class="number">0.485</span>, <span class="number">0.456</span>, -<span class="number">.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])]) <span class="comment"># 创建一个图像预处理管道，包括将PIL图像转换为张量和标准化</span></span><br><span class="line">    img_tensor = transform(img_tensor).unsqueeze(<span class="number">0</span>) <span class="comment"># 对图像进行预处理，并添加一个新的维度</span></span><br><span class="line">    <span class="keyword">if</span> args.cuda: <span class="comment"># 如果args.cuda为True，则将图像张量移动到GPU</span></span><br><span class="line">        img_tensor = img_tensor.cuda()</span><br><span class="line">    rois = np.array(rois) <span class="comment"># 将候选区域的列表转换为数组</span></span><br><span class="line">    roi_idx = [<span class="number">0</span>] * rois.shape[<span class="number">0</span>] <span class="comment"># 创建一个列表，长度为候选区域的数量，所有元素都为0</span></span><br><span class="line"></span><br><span class="line">    prob, rela_loc = model.forward(img_tensor, rois, roi_idx) <span class="comment"># 前向传播，计算预测的概率和边界框</span></span><br><span class="line">    prob = torch.nn.Softmax(dim=-<span class="number">1</span>)(prob).cpu().detach().numpy() <span class="comment"># 对预测的概率进行softmax操作，并将结果转换为numpy数组</span></span><br><span class="line">    <span class="comment"># rela_loc = rela_loc.cpu().detach().numpy()[:, 1:, :].mean(axis=1)</span></span><br><span class="line">    labels = []</span><br><span class="line">    max_probs = []</span><br><span class="line">    bboxs = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(prob)): <span class="comment"># 遍历每个预测的概率</span></span><br><span class="line">        <span class="keyword">if</span> prob[i].<span class="built_in">max</span>() &gt; <span class="number">0.8</span> <span class="keyword">and</span> np.argmax(prob[i], axis=<span class="number">0</span>) != <span class="number">0</span>: <span class="comment"># 如果最大概率大于0.8且对应的类别不是背景，则认为候选区域是有效的</span></span><br><span class="line">            <span class="comment"># proposal regions is directly used because of limited training epochs, bboxs predicted are not precise</span></span><br><span class="line">            <span class="comment"># bbox = [(rois[i][2] - rois[i][0]) * rela_loc[i][0] + 0.5 * (rois[i][2] + rois[i][0]),</span></span><br><span class="line">            <span class="comment">#         (rois[i][3] - rois[i][1]) * rela_loc[i][1] + 0.5 * (rois[i][3] + rois[i][1]),</span></span><br><span class="line">            <span class="comment">#         np.exp(rela_loc[i][2]) * rois[i][2],</span></span><br><span class="line">            <span class="comment">#         np.exp(rela_loc[i][3]) * rois[i][3]]</span></span><br><span class="line">            <span class="comment"># bbox = [bbox[0] - 0.5 * bbox[2],</span></span><br><span class="line">            <span class="comment">#         bbox[1] - 0.5 * bbox[3],</span></span><br><span class="line">            <span class="comment">#         bbox[0] + 0.5 * bbox[2],</span></span><br><span class="line">            <span class="comment">#         bbox[1] + 0.5 * bbox[3]]</span></span><br><span class="line">            labels.append(np.argmax(prob[i], axis=<span class="number">0</span>))  <span class="comment"># 将有效候选区域的类别添加到列表中</span></span><br><span class="line">            max_probs.append(prob[i].<span class="built_in">max</span>()) <span class="comment"># 将有效候选区域的最大概率添加到列表中</span></span><br><span class="line">            rois[i] = [<span class="built_in">int</span>(w * rois[i][<span class="number">0</span>]), <span class="built_in">int</span>(h * rois[i][<span class="number">1</span>]),</span><br><span class="line">                       <span class="built_in">int</span>(w * rois[i][<span class="number">2</span>]), <span class="built_in">int</span>(w * rois[i][<span class="number">3</span>])] <span class="comment"># 将候选区域的矩形框的坐标和大小转换为相对于原图的像素值</span></span><br><span class="line">            bboxs.append(rois[i]) <span class="comment"># 将处理后的矩形框添加到列表中</span></span><br><span class="line">    labels = np.array(labels) <span class="comment"># 将类别的列表转换为数组</span></span><br><span class="line">    max_probs = np.array(max_probs) <span class="comment"># 将最大概率的列表转换为数组</span></span><br><span class="line">    bboxs = np.array(bboxs) <span class="comment"># 将矩形框的列表转换为数组</span></span><br><span class="line">    order = np.argsort(-max_probs) <span class="comment"># 对最大概率进行降序排序，获取排序后的索引</span></span><br><span class="line">    labels = labels[order] <span class="comment"># 根据排序的索引重新排序类别</span></span><br><span class="line">    max_probs = max_probs[order]</span><br><span class="line">    bboxs = bboxs[order]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 下面的代码是进行非极大值抑制（NMS），用于去除重叠的候选区域</span></span><br><span class="line">    nms_labels = []</span><br><span class="line">    nms_probs = []</span><br><span class="line">    nms_bboxs = []</span><br><span class="line">    del_indexes = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels)):</span><br><span class="line">        <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> del_indexes:</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(labels)):</span><br><span class="line">                <span class="keyword">if</span> j <span class="keyword">not</span> <span class="keyword">in</span> del_indexes <span class="keyword">and</span> cal_iou(bboxs[i], bboxs[j]) &gt; <span class="number">0.3</span>:</span><br><span class="line">                    del_indexes.append(j)</span><br><span class="line">            nms_labels.append(labels[i])</span><br><span class="line">            nms_probs.append(max_probs[i])</span><br><span class="line">            nms_bboxs.append(bboxs[i])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将预测结果绘制到图像上</span></span><br><span class="line">    cat_dict = &#123;(i + <span class="number">1</span>): args.cats[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(args.cats))&#125;</span><br><span class="line">    cat_dict[<span class="number">0</span>] = <span class="string">&#x27;background&#x27;</span></span><br><span class="line">    font = ImageFont.truetype(<span class="string">&#x27;./fonts/chinese_cht.ttf&#x27;</span>, size=<span class="number">16</span>)</span><br><span class="line">    draw = ImageDraw.Draw(img)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(nms_labels)):</span><br><span class="line">        draw.polygon([(nms_bboxs[i][<span class="number">0</span>], nms_bboxs[i][<span class="number">1</span>]), (nms_bboxs[i][<span class="number">2</span>], nms_bboxs[i][<span class="number">1</span>]),</span><br><span class="line">                      (nms_bboxs[i][<span class="number">2</span>], nms_bboxs[i][<span class="number">3</span>]), (nms_bboxs[i][<span class="number">0</span>], nms_bboxs[i][<span class="number">3</span>])], outline=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line">        draw.text((nms_bboxs[i][<span class="number">0</span>] + <span class="number">5</span>, nms_bboxs[i][<span class="number">1</span>] + <span class="number">5</span>), <span class="string">&#x27;%s %.2f%%&#x27;</span> % (</span><br><span class="line">            cat_dict[nms_labels[i]], <span class="number">100</span> * max_probs[i]), fill=(<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), font=font)</span><br><span class="line">    img.save(args.save_path, args.save_type) <span class="comment"># 将绘制了预测结果的图像保存到指定的路径</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>测试结果如下：<br><img src="https://ooo.0x0.ooo/2023/12/29/OKYvBc.png" alt="OKYvBc.png"></p>
<p>参考资料</p>
<blockquote>
<p>1.博客：<a href="https://blog.csdn.net/guoqingru0311/article/details/129584426">目标检测 pytorch复现Fast_RCNN目标检测项目-CSDN博客</a></p>
<p>2.COCO数据集下载：</p>
<pre><code>训练集：
http://images.cocodataset.org/zips/train2017.zip
验证集：
http://images.cocodataset.org/zips/val2017.zip
训练集和验证集对应的标签：
http://images.cocodataset.org/annotations/annotations_trainval2017.zip
测试集：
http://images.cocodataset.org/zips/test2017.zip
</code></pre>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>Fast RCNN</tag>
        <tag>代码复现</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster RCNN论文理解</title>
    <url>/2023/12/29/Faster-RCNN%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="Faster-RCNN论文理解"><a href="#Faster-RCNN论文理解" class="headerlink" title="Faster RCNN论文理解"></a>Faster RCNN论文理解</h1><p><img src="https://ooo.0x0.ooo/2023/12/29/OKYpMG.png" alt="OKYpMG.png"></p>
<span id="more"></span>

<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>基于候选区域的CNNs(RCNN、SPPnet、FastRCNN…)在目标检测领域取得了很好的效果，尤其是共享卷积特征及大地降低了计算代价，提高了训练和测试的速度。如果忽略产生候选区域(region proposals)的耗时，Fast RCNN输入一张图片和其候选区域后几乎可以实现实时检测。因此，现在检测系统的计算瓶颈主要在于产生候选区域的部分。Selective Search (SS)产生一张图片的2000个候选区域要耗时2s，EdgeBoxes则要耗时0.2s（两种方法都只有CPU实现）——太慢了！因此，本文提出利用deep ConvNet来产生候选区域。</p>
<h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><ol>
<li><strong>用RPN代替selective、EdgeBoxes产生候选区域</strong>：RPN(Region Proposal Networks)，能够同时预测边界框和对象性得分(objectness scores)，并和Fast RCNN目标检测网络共享了卷积特征，实现了网络加速。</li>
<li>提出了一种“轮流”的训练模式来合并RPN和Fast RCNN</li>
</ol>
<h2 id="RPN-Region-Proposal-Networks"><a href="#RPN-Region-Proposal-Networks" class="headerlink" title="RPN(Region Proposal Networks)"></a>RPN(Region Proposal Networks)</h2><h3 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h3><blockquote>
<p>下图展示了RPN的总体结构示意图</p>
</blockquote>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYPHI.png" alt="OKYPHI.png"></p>
<p>共享卷积层(conv layers)本文实验了ZF模型和VGG-16模型</p>
<p>输入：一张任意大小的图片</p>
<p>输出：一系列矩形候选区域及其对应的对象性得分(objectness score——object&#x2F;not-object)</p>
<blockquote>
<p>下图展示了”RPN特有部分”的结构示意图</p>
</blockquote>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYRXD.png" alt="OKYRXD.png"></p>
<h3 id="平移不变的参考框-Translation-Invariant-Anchors"><a href="#平移不变的参考框-Translation-Invariant-Anchors" class="headerlink" title="平移不变的参考框(Translation-Invariant Anchors)"></a>平移不变的参考框(Translation-Invariant Anchors)</h3><p>用三种不同的尺度(scale)和长宽比(aspect ratio)，在每个滑动窗口位置产生9种不同的参考框。</p>
<p>参考框和根据参考框计算候选区域的函数，二者都具有平移不变性</p>
<h3 id="RPN损失函数"><a href="#RPN损失函数" class="headerlink" title="RPN损失函数"></a>RPN损失函数</h3><p><strong>注意！！！这里是RPN的分类和回归网络两个分支的损失函数，不是Fast RCNN的损失函数</strong></p>
<ol>
<li><p>怎么判断预测的参考框是正样本还是负样本？</p>
<ul>
<li>正样本：将参考框和所有的ground-truth计算IoU，与每个ground-truth有着最大IoU的参考框是正样本；将参考框和所有的ground-truth计算IoU，与任意ground-truth的IoU超过0.7的也是正样本</li>
<li>负样本：将参考框和所有的ground-truth计算IoU，与所有的ground-truth的IoU&lt;0.3的是负样本</li>
</ul>
</li>
<li><p>最小化Fast RCNN中的多任务损失函数(multi-task loss)</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYyZr.png" alt="OKYyZr.png"></p>
</li>
<li><p>cls：识别参考框(anchor box)属于object or not-object；reg：将参考框(anchor box)回归到真实标注框(ground-truth box)</p>
</li>
<li><p>回归的实现方式有所改变：</p>
<ul>
<li>RCNN、Fast RCNN：将任意大小的候选区域池化后，执行边界框回归，回归权重被各尺寸的候选区域共享</li>
<li>RPN：只在相同大小的特征图上进行回归，学习到k个不同的边界框回归器，它们之间的权重互不共享</li>
</ul>
</li>
</ol>
<h3 id="训练RPN"><a href="#训练RPN" class="headerlink" title="训练RPN"></a>训练RPN</h3><p>以图片为中心采样(“image centric” sampling strategy)：每个mini-batch来自于一张图片包含的正负样本。</p>
<p>实际做法：在一张图片上随机采样256个参考框，其中正负参考框占比接近1:1，用这些样本作为mini-batch，计算这个mini-batch的损失函数</p>
<h2 id="Faster-RCNN整体训练"><a href="#Faster-RCNN整体训练" class="headerlink" title="Faster RCNN整体训练"></a>Faster RCNN整体训练</h2><p><strong>Faster RCNN &#x3D; RPN + Fast RCNN</strong></p>
<h3 id="如何共享"><a href="#如何共享" class="headerlink" title="如何共享"></a>如何共享</h3><p><strong>如何在RPN和Fast RCNN间共享卷积层？</strong></p>
<h4 id="思路1：轮流训练"><a href="#思路1：轮流训练" class="headerlink" title="思路1：轮流训练"></a>思路1：轮流训练</h4><p>step 1，训练RPN：用ImageNet上的预训练模型初始化RPN，并在端到端的区域建议任务上微调。</p>
<p>step 2，训练Fast RCNN：用step-1训练的RPN产生的候选区域 + ImageNet上的预训练模型从头训练一个Fast RCNN检测模型。到此为止，这两个网络还没有共享卷积层的特征。</p>
<p>step 3，用step-2得到的Fast RCNN检测网络的特征提取部分(Deep ConvNet)初始化RPN的训练，微调RPN特有的的层。此时，两个网络实现了共享卷积层。</p>
<p>step 4，固定共享卷积层，微调Fast RCNN的全连接层（特有的那些层）。到此为止，两个网络就共享了卷积层并形成了一个统一的网络。</p>
<p>下图展示了这一轮流训练过程<br><img src="https://ooo.0x0.ooo/2023/12/29/OKYJ71.png" alt="OKYJ71.png"></p>
<h4 id="思路2：近似联合训练法"><a href="#思路2：近似联合训练法" class="headerlink" title="思路2：近似联合训练法"></a>思路2：近似联合训练法</h4><p>做法：训练初始就将RPN和Fast RCNN合并成一个网络，然后用同时进行反向传播来优化。</p>
<p>问题：无法求解坐标偏导数，因为Fast RCNN的损失函数反向传播也会传导到RPN回归出的坐标部分，但这种方法忽略了这部分</p>
<h4 id="思路3：非近似联合训练法"><a href="#思路3：非近似联合训练法" class="headerlink" title="思路3：非近似联合训练法"></a>思路3：非近似联合训练法</h4><p>利用ROI Warping实现了Fast RCNN尾部网络反向传播到坐标部分的问题</p>
<h3 id="实现细节"><a href="#实现细节" class="headerlink" title="实现细节"></a>实现细节</h3><ol>
<li><p>RPN和Fast RCNN的训练和测试都使用了单尺度图片：缩放图片的短边为600px</p>
</li>
<li><p>参考框选取了3种尺度：128^2，256^2，512^2，3种长宽比：1:1，1:2，2:1&#x3D;&gt;不需要多尺寸特征、多尺寸滑动窗口来预测大区域</p>
</li>
<li><p>处理跨图片边界的参考框：</p>
<ul>
<li>训练时忽略所有跨边界的参考框，因为如果不忽略跨边界的参考框，它们会在损失函数中引入很大很难纠正的错误模式，导致训练很难收敛。</li>
<li>测试时遇到跨图片边界的候选框，会保留其并裁剪其到图片边界</li>
</ul>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKY4zF.png" alt="OKY4zF.png"></p>
</li>
<li><p>基于cls scores针对每一类别的候选区域应用非极大值抑制过滤，以减少冗余。当NMS的IoU的阈值设定为0.7时，每张图片最终会留下大约2k个候选区域，用这2k个候选区域训练Fast RCNN（测试时不一定需要使用2k个，实际使用了300个）</p>
</li>
</ol>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>数据集：PASCAL VOC 2007，5k trainval images，5k test images，超过20个对象类</p>
<p>评估指标：mAP</p>
<h3 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h3><ol>
<li><p>困惑：在RPN和Fast RCNN之间共享卷积特征有什么作用？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验：在4-step的训练步骤的step-2后停下来，用2个分离的网络（RPN和Fast RCNN）完成获取候选区域和实现目标检测</span><br><span class="line"></span><br><span class="line">实验结果：精度会下降</span><br><span class="line"></span><br><span class="line">解释：说明step-2训练好的Fast RCNN网络的特征提取能力能更好地辅助RPN模块产生候选区域，提高了候选区域的质量</span><br></pre></td></tr></table></figure>


</li>
<li><p>困惑：只在测试时使用RPN产生的候选区域，对Fast RCNN检测网络有什么影响?<strong>（注意这里是Fast RCNN，Fast RCNN的训练还是采用selective-search产生的候选区域来实现的，而不是Faster RCNN，即这里RPN和Fast RCNN并没有共享卷积特征）</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验1：</span><br><span class="line"></span><br><span class="line">- 训练时：selective search产生2k个候选区域+ZF；</span><br><span class="line">- 测试时：固定训练产生的检测器，采用RPN产生的候选区域。这时RPN并没有和此时的ZF共享特征。</span><br><span class="line"></span><br><span class="line">实验结果：测试时用300个RPN产生的候选区域来代替selective-search，精度会下降</span><br><span class="line"></span><br><span class="line">解释：精度损失是因为训练和测试时所用的候选区域(proposals)不一致，该结果为后续实验提供baseline</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验2：测试时用RPN产生的前100个候选区域代替前300个</span><br><span class="line"></span><br><span class="line">实验结果：精度下降但下降不多</span><br><span class="line"></span><br><span class="line">解释：说明排名靠前的RPN proposals很准确</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验3：测试时用前6k个RPN proposals(without NMS)产生的候选区域</span><br><span class="line"></span><br><span class="line">实验结果：精度并没有比用300个RPN proposals(with NMS)更好，说明NMS并不损害检测时的mAP，</span><br></pre></td></tr></table></figure>


</li>
<li><p>测试时RPN的分类和回归输出分别有什么作用？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验1：测试时移除RPN的cls layer，然后从没有打分的region proposals随机采样N个proposals进行测试（关闭分类层会导致后续——不会进行NMS，因为NMS是针对每一类(object/not-object)的cls score来进行的，而此时没有分类了）</span><br><span class="line"></span><br><span class="line">实验结果：N=1000时，精度几乎无影响；N=100是，精度大幅下降</span><br><span class="line"></span><br><span class="line">解释：cls scores 考虑到了排名最高的proposals的准确性</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验2：测试时移除RPN的reg layer（移除reg layer的后续影响是——proposals变成了anchor boxes）</span><br><span class="line"></span><br><span class="line">实验结果：精度下降</span><br><span class="line"></span><br><span class="line">解释：高质量的候选区域(proposals)主要是因为位置回归，只有参考框不足以准确定位</span><br></pre></td></tr></table></figure>


</li>
<li><p>更强大的网络(VGG-16)对RPN产生的候选区域质量有什么影响</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">实验：在上述实验（训练：selective-search + ZF，测试：利用ZF训练的RPN产生候选区域），改用VGG-16训练的RPN产生候选区域进行测试（注意这里RPN和目标检测网络都没有共享卷积特征）</span><br><span class="line"></span><br><span class="line">结果：精度提高</span><br><span class="line"></span><br><span class="line">解释：RPN+VGG-16产生的候选区域质量优于RPN+ZF（用ZF训练出来的RPN）</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="Recall-to-IoU"><a href="#Recall-to-IoU" class="headerlink" title="Recall-to-IoU"></a>Recall-to-IoU</h3><p>这个评估指标主要用于诊断（注意是诊断，不是评估）产生候选区域的方法的优劣</p>
<p>下图展示了不同候选区域算法（SS、EB、RPN+ZF、RPN+VGG）在不同IoU时的召回率</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYdLK.png" alt="OKYdLK.png"></p>
<p>解释：</p>
<ol>
<li>当proposals的数量下降的时候，RPN在各个IoU比率下的召回率都只是略微降低</li>
<li>当proposals的数量下降的时候，SS和EB方法在各个IoU比率下的召回率都显著降低</li>
<li>这就解释了为什么RPN只需要300个候选区域就能取得比较好的精度</li>
</ol>
<h3 id="一阶段检测vs两阶段检测"><a href="#一阶段检测vs两阶段检测" class="headerlink" title="一阶段检测vs两阶段检测"></a>一阶段检测vs两阶段检测</h3><p>和OverFeat比较</p>
<p>参考资料：</p>
<blockquote>
<p><a href="https://www.bilibili.com/video/BV1GB4y1r7rM/?spm_id_from=333.880.my_history.page.click&vd_source=66a72b15abe9693bd8b4f738f5a67ee7">https://www.bilibili.com/video/BV1GB4y1r7rM/?spm_id_from=333.880.my_history.page.click&amp;vd_source=66a72b15abe9693bd8b4f738f5a67ee7</a></p>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>论文理解</tag>
        <tag>Faster RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster RCNN代码分析（二）</title>
    <url>/2023/12/29/Faster-RCNN%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90%EF%BC%88%E4%BA%8C%EF%BC%89/</url>
    <content><![CDATA[<h1 id="FasterRCNN代码分析"><a href="#FasterRCNN代码分析" class="headerlink" title="FasterRCNN代码分析"></a>FasterRCNN代码分析</h1><p><strong>项目源码</strong>：<a href="https://github.com/chenyuntc/simple-faster-rcnn-pytorch">https://github.com/chenyuntc/simple-faster-rcnn-pytorch</a></p>
<p><strong>对源码增加注释后的代码（代码2）：</strong></p>
<p><code>simple-faster-rcnn-pytorch-master</code> <a href="https://www.alipan.com/s/faJGPR261aG">https://www.alipan.com/s/faJGPR261aG</a> 提取码: ry92 点击链接保存，或者复制本段内容，打开「阿里云盘」APP ，无需下载极速在线查看，视频原画倍速播放。<br><strong>代码2</strong>只要将VOCdevkit数据集放到dataset目录下即可运行</p>
<p>这个项目是一个基于Faster R-CNN模型的目标检测项目，主要包含以下几个部分：</p>
<span id="more"></span>

<ol>
<li><p><code>utils/config.py</code>：这个文件包含了项目的配置选项，例如数据集路径、学习率、优化器类型、预训练模型的路径等。</p>
</li>
<li><p><code>data/dataset.py</code>：这个文件包含了处理PASCAL VOC数据集的类，例如<code>Dataset</code>、<code>TestDataset</code>。这些类用于加载数据集（这里会调用<code>data/voc_dataset.py</code>中的<code>VOCBboxDataset</code>），对图像和标签进行预处理，并提供了用于训练和测试模型的接口。</p>
</li>
<li><p><code>model/faster_rcnn.py</code>：这个文件包含了Faster R-CNN模型的实现。这个模型由三个主要部分组成：特征提取器、RPN网络和头部网络。特征提取器用于从图像中提取特征，RPN网络用于生成目标的候选区域，头部网络用于在这些候选区域上进行分类和回归。</p>
</li>
<li><p><code>model/faster_rcnn_vgg16.py</code>：这个文件包含了基于VGG-16的Faster R-CNN模型<code>FasterRCNNVGG16</code>（继承了<code>model/faster_rcnn.py</code>中的<code>FasterRCNN</code>）。这个模型由三个主要部分组成：基于VGG-16的特征提取器、RPN网络和<code>VGG16RoIHead</code>头部网络。特征提取器用于从图像中提取特征，RPN网络用于生成目标的候选区域，头部网络用于在这些候选区域上进行分类和回归。</p>
</li>
<li><p><code>model/region_proposal_network.py</code>：这个文件包含了Region Proposal Network（RPN）的实现。RPN是Faster R-CNN模型的一个关键组件，它用于生成目标的候选区域。</p>
</li>
<li><p><code>model/utils/creator_tool.py</code>：这个文件包含了一些用于生成训练Faster R-CNN模型所需的目标的工具类，例如<code>AnchorTargetCreator</code>和<code>ProposalTargetCreator</code>。</p>
</li>
<li><p><code>trainer.py</code>：这个文件包含了一个用于训练Faster R-CNN模型的类<code>FasterRCNNTrainer</code>。这个类提供了一些方法，例如<code>train_step</code>用于执行一步训练，<code>save</code>和<code>load</code>用于保存和加载模型，<code>update_meters</code>和<code>reset_meters</code>用于更新和重置度量等。</p>
</li>
<li><p><code>train.py</code>：这个文件是项目的主程序，它首先加载数据集，然后创建Faster R-CNN模型和训练器，接着进入一个循环，每个循环代表一个训练周期，在每个训练周期中，它会遍历数据集中的所有图像，并使用训练器的<code>train_step</code>方法来更新模型的参数。</p>
</li>
</ol>
<p>这些文件之间的关系主要是通过数据和模型的流动来实现的。首先，<code>train.py</code>会加载<code>dataset.py</code>中的数据集，然后使用<code>model/faster_rcnn.py</code>中的模型对数据进行处理，接着使用<code>trainer.py</code>中的训练器对模型进行训练。在训练过程中，<code>model/utils/creator_tool.py</code>中的工具类会被用来生成训练所需的目标，<code>model/region_proposal_network.py</code>中的RPN会被用来生成目标的候选区域。</p>
<p>1.<code>train.py</code></p>
<p>在<code>main</code>函数中调用<code>train()</code>方法，<code>train()</code>方法的主要步骤为：</p>
<p>（1）加载数据集</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataset = Dataset(opt)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;load data&#x27;</span>)</span><br><span class="line">dataloader = data_.DataLoader(dataset, \</span><br><span class="line">                              batch_size=<span class="number">1</span>, \</span><br><span class="line">                              shuffle=<span class="literal">True</span>, \</span><br><span class="line">                              <span class="comment"># pin_memory=True,</span></span><br><span class="line">                              num_workers=opt.num_workers)</span><br><span class="line">testset = TestDataset(opt)</span><br><span class="line">test_dataloader = data_.DataLoader(testset,</span><br><span class="line">                                   batch_size=<span class="number">1</span>,</span><br><span class="line">                                   num_workers=opt.test_num_workers,</span><br><span class="line">                                   shuffle=<span class="literal">False</span>, \</span><br><span class="line">                                   pin_memory=<span class="literal">True</span></span><br><span class="line">                                  )</span><br></pre></td></tr></table></figure>

<p>（2）创建Faster RCNN模型及其训练器</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">faster_rcnn = FasterRCNNVGG16()<span class="comment"># 创建Faster R-CNN模型对象</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;model construct completed&#x27;</span>)</span><br><span class="line">trainer = FasterRCNNTrainer(faster_rcnn).cuda() <span class="comment"># 创建Faster R-CNN模型的训练器</span></span><br><span class="line"><span class="keyword">if</span> opt.load_path:<span class="comment"># 如果指定了预训练模型的路径</span></span><br><span class="line">   trainer.load(opt.load_path)<span class="comment"># 加载预训练模型</span></span><br><span class="line">   <span class="built_in">print</span>(<span class="string">&#x27;load pretrained model from %s&#x27;</span> % opt.load_path)</span><br></pre></td></tr></table></figure>

<p>（3）开启训练</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">best_map = <span class="number">0</span> <span class="comment"># 初始化最佳mAP为0</span></span><br><span class="line">lr_ = opt.lr <span class="comment"># 获取初始学习率 lr=0.001</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(opt.epoch):</span><br><span class="line">   trainer.reset_meters() <span class="comment"># 重置训练器的度量计数器</span></span><br><span class="line">   <span class="keyword">for</span> ii, (img, bbox_, label_, scale) <span class="keyword">in</span> tqdm(<span class="built_in">enumerate</span>(dataloader)): <span class="comment"># 对数据加载器中的每个batch进行循环 ii为批次索引 img==tensor(1,3,800,600) bbox_==tensor(1,1,4) label_==tensor(1,1) scale==(1,)</span></span><br><span class="line">        scale = at.scalar(scale) <span class="comment"># 获取缩放因子</span></span><br><span class="line">        img, bbox, label = img.cuda().<span class="built_in">float</span>(), bbox_.cuda(), label_.cuda() <span class="comment"># 将图像、边界框（ground_truth）和标签移动到GPU上，并将图像转换为浮点类型</span></span><br><span class="line">        trainer.train_step(img, bbox, label, scale) <span class="comment"># 执行一个训练步骤</span></span><br></pre></td></tr></table></figure>

<p>（4）评估训练结果并在visdom中可视化展示</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">eval_result = <span class="built_in">eval</span>(test_dataloader, faster_rcnn, test_num=opt.test_num)<span class="comment"># 对测试数据集进行评估</span></span><br><span class="line">trainer.vis.plot(<span class="string">&#x27;test_map&#x27;</span>, eval_result[<span class="string">&#x27;map&#x27;</span>])<span class="comment"># 在visdom中绘制mAP</span></span><br><span class="line">lr_ = trainer.faster_rcnn.optimizer.param_groups[<span class="number">0</span>][<span class="string">&#x27;lr&#x27;</span>]<span class="comment"># 获取当前的学习率</span></span><br><span class="line">log_info = <span class="string">&#x27;lr:&#123;&#125;, map:&#123;&#125;,loss:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(<span class="built_in">str</span>(lr_),</span><br><span class="line">                                          <span class="built_in">str</span>(eval_result[<span class="string">&#x27;map&#x27;</span>]),</span><br><span class="line">                                          <span class="built_in">str</span>(trainer.get_meter_data()))<span class="comment"># 生成日志信息</span></span><br><span class="line">trainer.vis.log(log_info)<span class="comment"># 在visdom中显示日志信息</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> eval_result[<span class="string">&#x27;map&#x27;</span>] &gt; best_map:<span class="comment"># 如果当前的mAP大于最佳mAP</span></span><br><span class="line">    best_map = eval_result[<span class="string">&#x27;map&#x27;</span>]<span class="comment"># 更新最佳mAP</span></span><br><span class="line">    best_path = trainer.save(best_map=best_map)<span class="comment"># 保存当前的模型，并获取保存路径</span></span><br><span class="line">    <span class="keyword">if</span> epoch == <span class="number">9</span>:<span class="comment"># 如果当前是第10个训练周期</span></span><br><span class="line">        trainer.load(best_path)<span class="comment"># 加载最佳模型</span></span><br><span class="line">        trainer.faster_rcnn.scale_lr(opt.lr_decay)<span class="comment"># 调整学习率</span></span><br><span class="line">        lr_ = lr_ * opt.lr_decay <span class="comment"># 更新当前的学习率</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> epoch == <span class="number">13</span>: <span class="comment"># 如果当前是第14个训练周期</span></span><br><span class="line">            <span class="keyword">break</span><span class="comment"># 结束训练</span></span><br></pre></td></tr></table></figure>

<p>2.<code>trainer.py</code></p>
<p>在<code>train.py</code>的<code>train()</code>开启训练后，<code>trainer.train_step(img, bbox, label, scale)</code> 会执行一个训练步骤，即进入<code>trainer.py</code>的<code>train_step()</code>方法，进而通过内部的<code>losses = self.forward(imgs, bboxes, labels, scale)</code>进行前向传播，前向传播的主要步骤为：</p>
<p>（1）使用<code>Faster R-CNN</code>的特征提取器提取特征</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">features = self.faster_rcnn.extractor(imgs)  <span class="comment"># 使用Faster R-CNN的特征提取器提取特征</span></span><br></pre></td></tr></table></figure>

<p>（2）使用RPN生成RoIs(初步筛选后得到每张图片约2000个RoI)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># RPN</span></span><br><span class="line"><span class="comment"># rpn_locs代表所有偏移锚框的位置，形状为(1, hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># rpn_scores代表所有偏移锚框的得分下，形状为(1, hh*ww*9, 2)</span></span><br><span class="line"><span class="comment"># rois代表所有的RoIs(感兴趣区域)，形状约为(2000, 4)</span></span><br><span class="line"><span class="comment"># roi_indices代表RoIs对应的图像索引，形状约为(2000, ) 表明rois中的每个RoI都对应于哪张图片（这里batch=1，每次都来自第0张图片）</span></span><br><span class="line">rpn_locs, rpn_scores, rois, roi_indices, anchor = \</span><br><span class="line">	self.faster_rcnn.rpn(features, img_size, scale) <span class="comment"># 使用RPN生成RoIs</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">RegionProposalNetwork</span>(nn.Module):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params"></span></span><br><span class="line"><span class="params">            self, in_channels=<span class="number">512</span>, mid_channels=<span class="number">512</span>, ratios=[<span class="number">0.5</span>, <span class="number">1</span>, <span class="number">2</span>],</span></span><br><span class="line"><span class="params">            anchor_scales=[<span class="number">8</span>, <span class="number">16</span>, <span class="number">32</span>], feat_stride=<span class="number">16</span>,</span></span><br><span class="line"><span class="params">            proposal_creator_params=<span class="built_in">dict</span>(<span class="params"></span>),</span></span><br><span class="line"><span class="params">    </span>):  <span class="comment"># 初始化方法，接受输入通道数、中间通道数、长宽比、锚框尺度、特征步长和proposal创建器参数作为参数</span></span><br><span class="line">        <span class="built_in">super</span>(RegionProposalNetwork, self).__init__()</span><br><span class="line">        self.anchor_base = generate_anchor_base(</span><br><span class="line">            anchor_scales=anchor_scales, ratios=ratios)<span class="comment"># 生成基础参考框anchor_base==&gt;shape(9,4)</span></span><br><span class="line">        self.feat_stride = feat_stride <span class="comment"># 设置特征步长</span></span><br><span class="line">        self.proposal_layer = ProposalCreator(self, **proposal_creator_params)  <span class="comment"># 创建proposal创建器</span></span><br><span class="line">        n_anchor = self.anchor_base.shape[<span class="number">0</span>]  <span class="comment"># 获取锚框数量 n_anchor ==&gt; 9</span></span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels, mid_channels, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>) <span class="comment"># 创建一个卷积层，用于特征提取 ==&gt; shape(512,512,3,1,1) kernel_size=(3,3), stride=(1,1), padding=(1,1)</span></span><br><span class="line">        self.score = nn.Conv2d(mid_channels, n_anchor * <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>) <span class="comment"># 创建一个卷积层，用于计算锚框的得分 ==&gt; shape(512,9*2,1,1,0)</span></span><br><span class="line">        self.loc = nn.Conv2d(mid_channels, n_anchor * <span class="number">4</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>) <span class="comment"># 创建一个卷积层，用于计算锚框的位置 ==&gt; shape(512,9*4,1,1,0)</span></span><br><span class="line">        normal_init(self.conv1, <span class="number">0</span>, <span class="number">0.01</span>) <span class="comment"># 初始化conv1的权重</span></span><br><span class="line">        normal_init(self.score, <span class="number">0</span>, <span class="number">0.01</span>) <span class="comment"># 初始化score的权重</span></span><br><span class="line">        normal_init(self.loc, <span class="number">0</span>, <span class="number">0.01</span>) <span class="comment"># 初始化loc的权重</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, img_size, scale=<span class="number">1.</span></span>):<span class="comment"># 定义前向传播方法，接受FasterRCNN特征提取得到的(也是vgg16的)特征图features、图像尺寸和缩放因子作为参数 img_size==(800,600) scale==1</span></span><br><span class="line">      </span><br><span class="line">        n, _, hh, ww = x.shape <span class="comment"># 获取输入特征图x的形状</span></span><br><span class="line">        anchor = _enumerate_shifted_anchor(</span><br><span class="line">            np.array(self.anchor_base),</span><br><span class="line">            self.feat_stride, hh, ww) <span class="comment"># 枚举所有的偏移锚框，数量为特征图的像素数每个像素的锚框数==&gt;(hh*ww)*9</span></span><br><span class="line"></span><br><span class="line">        n_anchor = anchor.shape[<span class="number">0</span>] // (hh * ww) <span class="comment"># 计算每个像素的锚框数量</span></span><br><span class="line">        h = F.relu(self.conv1(x)) <span class="comment"># 对输入进行卷积操作并通过ReLU激活函数</span></span><br><span class="line"></span><br><span class="line">        rpn_locs = self.loc(h) <span class="comment"># 计算锚框的位置</span></span><br><span class="line">        <span class="comment"># UN<span class="doctag">NOTE:</span> check whether need contiguous</span></span><br><span class="line">        <span class="comment"># A: Yes</span></span><br><span class="line">        rpn_locs = rpn_locs.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).contiguous().view(n, -<span class="number">1</span>, <span class="number">4</span>) <span class="comment"># 调整rpn_locs的形状  rpn_locs代表所有偏移锚框的位置，形状为(1, hh*ww*9, 4)</span></span><br><span class="line">        rpn_scores = self.score(h) <span class="comment"># 计算锚框的得分 rpn_scores代表所有偏移锚框的得分</span></span><br><span class="line">        rpn_scores = rpn_scores.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>).contiguous() <span class="comment"># 调整rpn_scores的形状</span></span><br><span class="line">        rpn_softmax_scores = F.softmax(rpn_scores.view(n, hh, ww, n_anchor, <span class="number">2</span>), dim=<span class="number">4</span>)  <span class="comment"># (1,hh,ww,9,2)# 对得分进行softmax操作，得到每个类别的概率  rpn_softmax_scores代表所有偏移锚框的得分，形状为(1, hh, ww, 9, 2)</span></span><br><span class="line">        rpn_fg_scores = rpn_softmax_scores[:, :, :, :, <span class="number">1</span>].contiguous()  <span class="comment"># 获取前景的得分</span></span><br><span class="line">        rpn_fg_scores = rpn_fg_scores.view(n, -<span class="number">1</span>)  <span class="comment"># 调整rpn_fg_scores的形状 rpn_fg_scores代表所有偏移锚框的前景得分，形状为(1, hh*ww*9)</span></span><br><span class="line">        rpn_scores = rpn_scores.view(n, -<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># 调整rpn_scores的形状 (1, hh*ww*9, 2)</span></span><br><span class="line"></span><br><span class="line">        rois = <span class="built_in">list</span>() <span class="comment"># 创建一个列表，用于存储RoIs</span></span><br><span class="line">        roi_indices = <span class="built_in">list</span>() <span class="comment"># 创建一个列表，用于存储RoIs的索引</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n): <span class="comment"># 对每个图像进行循环</span></span><br><span class="line">            roi = self.proposal_layer(</span><br><span class="line">                rpn_locs[i].cpu().data.numpy(),</span><br><span class="line">                rpn_fg_scores[i].cpu().data.numpy(),</span><br><span class="line">                anchor, img_size,</span><br><span class="line">                scale=scale) <span class="comment"># 使用proposal创建器生成RoIs roi==&gt;(1944,4)</span></span><br><span class="line">            batch_index = i * np.ones((<span class="built_in">len</span>(roi),), dtype=np.int32) <span class="comment"># 创建一个数组，用于存储RoIs的索引</span></span><br><span class="line">            rois.append(roi) <span class="comment"># 将RoIs添加到列表中</span></span><br><span class="line">            roi_indices.append(batch_index) <span class="comment"># 将RoIs的索引添加到列表中</span></span><br><span class="line"></span><br><span class="line">        rois = np.concatenate(rois, axis=<span class="number">0</span>) <span class="comment"># 将所有图像的RoIs合并</span></span><br><span class="line">        roi_indices = np.concatenate(roi_indices, axis=<span class="number">0</span>) <span class="comment"># 将所有图像的RoIs的索引合并</span></span><br><span class="line">        <span class="keyword">return</span> rpn_locs, rpn_scores, rois, roi_indices, anchor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用处：获取偏移后的锚框</span></span><br><span class="line"><span class="comment"># 在Faster R-CNN中，我们首先在图像中生成一系列的锚点（也称为锚框或参考框）</span></span><br><span class="line"><span class="comment"># 这些锚点通常是在不同的位置、尺度和长宽比下生成的（称为基础锚点：3*3=9——特征图的每个像素处都会有9个锚点——即下文代码中的A=9）</span></span><br><span class="line"><span class="comment"># 然后，我们会预测每个锚点需要偏移多少，才能更好地匹配到真实的目标边界框，这个偏移的过程就是所谓的偏移锚点</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 为什么需要偏移?</span></span><br><span class="line"><span class="comment"># 因为我们希望在特征图的每个位置都有一组锚点，这样可以更全面地覆盖到图像中的所有可能的目标。</span></span><br><span class="line"><span class="comment"># 如果只使用基础锚点，那么锚点的位置就只能在参考窗口的位置，这样可能会漏掉一些位于其他位置的目标。</span></span><br><span class="line"><span class="comment"># 通过偏移，我们可以让锚点覆盖到特征图的每个位置，从而更好地检测到所有的目标。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_enumerate_shifted_anchor</span>(<span class="params">anchor_base, feat_stride, height, width</span>):</span><br><span class="line">    <span class="keyword">import</span> numpy <span class="keyword">as</span> xp</span><br><span class="line">    shift_y = xp.arange(<span class="number">0</span>, height * feat_stride, feat_stride) <span class="comment"># 计算y方向上的所有偏移</span></span><br><span class="line">    shift_x = xp.arange(<span class="number">0</span>, width * feat_stride, feat_stride) <span class="comment"># 计算x方向上的所有偏移</span></span><br><span class="line">    shift_x, shift_y = xp.meshgrid(shift_x, shift_y)  <span class="comment"># 生成网格坐标</span></span><br><span class="line">    shift = xp.stack((shift_y.ravel(), shift_x.ravel(),</span><br><span class="line">                      shift_y.ravel(), shift_x.ravel()), axis=<span class="number">1</span>) <span class="comment"># 将偏移堆叠成一个数组</span></span><br><span class="line"></span><br><span class="line">    A = anchor_base.shape[<span class="number">0</span>] <span class="comment"># 每个像素处会有A个锚点（A=9）</span></span><br><span class="line">    K = shift.shape[<span class="number">0</span>] <span class="comment"># 特征图的像素数量（K=hh*ww）==&gt; 整张特征图总的偏移量的数量=K*A</span></span><br><span class="line">    anchor = anchor_base.reshape((<span class="number">1</span>, A, <span class="number">4</span>)) + \</span><br><span class="line">             shift.reshape((<span class="number">1</span>, K, <span class="number">4</span>)).transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>)) <span class="comment"># 将基础锚点和偏移相加，得到所有的偏移后的锚点</span></span><br><span class="line">    anchor = anchor.reshape((K * A, <span class="number">4</span>)).astype(np.float32) <span class="comment"># 调整偏移锚点的形状，并转换为浮点类型</span></span><br><span class="line">    <span class="keyword">return</span> anchor</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（3）生成用于训练<code>Faster R-CNN</code>的head网络（即RoI网络）所需的目标：经IoU阈值筛选后得到128个ROIs(<code>sample_roi</code>)，使用<code>ProposalTargetCreator</code>为<code>sample_roi</code>分配真实边界框<code>gt_roi_loc</code>和真实标签<code>gt_roi_label</code>，此时就生成了用于训练<code>Faster R-CNN</code>的head网络（即RoI网络）所需的目标。这些目标包括每个RoI对应的ground truth边界框的偏移和比例（用于边界框回归任务），以及每个RoI对应的ground truth边界框的类别标签（用于分类任务）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sample_roi代表经过IoU阈值筛选后的RoIs，由前景roi和背景roi组成，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># gt_roi_loc代表sample_roi与其对应的真实边界框（其实是与它IoU最大的真实边界框）之间的偏移和比例，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># gt_roi_label代表sample_roi对应的真实标签（其实是与它IoU最大的真实边界框的标签），形状为(128,)</span></span><br><span class="line">sample_roi, gt_roi_loc, gt_roi_label = self.proposal_target_creator(</span><br><span class="line">            roi,</span><br><span class="line">            at.tonumpy(bbox),</span><br><span class="line">            at.tonumpy(label),</span><br><span class="line">            self.loc_normalize_mean,</span><br><span class="line">            self.loc_normalize_std)<span class="comment"># 使用ProposalTargetCreator生成训练目标</span></span><br></pre></td></tr></table></figure>

<p><code>utils/creator_tool.py</code>中的类<code>ProposalTargetCreator</code>的代码如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 用处：为给定的RoIs分配ground truth边界框</span></span><br><span class="line"><span class="comment"># 1.计算RoIs和边界框的IoU</span></span><br><span class="line"><span class="comment"># 2.找出每个RoI与哪个边界框的IoU最大</span></span><br><span class="line"><span class="comment"># 3.将每个RoI分配给与其IoU最大的边界框</span></span><br><span class="line"><span class="comment"># 4.计算这些RoI与其对应的边界框的偏移和比例</span></span><br><span class="line"><span class="comment"># 5.对偏移和比例进行归一化</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ProposalTargetCreator</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 n_sample=<span class="number">128</span>,</span></span><br><span class="line"><span class="params">                 pos_ratio=<span class="number">0.25</span>, pos_iou_thresh=<span class="number">0.5</span>,</span></span><br><span class="line"><span class="params">                 neg_iou_thresh_hi=<span class="number">0.5</span>, neg_iou_thresh_lo=<span class="number">0.0</span></span></span><br><span class="line"><span class="params">                 </span>):<span class="comment"># 初始化方法，接受一系列参数，包括采样区域的数量、前景的比例、前景的IoU阈值、背景的IoU阈值等</span></span><br><span class="line">        self.n_sample = n_sample  <span class="comment"># 采样区域的数量</span></span><br><span class="line">        self.pos_ratio = pos_ratio  <span class="comment"># 前景的比例</span></span><br><span class="line">        self.pos_iou_thresh = pos_iou_thresh  <span class="comment"># 前景的IoU阈值</span></span><br><span class="line">        self.neg_iou_thresh_hi = neg_iou_thresh_hi  <span class="comment"># 背景的IoU阈值上限</span></span><br><span class="line">        self.neg_iou_thresh_lo = neg_iou_thresh_lo  <span class="comment"># 背景的IoU阈值下限 <span class="doctag">NOTE:</span>default 0.1 in py-faster-rcnn</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, roi, bbox, label,</span></span><br><span class="line"><span class="params">        loc_normalize_mean=(<span class="params"><span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span></span>),</span></span><br><span class="line"><span class="params">        loc_normalize_std=(<span class="params"><span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.2</span></span>)</span>):<span class="comment"># 定义__call__方法，接受RoIs、边界框、标签、位置归一化的均值和标准差作为参数</span></span><br><span class="line">        n_bbox, _ = bbox.shape <span class="comment"># 获取边界框的数量</span></span><br><span class="line"></span><br><span class="line">        roi = np.concatenate((roi, bbox), axis=<span class="number">0</span>)  <span class="comment"># 将RoIs和边界框合并</span></span><br><span class="line"></span><br><span class="line">        pos_roi_per_image = np.<span class="built_in">round</span>(self.n_sample * self.pos_ratio)  <span class="comment"># 计算每个图像的前景RoI数量</span></span><br><span class="line">        iou = bbox_iou(roi, bbox)  <span class="comment"># 计算RoIs和边界框的IoU</span></span><br><span class="line">        gt_assignment = iou.argmax(axis=<span class="number">1</span>)  <span class="comment"># 找出每个RoI与哪个边界框的IoU最大</span></span><br><span class="line">        max_iou = iou.<span class="built_in">max</span>(axis=<span class="number">1</span>)  <span class="comment"># 找出每个RoI的最大IoU</span></span><br><span class="line">        <span class="comment"># Offset range of classes from [0, n_fg_class - 1] to [1, n_fg_class].</span></span><br><span class="line">        <span class="comment"># The label with value 0 is the background.</span></span><br><span class="line">        gt_roi_label = label[gt_assignment] + <span class="number">1</span> <span class="comment"># 将每个RoI分配给与其IoU最大的边界框的标签</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Select foreground RoIs as those with &gt;= pos_iou_thresh IoU.</span></span><br><span class="line">        pos_index = np.where(max_iou &gt;= self.pos_iou_thresh)[<span class="number">0</span>]  <span class="comment"># 找出IoU大于等于前景阈值的RoIs</span></span><br><span class="line">        pos_roi_per_this_image = <span class="built_in">int</span>(<span class="built_in">min</span>(pos_roi_per_image, pos_index.size)) <span class="comment"># 计算这个图像的前景RoI数量</span></span><br><span class="line">        <span class="keyword">if</span> pos_index.size &gt; <span class="number">0</span>:  <span class="comment"># 如果存在前景RoI</span></span><br><span class="line">            pos_index = np.random.choice(</span><br><span class="line">                pos_index, size=pos_roi_per_this_image, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Select background RoIs as those within</span></span><br><span class="line">        <span class="comment"># [neg_iou_thresh_lo, neg_iou_thresh_hi).</span></span><br><span class="line">        neg_index = np.where((max_iou &lt; self.neg_iou_thresh_hi) &amp;</span><br><span class="line">                             (max_iou &gt;= self.neg_iou_thresh_lo))[<span class="number">0</span>]  <span class="comment"># 找出IoU在背景阈值范围内的RoIs</span></span><br><span class="line">        neg_roi_per_this_image = self.n_sample - pos_roi_per_this_image  <span class="comment"># 计算这个图像的背景RoI数量</span></span><br><span class="line">        neg_roi_per_this_image = <span class="built_in">int</span>(<span class="built_in">min</span>(neg_roi_per_this_image,</span><br><span class="line">                                         neg_index.size)) <span class="comment"># 计算这个图像的背景RoI数量</span></span><br><span class="line">        <span class="keyword">if</span> neg_index.size &gt; <span class="number">0</span>:  <span class="comment"># 如果存在背景RoI</span></span><br><span class="line">            neg_index = np.random.choice(</span><br><span class="line">                neg_index, size=neg_roi_per_this_image, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># The indices that we&#x27;re selecting (both positive and negative).</span></span><br><span class="line">        keep_index = np.append(pos_index, neg_index)  <span class="comment"># 将前景和背景的索引合并</span></span><br><span class="line">        gt_roi_label = gt_roi_label[keep_index]  <span class="comment"># 保留这些RoI的标签</span></span><br><span class="line">        gt_roi_label[pos_roi_per_this_image:] = <span class="number">0</span>  <span class="comment"># negative labels --&gt; 0  # 将背景RoI的标签设置为0</span></span><br><span class="line">        sample_roi = roi[keep_index] <span class="comment"># 保留这些RoI</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute offsets and scales to match sampled RoIs to the GTs.</span></span><br><span class="line">        gt_roi_loc = bbox2loc(sample_roi, bbox[gt_assignment[keep_index]]) <span class="comment"># 计算这些RoI与其对应的边界框的偏移和比例</span></span><br><span class="line">        gt_roi_loc = ((gt_roi_loc - np.array(loc_normalize_mean, np.float32)</span><br><span class="line">                       ) / np.array(loc_normalize_std, np.float32))<span class="comment"># 对偏移和比例进行归一化</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> sample_roi, gt_roi_loc, gt_roi_label</span><br><span class="line">    <span class="comment">#sample_roi代表经过IoU阈值筛选后的RoIs，由前景roi和背景roi组成，形状为(128, 4)</span></span><br><span class="line">    <span class="comment">#gt_roi_loc代表sample_roi与其对应的真实边界框（其实是与它IoU最大的真实边界框）之间的偏移和比例，形状为(128, 4)</span></span><br><span class="line">    <span class="comment">#gt_roi_label代表sample_roi对应的真实标签（其实是与它IoU最大的真实边界框的标签），形状为(128,)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（4）生成用于训练<code>Faster R-CNN</code>的RPN网络所需的目标：这些目标包括每个锚点对应的ground truth边界框的偏移和比例（用于边界框回归任务），以及每个锚点是否包含物体的标签（用于前景&#x2F;背景分类任务）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># rpn_loc代表偏移后的锚框的位置</span></span><br><span class="line"><span class="comment"># gt_rpn_loc代表每个anchor与其对应的真实边界框之间的偏移和比例 (hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># gt_rpn_label代表每个anchor对应的真实边界框的标签 (hh*ww*9,)</span></span><br><span class="line">gt_rpn_loc, gt_rpn_label = self.anchor_target_creator(</span><br><span class="line">            at.tonumpy(bbox),</span><br><span class="line">            anchor,</span><br><span class="line">            img_size)  <span class="comment"># 使用AnchorTargetCreator生成训练目标</span></span><br></pre></td></tr></table></figure>

<p><code>utils/creator_tool.py</code>中的类<code>AnchorTargetCreator</code>的代码如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AnchorTargetCreator</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 n_sample=<span class="number">256</span>,</span></span><br><span class="line"><span class="params">                 pos_iou_thresh=<span class="number">0.7</span>, neg_iou_thresh=<span class="number">0.3</span>,</span></span><br><span class="line"><span class="params">                 pos_ratio=<span class="number">0.5</span></span>):  <span class="comment"># 初始化方法，接受一系列参数，包括采样区域的数量、前景的IoU阈值、背景的IoU阈值、前景的比例等</span></span><br><span class="line">        self.n_sample = n_sample <span class="comment"># 采样区域的数量</span></span><br><span class="line">        self.pos_iou_thresh = pos_iou_thresh  <span class="comment"># 前景的IoU阈值</span></span><br><span class="line">        self.neg_iou_thresh = neg_iou_thresh  <span class="comment"># 背景的IoU阈值</span></span><br><span class="line">        self.pos_ratio = pos_ratio   <span class="comment"># 前景的比例</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__call__</span>(<span class="params">self, bbox, anchor, img_size</span>):   <span class="comment"># 定义__call__方法，接受边界框、锚点和图像尺寸作为参数</span></span><br><span class="line"></span><br><span class="line">        img_H, img_W = img_size  <span class="comment"># 获取图像的尺寸</span></span><br><span class="line"></span><br><span class="line">        n_anchor = <span class="built_in">len</span>(anchor)  <span class="comment"># 获取锚点的数量</span></span><br><span class="line">        inside_index = _get_inside_index(anchor, img_H, img_W) <span class="comment"># 获取在图像内部的锚点的索引</span></span><br><span class="line">        anchor = anchor[inside_index]   <span class="comment"># 获取在图像内部的锚点</span></span><br><span class="line">        argmax_ious, label = self._create_label(</span><br><span class="line">            inside_index, anchor, bbox)  <span class="comment"># 创建标签</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute bounding box regression targets</span></span><br><span class="line">        loc = bbox2loc(anchor, bbox[argmax_ious])  <span class="comment"># 计算anchor和ground truth边界框之间的偏移和缩放</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># map up to original set of anchors</span></span><br><span class="line">        label = _unmap(label, n_anchor, inside_index, fill=-<span class="number">1</span>)  <span class="comment"># 将标签映射回原始的锚点集</span></span><br><span class="line">        loc = _unmap(loc, n_anchor, inside_index, fill=<span class="number">0</span>)  <span class="comment"># 将位置映射回原始的锚点集</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loc, label  <span class="comment"># 返回位置和标签</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_create_label</span>(<span class="params">self, inside_index, anchor, bbox</span>):</span><br><span class="line">        <span class="comment"># label: 1 is positive, 0 is negative, -1 is dont care</span></span><br><span class="line">        label = np.empty((<span class="built_in">len</span>(inside_index),), dtype=np.int32)  <span class="comment"># 创建一个空的标签数组</span></span><br><span class="line">        label.fill(-<span class="number">1</span>)  <span class="comment"># 将标签数组填充为-1</span></span><br><span class="line"></span><br><span class="line">        argmax_ious, max_ious, gt_argmax_ious = \</span><br><span class="line">            self._calc_ious(anchor, bbox, inside_index)  <span class="comment"># 计算IoU</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># assign negative labels first so that positive labels can clobber them</span></span><br><span class="line">        label[max_ious &lt; self.neg_iou_thresh] = <span class="number">0</span>  <span class="comment"># 将IoU小于背景阈值的锚点标记为背景</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># positive label: for each gt, anchor with highest iou</span></span><br><span class="line">        label[gt_argmax_ious] = <span class="number">1</span>  <span class="comment"># 将每个ground truth对应的IoU最大的锚点标记为前景</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># positive label: above threshold IOU</span></span><br><span class="line">        label[max_ious &gt;= self.pos_iou_thresh] = <span class="number">1</span>  <span class="comment"># 将IoU大于前景阈值的锚点标记为前景</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># subsample positive labels if we have too many</span></span><br><span class="line">        n_pos = <span class="built_in">int</span>(self.pos_ratio * self.n_sample)   <span class="comment"># 计算前景的数量</span></span><br><span class="line">        pos_index = np.where(label == <span class="number">1</span>)[<span class="number">0</span>]   <span class="comment"># 获取前景的索引</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(pos_index) &gt; n_pos:   <span class="comment"># 如果前景的数量过多</span></span><br><span class="line">            disable_index = np.random.choice(</span><br><span class="line">                pos_index, size=(<span class="built_in">len</span>(pos_index) - n_pos), replace=<span class="literal">False</span>)   <span class="comment"># 随机选择一部分前景</span></span><br><span class="line">            label[disable_index] = -<span class="number">1</span>   <span class="comment"># 将这部分前景标记为不关心</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># subsample negative labels if we have too many</span></span><br><span class="line">        n_neg = self.n_sample - np.<span class="built_in">sum</span>(label == <span class="number">1</span>)  <span class="comment"># 计算背景的数量</span></span><br><span class="line">        neg_index = np.where(label == <span class="number">0</span>)[<span class="number">0</span>] <span class="comment"># 获取背景的索引</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(neg_index) &gt; n_neg:  <span class="comment"># 如果背景的数量过多</span></span><br><span class="line">            disable_index = np.random.choice(</span><br><span class="line">                neg_index, size=(<span class="built_in">len</span>(neg_index) - n_neg), replace=<span class="literal">False</span>) <span class="comment"># 随机选择一部分背景</span></span><br><span class="line">            label[disable_index] = -<span class="number">1</span> <span class="comment"># 将这部分背景标记为不关心</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> argmax_ious, label  <span class="comment"># 返回最大IoU的索引和标签</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_calc_ious</span>(<span class="params">self, anchor, bbox, inside_index</span>):</span><br><span class="line">        <span class="comment"># ious between the anchors and the gt boxes</span></span><br><span class="line">        ious = bbox_iou(anchor, bbox) <span class="comment"># 计算锚点和ground truth边界框之间的IoU</span></span><br><span class="line">        argmax_ious = ious.argmax(axis=<span class="number">1</span>)  <span class="comment"># 获取每个锚点对应的最大IoU的索引</span></span><br><span class="line">        max_ious = ious[np.arange(<span class="built_in">len</span>(inside_index)), argmax_ious]  <span class="comment"># 获取每个锚点的最大IoU</span></span><br><span class="line">        gt_argmax_ious = ious.argmax(axis=<span class="number">0</span>) <span class="comment"># 获取每个ground truth边界框对应的最大IoU的索引</span></span><br><span class="line">        gt_max_ious = ious[gt_argmax_ious, np.arange(ious.shape[<span class="number">1</span>])]  <span class="comment"># 获取每个ground truth边界框的最大IoU</span></span><br><span class="line">        gt_argmax_ious = np.where(ious == gt_max_ious)[<span class="number">0</span>] <span class="comment"># 获取最大IoU的索引</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> argmax_ious, max_ious, gt_argmax_ious   <span class="comment"># 返回最大IoU的索引、最大IoU和ground truth边界框的最大IoU的索引</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>（5）使用<code>Faster R-CNN</code>的头部网络（即RoI网络）对<code>sample_roi</code>进行前向传播，返回<code>roi_cls_locs</code>、<code>roi_scores</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sample_roi代表经过IoU阈值筛选后的RoIs，由前景roi和背景roi组成，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># sample_roi_index：一个全零的数组，用于存储RoIs的索引</span></span><br><span class="line"><span class="comment"># roi_cls_locs代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的边界框位置 (128,21*4)，128为RPN得出的sample_roi的数量</span></span><br><span class="line"><span class="comment"># roi_scores代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的得分 (128,21)</span></span><br><span class="line">roi_cls_loc, roi_score = self.faster_rcnn.head(</span><br><span class="line">    features,</span><br><span class="line">    sample_roi,</span><br><span class="line">    sample_roi_index) <span class="comment"># 使用Faster R-CNN的头部网络进行前向传播</span></span><br></pre></td></tr></table></figure>

<p>（6）计算<code>RPN losses</code></p>
<p>RPN的定位损失：偏移后的锚框位置和真实边界框位置之间的平滑L1损失</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ------------------ RPN losses -------------------#</span></span><br><span class="line"><span class="comment"># rpn_loc代表偏移后的锚框的位置 (hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># gt_rpn_loc代表每个anchor与其对应的真实边界框之间的偏移和比例 (hh*ww*9, 4)</span></span><br><span class="line"><span class="comment"># gt_rpn_label代表每个anchor对应的真实边界框的标签 (hh*ww*9,)</span></span><br><span class="line">rpn_loc_loss = _fast_rcnn_loc_loss(</span><br><span class="line">rpn_loc,</span><br><span class="line">gt_rpn_loc,</span><br><span class="line">gt_rpn_label.data,</span><br><span class="line">self.rpn_sigma)  <span class="comment"># 计算RPN的定位损失：偏移后的锚框位置和真实边界框位置之间的平滑L1损失</span></span><br></pre></td></tr></table></figure>

<p>RPN的分类损失</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># rpn_score代表偏移后的锚框的得分 (hh*ww*9, 2)</span></span><br><span class="line">rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_label.cuda(), ignore_index=-<span class="number">1</span>)  <span class="comment"># 计算RPN的分类损失</span></span><br></pre></td></tr></table></figure>

<p>（7）计算<code>ROI losses</code>（fast rcnn loss）</p>
<p>ROI的定位损失</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ------------------ ROI losses (fast rcnn loss) -------------------#</span></span><br><span class="line"><span class="comment"># roi_cls_loc代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的边界框位置 (128,21,4)，128为RPN得出的sample_roi的数量</span></span><br><span class="line"><span class="comment"># roi_score代表每个sample_roi在经过head网络预测之后，预测出来的每个类别（21类）的得分 (128,21)</span></span><br><span class="line"><span class="comment"># gt_roi_loc代表sample_roi与其对应的真实边界框（其实是与它IoU最大的真实边界框）之间的偏移和比例，形状为(128, 4)</span></span><br><span class="line"><span class="comment"># gt_roi_label代表sample_roi对应的真实标签（其实是与它IoU最大的真实边界框的标签），形状为(128,)</span></span><br><span class="line">roi_loc_loss = _fast_rcnn_loc_loss(</span><br><span class="line">roi_loc.contiguous(),</span><br><span class="line">gt_roi_loc,</span><br><span class="line">gt_roi_label.data,</span><br><span class="line">self.roi_sigma)  <span class="comment"># 计算RoI的定位损失</span></span><br></pre></td></tr></table></figure>

<p>ROI的分类损失</p>
<p>（8）计算总损失</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 总损失 = rpn定位损失+rpn分类损失+roi定位损失+roi分类损失</span></span><br><span class="line">losses = [rpn_loc_loss, rpn_cls_loss, roi_loc_loss, roi_cls_loss]  <span class="comment"># 创建一个列表，用于存储所有的损失</span></span><br><span class="line">losses = losses + [<span class="built_in">sum</span>(losses)]  <span class="comment"># 计算总损失</span></span><br></pre></td></tr></table></figure>

<p>（9）前向传播返回总损失后，执行反向传播、参数更新等操作</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">self, imgs, bboxes, labels, scale</span>): <span class="comment"># 定义训练步骤方法，接受图像、边界框、标签和缩放因子作为参数</span></span><br><span class="line">    self.optimizer.zero_grad() <span class="comment"># 清零优化器的梯度缓存</span></span><br><span class="line">    losses = self.forward(imgs, bboxes, labels, scale) <span class="comment"># 调用forward方法，计算损失 imgs==tensor(1,3,800,600) bboxes==tensor(1,1,4) labels==tensor(1,1) scale==(1,)</span></span><br><span class="line">    losses.total_loss.backward()<span class="comment"># 对总损失进行反向传播</span></span><br><span class="line">    self.optimizer.step()  <span class="comment"># 执行一步优化（参数更新）</span></span><br><span class="line">    self.update_meters(losses)  <span class="comment"># 更新度量</span></span><br><span class="line">    <span class="keyword">return</span> losses <span class="comment"># 返回损失</span></span><br></pre></td></tr></table></figure>

<p>（10）一个训练步骤<code>trainer.train_step(img, bbox, label, scale)</code>完成后，评估训练结果并在<code>visdom</code>中可视化展示<br><img src="https://ooo.0x0.ooo/2023/12/29/OKYXOt.png" alt="OKYXOt.png"></p>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>代码复现</tag>
        <tag>Faster RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster RCNN项目部署（一）</title>
    <url>/2023/12/29/Faster-RCNN%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h2 id="Faster-RCNN项目部署"><a href="#Faster-RCNN项目部署" class="headerlink" title="Faster RCNN项目部署"></a>Faster RCNN项目部署</h2><p>simple-faster-rcnn-pytorch-master</p>
<p><strong>项目源码</strong>：<a href="https://github.com/chenyuntc/simple-faster-rcnn-pytorch">https://github.com/chenyuntc/simple-faster-rcnn-pytorch</a></p>
<span id="more"></span>

<p><strong>云服务器环境：</strong></p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYfPN.png" alt="OKYfPN.png"></p>
<h3 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">!pip install scikit-image</span><br><span class="line">!pip install visdom</span><br><span class="line">!pip install torchnet</span><br><span class="line">!pip install opencv-python</span><br><span class="line">!pip install ipdb</span><br><span class="line">!pip install ipython==7.28.0</span><br><span class="line">!pip install fire</span><br></pre></td></tr></table></figure>

<h3 id="运行demo"><a href="#运行demo" class="headerlink" title="运行demo"></a>运行demo</h3><h4 id="下载预训练模型"><a href="#下载预训练模型" class="headerlink" title="下载预训练模型"></a>下载预训练模型</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">百度网盘地址：https://pan.baidu.com/s/1o87RuXW</span><br><span class="line">密码：scxn</span><br></pre></td></tr></table></figure>

<h4 id="运行demo-pipynb"><a href="#运行demo-pipynb" class="headerlink" title="运行demo.pipynb"></a>运行demo.pipynb</h4><blockquote>
<p>问题：在运行<code>img = read_image(&#39;/root/autodl-tmp/FasterRCNN/misc/demo.jpg&#39;)</code>出现错误：<br><code>UnidentifiedImageError：Image.open() cannot identify image file</code></p>
<p>解决：我也不知道咋解决，因为另外测试后发现PIL的Image.open()是可以用的，我重启了几次不知道为什么就能用了</p>
</blockquote>
<h3 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h3><h4 id="准备数据"><a href="#准备数据" class="headerlink" title="准备数据"></a>准备数据</h4><p>参考项目官网的<code>5.1 Prepare data--Pascal VOC2007</code></p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYllC.png" alt="OKYllC.png"></p>
<p>最终得到的数据目录如下</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYjTL.png" alt="OKYjTL.png"></p>
<h4 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h4><ol>
<li>utils&#x2F;config.py：修改VOC数据集的存放位置<code>voc_data_dir = &#39;/root/autodl-tmp/FasterRCNN/dataset/VOCdevkit/VOC2007/&#39;</code></li>
</ol>
<h4 id="开启训练"><a href="#开启训练" class="headerlink" title="开启训练"></a>开启训练</h4><p>如果直接运行代码<code>!python train.py train --env=&#39;fasterrcnn&#39; --plot-every=100</code>，会出现以下问题：</p>
<blockquote>
<p>问题：ERROR:visdom:[WinError 10061] 由于目标计算机积极拒绝，无法连接。</p>
<p>原因：代码中用到了在线可视化工具visdom，但是没有启动</p>
<p>解决：利用Xshell映射云端服务器的visdom，进行训练过程可视。参考博客<a href="https://blog.csdn.net/m0_6551">https://blog.csdn.net/m0_6551</a></p>
</blockquote>
<p>因此，先利用Xshell映射云端服务器的visdom（参见上面的博客），再在jupyter notebook运行以下代码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python train.py train --env=&#x27;fasterrcnn&#x27; --plot-every=100</span><br></pre></td></tr></table></figure>

<p>运行成功结果如下：<br><img src="https://ooo.0x0.ooo/2023/12/29/OKY2vi.png" alt="OKY2vi.png"></p>
<h4 id="利用Pycharm进行调试"><a href="#利用Pycharm进行调试" class="headerlink" title="利用Pycharm进行调试"></a>利用Pycharm进行调试</h4><p>因为在jupyter notebook中开启训练时使用了代码<code>python train.py train --env=&#39;fasterrcnn&#39; --plot-every=100</code>，而在Pycharm中无法输入这样的命令进行debug，因此我对<code>train.py</code>做了以下修改：</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYsua.png" alt="OKYsua.png"></p>
<p>我舍弃了利用fire.Fire()来调用函数train，而是直接在main函数中调用了train()方法，并传递了参数。此时就可以在Pycharm进行debug了。</p>
<blockquote>
<p>另外，Pycharm在调试过程会遇到一个问题，即：debug时Pycharm卡住在connected界面不动</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYYzS.png" alt="OKYYzS.png"></p>
<p>解决：<img src="https://ooo.0x0.ooo/2023/12/29/OKY6cX.png" alt="OKY6cX.png"></p>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>代码复现</tag>
        <tag>Faster RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Pycharm连接云服务器训练</title>
    <url>/2023/12/29/Pycharm%E8%BF%9E%E6%8E%A5%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%AD%E7%BB%83/</url>
    <content><![CDATA[<h4 id="在AutoDL租用实例"><a href="#在AutoDL租用实例" class="headerlink" title="在AutoDL租用实例"></a>在AutoDL租用实例</h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">获得主机名、端口号、用户名和密码</span><br></pre></td></tr></table></figure>

<h4 id="点击-Tools，点击-部署Deployment，点击Configuration"><a href="#点击-Tools，点击-部署Deployment，点击Configuration" class="headerlink" title="点击 Tools，点击 部署Deployment，点击Configuration"></a>点击 <code>Tools</code>，点击 部署<code>Deployment</code>，点击<code>Configuration</code></h4><span id="more"></span>

<p><img src="https://ooo.0x0.ooo/2023/12/29/OKfzRF.png" alt="OKfzRF.png"></p>
<h4 id="配置服务器信息并测试连接"><a href="#配置服务器信息并测试连接" class="headerlink" title="配置服务器信息并测试连接"></a>配置服务器信息并测试连接</h4><p><img src="https://ooo.0x0.ooo/2023/12/29/OKfbuI.png" alt="OKfbuI.png"></p>
<h4 id="设置本地路径和远程路径映射"><a href="#设置本地路径和远程路径映射" class="headerlink" title="设置本地路径和远程路径映射"></a>设置本地路径和远程路径映射</h4><p><img src="https://ooo.0x0.ooo/2023/12/29/OKfoUq.png" alt="OKfoUq.png"></p>
<h4 id="勾选同步代码时自动创建文件夹"><a href="#勾选同步代码时自动创建文件夹" class="headerlink" title="勾选同步代码时自动创建文件夹"></a>勾选同步代码时自动创建文件夹</h4><p><img src="https://ooo.0x0.ooo/2023/12/29/OKfMPY.png" alt="OKfMPY.png"></p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKfWE1.png" alt="OKfWE1.png"></p>
<h4 id="设置远程解释器和同步目录"><a href="#设置远程解释器和同步目录" class="headerlink" title="设置远程解释器和同步目录"></a>设置远程解释器和同步目录</h4><p><img src="https://ooo.0x0.ooo/2023/12/29/OKf5dr.png" alt="OKf5dr.png"></p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKfO9v.png" alt="OKfO9v.png"></p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYILj.png" alt="OKYILj.png"></p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYuNx.png" alt="OKYuNx.png"></p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYwFU.png" alt="OKYwFU.png"></p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKfqvc.png" alt="OKfqvc.png"></p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKY3up.png" alt="OKY3up.png"></p>
<h4 id="连接成功"><a href="#连接成功" class="headerlink" title="连接成功"></a>连接成功</h4><p><img src="https://ooo.0x0.ooo/2023/12/29/OKfxFD.png" alt="OKfxFD.png"></p>
<h4 id="打开远程Terminal"><a href="#打开远程Terminal" class="headerlink" title="打开远程Terminal"></a>打开远程Terminal</h4><p><img src="https://ooo.0x0.ooo/2023/12/29/OKfTaM.png" alt="OKfTaM.png"></p>
<h4 id="同地区可以选择跨实例拷贝数据"><a href="#同地区可以选择跨实例拷贝数据" class="headerlink" title="同地区可以选择跨实例拷贝数据"></a>同地区可以选择跨实例拷贝数据</h4><p><img src="https://ooo.0x0.ooo/2023/12/29/OKfUNG.png" alt="OKfUNG.png"></p>
]]></content>
      <categories>
        <category>经验技巧</category>
      </categories>
      <tags>
        <tag>Pycharm</tag>
        <tag>云服务器</tag>
      </tags>
  </entry>
  <entry>
    <title>RCNN论文理解</title>
    <url>/2023/12/29/RCNN%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="RCNN"><a href="#RCNN" class="headerlink" title="RCNN"></a>RCNN</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>过去主流的目标检测思路：输入一张图片&#x3D;&#x3D;》获取一系列区域&#x3D;&#x3D;》传统的特征提取方法（HOG特征）得到一组特征表示（x1,x2,…xn）&#x3D;&#x3D;》输入预训练好的机器学习算法（SVM、决策树）进行分类</p>
<p>本文创新：用CNN代替传统的特征提取方法来提取图像特征</p>
<span id="more"></span>

<h2 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h2><ol>
<li>用CNN代替传统的特征提取方法来提取图像特征</li>
<li>迁移学习（模型微调）：模型在大的源领域数据集上预训练后，再在特定目标领域的小数据集上微调，能够适应新任务的要求。——解决目标领域数据稀缺问题。</li>
</ol>
<h2 id="面临问题及解决思路"><a href="#面临问题及解决思路" class="headerlink" title="面临问题及解决思路"></a>面临问题及解决思路</h2><h3 id="问题1：如何用CNN来定位目标？"><a href="#问题1：如何用CNN来定位目标？" class="headerlink" title="问题1：如何用CNN来定位目标？"></a>问题1：如何用CNN来定位目标？</h3><h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>分类任务只需要确定类别；检测任务除了需要确定类别，还需要获得对象的检测边界框。CNN过去已经被证明可以用于分类任务，如何利用它来检测边界框呢？</p>
<h4 id="解决思路"><a href="#解决思路" class="headerlink" title="解决思路"></a>解决思路</h4><ol>
<li><p>基于回归的定位策略：直接用CNN来回归边界框<br><img src="https://ooo.0x0.ooo/2023/12/29/OKYa0B.png" alt="OKYa0B.png"></p>
</li>
<li><p>基于滑动窗口检测器的定位策略：在输入图片上用特定大小和比例的滑动窗口进行滑动，对于滑动到的区域用<strong>浅层的CNN</strong>进行检测，适用于人脸、行人这类<strong>特定比例的任务</strong>。（有人试了，效果不好）</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYows.png" alt="OKYows.png"></p>
</li>
<li><p><strong>基于区域的定位策略（本文√）</strong>：输入一张图片，用某种方法产生一定数量的候选区域（Region proposal），然后用一个深层的CNN提取特征，最后输入分类器种进行分类</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKVIk6.png" alt="OKVIk6.png"></p>
</li>
</ol>
<h3 id="问题2：标注数据太少"><a href="#问题2：标注数据太少" class="headerlink" title="问题2：标注数据太少"></a>问题2：标注数据太少</h3><h4 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h4><p>图像分类领域ImageNet数据集，标注数据丰富，而当时目标检测领域只有PASCAL VOC数据集，标注数据很少</p>
<h4 id="解决思路-1"><a href="#解决思路-1" class="headerlink" title="解决思路"></a>解决思路</h4><ol>
<li>传统思路：无监督预训练+有监督微调</li>
<li>本文思路：迁移学习。在ImageNet大数据集上有监督预训练+在PASCAL VOC小数据集上微调</li>
</ol>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p><img src="https://ooo.0x0.ooo/2023/12/29/OKY51K.png" alt="OKY51K.png"></p>
<h3 id="三个模块"><a href="#三个模块" class="headerlink" title="三个模块"></a>三个模块</h3><ol>
<li><p>产生候选区域：selective search</p>
</li>
<li><p>抽取图像特征：  利用deep CNN从每个候选区域(region proposal )抽取出一个固定长度(4096-dim)的特征向量(feature vector)</p>
<ol>
<li><p>5个卷积层 + 2个全连接层前向传播，删除了源网络最后的1000种分类层（AlexNet）</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKVX8F.png" alt="OKVX8F.png"></p>
</li>
<li><p>deep CNN要求输入的图片固定大小，因此需要对不同大小的候选区域进行缩放至(227 x 227 RGB)</p>
<p>缩放方法：</p>
<ol>
<li>tightest square with context：把整张图片的长边缩放到227，短边按照此比例缩放</li>
<li>tightest square without context：只把候选区域的长边缩放到227，短边按照此比例缩放</li>
<li>warp：把候选区域的长短边都直接缩放到227（有形变）（本文√）</li>
</ol>
</li>
</ol>
</li>
<li><p>用特定类的SVM来对候选区域进行分类：多个二分类构成的SVMs</p>
</li>
</ol>
<h3 id="训练思路"><a href="#训练思路" class="headerlink" title="训练思路"></a>训练思路</h3><h4 id="训练特征提取网络"><a href="#训练特征提取网络" class="headerlink" title="训练特征提取网络"></a>训练特征提取网络</h4><ol>
<li>有监督预训练：在ImageNet上预训练</li>
<li>针对特定领域微调（在VOC数据集上微调出21类的分类模型-softmax层实现分类）<ol>
<li>网络结构：把ImageNet上训练的CNN(AlexNet)最后一层的1000种分类改成 (N+1) 类的分类层，N为微调的数据集的对象类别数，+1为背景</li>
<li>构建数据集：候选区域和ground-truth box的iou &gt; 0.5，为正样本；否则为负样本</li>
<li>SGD：<ol>
<li>初始学习率0.001</li>
<li>每个iteration，统一采样32个正样本和96个负样本组成128的mini-batch</li>
</ol>
</li>
</ol>
</li>
</ol>
<p>训练好了分类网络后，就可以在VOC数据集上较好地提取图像特征；在提取特征后，可以训练一个SVM模型，来对候选区域进行分类。</p>
<h4 id="训练SVMs分类器"><a href="#训练SVMs分类器" class="headerlink" title="训练SVMs分类器"></a>训练SVMs分类器</h4><p>SVMs是由N个linear SVM构成的，我们需要为每个对象类优化一个linear SVM分类器</p>
<ol>
<li>构建数据集：只把ground truth box作为每个类的正样本；把和ground-truth box的iou &lt; 0.3的候选区域，作为负样本（因为负样本很多，这里采用难负例挖掘策略（hard negative mining method）来进一步挑选）</li>
<li>训练分类器：为每个类训练一个linear SVM分类器</li>
</ol>
<h3 id="测试思路"><a href="#测试思路" class="headerlink" title="测试思路"></a>测试思路</h3><p> 输入一张图片&#x3D;&#x3D;》运行selective search产生2000个候选区域（Region proposals）&#x3D;&#x3D;》缩放成固定大小的proposal&#x3D;&#x3D;》利用CNN从每个proposal抽取出一个固定长度的feature vector&#x3D;&#x3D;》用针对特定类的linear SVM分类每一个region proposal&#x3D;&#x3D;》对每一个类的proposals进行非极大值抑制</p>
<h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p>如何可视化高层特征？</p>
<p>在第五个卷积层conv5后跟了一个池化层pool5，经过该于池化层后得到6 x 6 x 256的特征图。提取出一个数据集的所有图像对应的所有候选区域在某一通道某一特定位置的数据进行可视化，实验规律如下：</p>
<ol>
<li>对于高层特征来说，每一个不同的通道，学习到一种高层特征</li>
<li>对于同一个通道的不同位置，它表示的特征是相同的，只是边界框的位置有偏移</li>
</ol>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYM5l.png" alt="OKYM5l.png"></p>
<h2 id="消融实验"><a href="#消融实验" class="headerlink" title="消融实验"></a>消融实验</h2><ol>
<li>在训练CNN的时候，我们使用的是fc7的4096维的输出作为图片的特征，那能不能使用fc6的输出，或pool5的输出作为提取到的特征呢？</li>
</ol>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYOKg.png" alt="OKYOKg.png"></p>
<ol start="2">
<li><p>使用微调和不使用微调对最终的精度有没有影响？</p>
<p>在1中选取不同层的输出作为图片的特征的基础上，测试微调后的精度如何改变。实验结果发现：</p>
<p>（1）微调后精度提高，说明微调重要；</p>
<p>（2）在使用全连接层特征、不同层的卷积特征分别进行微调的基础上，发现使用全连接层特征微调后的精度改善更明显，说明微调更多改善的是全连接层的特征提取能力</p>
</li>
<li><p>不同的CNN结构对特征提取效果有什么影响？</p>
<p>对比了AlexNet（本文）、VGG（更复杂）两种CNN结构提取特征的效果，实验结果发现：</p>
<p>VGG更复杂，提取到的特征更好，检测的准确率也更高</p>
</li>
</ol>
<h2 id="边界框回归"><a href="#边界框回归" class="headerlink" title="边界框回归"></a>边界框回归</h2><p>因为我们在进行目标检测，所以不仅要实现分类，还要对目标的边界框进行回归。因此，在提取出CNN特征（这里用的pool5层的特征）后又训练了一个SVM模型，用于回归出目标的边界框，即原始的候选区域到真实框的偏移量。而在实际实验中发现，分类的预测精度较高，但目标的位置预测并不准确。也就是说，我们希望预测框（黄框）尽可能接近真实框（绿框），即损失函数尽可能小</p>
<p>因此要解决的问题变成了：已知一个不准确的位置，要预测出一个准确的位置（从黄框变成绿框）。</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKVCfb.png" alt="OKVCfb.png"></p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKV3pP.png" alt="OKV3pP.png"></p>
<h2 id="错检情况分析"><a href="#错检情况分析" class="headerlink" title="错检情况分析"></a>错检情况分析</h2><p>分析以下四类错误的占比情况</p>
<ol>
<li>类别正确，但位置不准确</li>
<li>类别识别为相似类</li>
<li>类别识别明显错误</li>
<li>目标误识别为类别</li>
</ol>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYBHa.png" alt="OKYBHa.png"></p>
<h2 id="检测不同因素对算法的敏感度影响（看不懂）"><a href="#检测不同因素对算法的敏感度影响（看不懂）" class="headerlink" title="检测不同因素对算法的敏感度影响（看不懂）"></a>检测不同因素对算法的敏感度影响（看不懂）</h2><h2 id="实验设置的一些问题解释"><a href="#实验设置的一些问题解释" class="headerlink" title="实验设置的一些问题解释"></a>实验设置的一些问题解释</h2><ol>
<li>为什么CNN和SVM的正负例定义的方法不同<ol>
<li>实验观察：通过实验先确定了SVM的划分方法，然后才确定了CNN的正负样本的划分方法</li>
<li>理论解释：训练CNN要求的参数很多，需要大量的训练样本。如果也采用训练SVM时采用的正负样本策略，即只把ground truth的标注框作为每个类的正样本，iou &lt; 0.3的候选区域为负样本，这样训练样本就太少了；而采用另外的方法，即iou &gt; 0.5的候选区域为正样本，否则为负样本，能够在标注框附近引入大量的抖动样本，丰富的数据量可以避免CNN过拟合</li>
</ol>
</li>
<li>在微调之后明明已经能够对候选区域进行多分类了，后面训练SVMs的部分能不能去掉？<ol>
<li>实验观察：直接用CNN的softmax层分类会让精度降低</li>
<li>解释：<ol>
<li>CNN在训练时使用的正样本（抖动样本）并不是每个目标的精确位置，可能会导致误差<br>富的数据量可以避免CNN过拟合</li>
</ol>
</li>
</ol>
</li>
<li>在微调之后明明已经能够对候选区域进行多分类了，后面训练SVMs的部分能不能去掉？<ol>
<li>实验观察：直接用CNN的softmax层分类会让精度降低</li>
<li>解释：<ol>
<li>CNN在训练时使用的正样本（抖动样本）并不是每个目标的精确位置，可能会导致误差</li>
<li>在训练CNN时的负样本是被随机挑选的，而我们可以从CNN分类错误的样本中去挑选那些难负样本，让SVM训练，这样也让增加SVMs分类器后的训练效果更好</li>
</ol>
</li>
</ol>
</li>
</ol>
<p><strong>参考资料：</strong><br><a href="https://www.bilibili.com/video/BV1CZ4y1a7NP/?spm_id_from=333.1007.top_right_bar_window_history.content.click&vd_source=66a72b15abe9693bd8b4f738f5a67ee7">https://www.bilibili.com/video/BV1CZ4y1a7NP/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=66a72b15abe9693bd8b4f738f5a67ee7</a></p>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>论文理解</tag>
        <tag>RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>RCNN代码复现</title>
    <url>/2023/12/29/RCNN%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0/</url>
    <content><![CDATA[<p>本代码最初在colab中实现，以下为全部代码及运行输出结果</p>
<h1 id="挂载谷歌云盘，解压数据集"><a href="#挂载谷歌云盘，解压数据集" class="headerlink" title="挂载谷歌云盘，解压数据集"></a>挂载谷歌云盘，解压数据集</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">%pwd</span><br></pre></td></tr></table></figure>




<p>‘&#x2F;content’</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!unzip <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN/Images.zip&#x27;</span> -d <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN&#x27;</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!unzip <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN/Airplanes_Annotations.zip&#x27;</span> -d <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN&#x27;</span></span><br></pre></td></tr></table></figure>

<span id="more"></span>

<h1 id="安装并导入依赖"><a href="#安装并导入依赖" class="headerlink" title="安装并导入依赖"></a>安装并导入依赖</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">!pip install tensorflow==<span class="number">2.8</span><span class="number">.0</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os,cv2,keras</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tf.__version__</span><br></pre></td></tr></table></figure>




<p>‘2.8.0’</p>
<h1 id="更改工作目录"><a href="#更改工作目录" class="headerlink" title="更改工作目录"></a>更改工作目录</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cd /content/drive/MyDrive/AI_content/RCNN</span><br></pre></td></tr></table></figure>

<p>&#x2F;content&#x2F;drive&#x2F;MyDrive&#x2F;AI_content&#x2F;RCNN</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">path = <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN/Images&#x27;</span></span><br><span class="line">annot = <span class="string">&#x27;/content/drive/MyDrive/AI_content/RCNN/Airplanes_Annotations&#x27;</span></span><br></pre></td></tr></table></figure>

<h1 id="查看数据和标签"><a href="#查看数据和标签" class="headerlink" title="查看数据和标签"></a>查看数据和标签</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Index=<span class="number">148</span></span><br><span class="line">filename = <span class="string">&quot;airplane_&quot;</span>+<span class="built_in">str</span>(Index)+<span class="string">&quot;.jpg&quot;</span></span><br><span class="line"><span class="built_in">print</span>(filename)</span><br><span class="line">img = cv2.imread(os.path.join(path,filename))</span><br><span class="line">df = pd.read_csv(os.path.join(annot,filename.replace(<span class="string">&quot;.jpg&quot;</span>,<span class="string">&quot;.csv&quot;</span>)))</span><br><span class="line">plt.imshow(img)</span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">    x1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">0</span>])</span><br><span class="line">    y1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">1</span>])</span><br><span class="line">    x2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">2</span>])</span><br><span class="line">    y2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">3</span>])</span><br><span class="line">    cv2.rectangle(img,(x1,y1),(x2,y2),(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>), <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(img)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>airplane_148.jpg</p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYkfL.png" alt="OKYkfL.png"></p>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYzBi.png" alt="OKYzBi.png"></p>
<h1 id="Selective-search"><a href="#Selective-search" class="headerlink" title="Selective search"></a>Selective search</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.setUseOptimized(<span class="literal">True</span>);</span><br><span class="line">ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">im = cv2.imread(os.path.join(path,<span class="string">&quot;42850.jpg&quot;</span>))</span><br><span class="line">ss.setBaseImage(im)</span><br><span class="line">ss.switchToSelectiveSearchFast()</span><br><span class="line">rects = ss.process()</span><br><span class="line">imOut = im.copy() <span class="comment">#复制原图，在复制后的图片上绘制矩形</span></span><br><span class="line"><span class="keyword">for</span> i, rect <span class="keyword">in</span> (<span class="built_in">enumerate</span>(rects)):</span><br><span class="line">    x, y, w, h = rect</span><br><span class="line">    cv2.rectangle(imOut, (x, y), (x+w, y+h), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>, cv2.LINE_AA) <span class="comment">#在imOut上绘制矩形</span></span><br><span class="line"></span><br><span class="line">plt.imshow(imOut)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示可视化的结果</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYbpC.png" alt="OKYbpC.png"></p>
<h1 id="IOU"><a href="#IOU" class="headerlink" title="IOU"></a>IOU</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_iou</span>(<span class="params">bb1, bb2</span>):</span><br><span class="line">  <span class="comment"># assuring for proper dimension.</span></span><br><span class="line">    <span class="keyword">assert</span> bb1[<span class="string">&#x27;x1&#x27;</span>] &lt; bb1[<span class="string">&#x27;x2&#x27;</span>]</span><br><span class="line">    <span class="keyword">assert</span> bb1[<span class="string">&#x27;y1&#x27;</span>] &lt; bb1[<span class="string">&#x27;y2&#x27;</span>]</span><br><span class="line">    <span class="keyword">assert</span> bb2[<span class="string">&#x27;x1&#x27;</span>] &lt; bb2[<span class="string">&#x27;x2&#x27;</span>]</span><br><span class="line">    <span class="keyword">assert</span> bb2[<span class="string">&#x27;y1&#x27;</span>] &lt; bb2[<span class="string">&#x27;y2&#x27;</span>]</span><br><span class="line">  <span class="comment"># calculating dimension of common area between these two boxes.</span></span><br><span class="line">    x_left = <span class="built_in">max</span>(bb1[<span class="string">&#x27;x1&#x27;</span>], bb2[<span class="string">&#x27;x1&#x27;</span>])</span><br><span class="line">    y_top = <span class="built_in">max</span>(bb1[<span class="string">&#x27;y1&#x27;</span>], bb2[<span class="string">&#x27;y1&#x27;</span>])</span><br><span class="line">    x_right = <span class="built_in">min</span>(bb1[<span class="string">&#x27;x2&#x27;</span>], bb2[<span class="string">&#x27;x2&#x27;</span>])</span><br><span class="line">    y_bottom = <span class="built_in">min</span>(bb1[<span class="string">&#x27;y2&#x27;</span>], bb2[<span class="string">&#x27;y2&#x27;</span>])</span><br><span class="line">  <span class="comment"># if there is no overlap output 0 as intersection area is zero.</span></span><br><span class="line">    <span class="keyword">if</span> x_right &lt; x_left <span class="keyword">or</span> y_bottom &lt; y_top:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span></span><br><span class="line">  <span class="comment"># calculating intersection area.</span></span><br><span class="line">    intersection_area = (x_right - x_left) * (y_bottom - y_top)</span><br><span class="line">  <span class="comment"># individual areas of both these bounding boxes.</span></span><br><span class="line">    bb1_area = (bb1[<span class="string">&#x27;x2&#x27;</span>] - bb1[<span class="string">&#x27;x1&#x27;</span>]) * (bb1[<span class="string">&#x27;y2&#x27;</span>] - bb1[<span class="string">&#x27;y1&#x27;</span>])</span><br><span class="line">    bb2_area = (bb2[<span class="string">&#x27;x2&#x27;</span>] - bb2[<span class="string">&#x27;x1&#x27;</span>]) * (bb2[<span class="string">&#x27;y2&#x27;</span>] - bb2[<span class="string">&#x27;y1&#x27;</span>])</span><br><span class="line">  <span class="comment"># union area = area of bb1_+ area of bb2 - intersection of bb1 and bb2.</span></span><br><span class="line">    iou = intersection_area / <span class="built_in">float</span>(bb1_area + bb2_area - intersection_area)</span><br><span class="line">    <span class="keyword">assert</span> iou &gt;= <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">assert</span> iou &lt;= <span class="number">1.0</span></span><br><span class="line">    <span class="keyword">return</span> iou</span><br></pre></td></tr></table></figure>

<h1 id="准备训练数据"><a href="#准备训练数据" class="headerlink" title="准备训练数据"></a>准备训练数据</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># At the end of below code we will have our train data in these lists</span></span><br><span class="line">train_images=[]</span><br><span class="line">train_labels=[]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> e,i <span class="keyword">in</span> <span class="built_in">enumerate</span>(os.listdir(annot)):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> i.startswith(<span class="string">&quot;airplane&quot;</span>):</span><br><span class="line">            filename = i.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>]+<span class="string">&quot;.jpg&quot;</span></span><br><span class="line">            <span class="built_in">print</span>(e,filename)</span><br><span class="line">            <span class="comment"># 读取图像</span></span><br><span class="line">            image = cv2.imread(os.path.join(path,filename))</span><br><span class="line">            <span class="comment"># 读取标注文件</span></span><br><span class="line">            df = pd.read_csv(os.path.join(annot,i))</span><br><span class="line">            gtvalues=[]</span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">                x1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">0</span>])</span><br><span class="line">                y1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">1</span>])</span><br><span class="line">                x2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">2</span>])</span><br><span class="line">                y2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">3</span>])</span><br><span class="line">                gtvalues.append(&#123;<span class="string">&quot;x1&quot;</span>:x1,<span class="string">&quot;x2&quot;</span>:x2,<span class="string">&quot;y1&quot;</span>:y1,<span class="string">&quot;y2&quot;</span>:y2&#125;)</span><br><span class="line">            <span class="comment"># 设置基础图像</span></span><br><span class="line">            ss.setBaseImage(image)   <span class="comment"># setting given image as base image</span></span><br><span class="line">            ss.switchToSelectiveSearchFast()     <span class="comment"># running selective search on base image</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 运行选择性搜索</span></span><br><span class="line">            ssresults = ss.process()     <span class="comment"># processing to get the outputs</span></span><br><span class="line">            imout = image.copy()</span><br><span class="line">            counter = <span class="number">0</span></span><br><span class="line">            falsecounter = <span class="number">0</span></span><br><span class="line">            flag = <span class="number">0</span></span><br><span class="line">            fflag = <span class="number">0</span></span><br><span class="line">            bflag = <span class="number">0</span></span><br><span class="line">             <span class="comment"># 遍历选择性搜索的结果</span></span><br><span class="line">            <span class="keyword">for</span> e,result <span class="keyword">in</span> <span class="built_in">enumerate</span>(ssresults):</span><br><span class="line">                <span class="keyword">if</span> e &lt; <span class="number">2000</span> <span class="keyword">and</span> flag == <span class="number">0</span>:     <span class="comment"># till 2000 to get top 2000 regions only</span></span><br><span class="line">                    <span class="keyword">for</span> gtval <span class="keyword">in</span> gtvalues:</span><br><span class="line">                        x,y,w,h = result</span><br><span class="line">                        iou = get_iou(gtval,&#123;<span class="string">&quot;x1&quot;</span>:x,<span class="string">&quot;x2&quot;</span>:x+w,<span class="string">&quot;y1&quot;</span>:y,<span class="string">&quot;y2&quot;</span>:y+h&#125;)  <span class="comment"># calculating IoU for each of the proposed regions</span></span><br><span class="line">                        <span class="keyword">if</span> counter &lt; <span class="number">30</span>:       <span class="comment"># getting only 30 psoitive examples</span></span><br><span class="line">                            <span class="keyword">if</span> iou &gt; <span class="number">0.70</span>:     <span class="comment"># IoU of being positive is 0.7</span></span><br><span class="line">                                timage = imout[x:x+w,y:y+h]</span><br><span class="line">                                resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA)</span><br><span class="line">                                train_images.append(resized)</span><br><span class="line">                                train_labels.append(<span class="number">1</span>)</span><br><span class="line">                                counter += <span class="number">1</span></span><br><span class="line">                        <span class="keyword">else</span> :</span><br><span class="line">                            fflag =<span class="number">1</span>              <span class="comment"># to insure we have collected all psotive examples</span></span><br><span class="line">                        <span class="keyword">if</span> falsecounter &lt;<span class="number">30</span>:      <span class="comment"># 30 negatve examples are allowed only</span></span><br><span class="line">                            <span class="keyword">if</span> iou &lt; <span class="number">0.3</span>:         <span class="comment"># IoU of being negative is 0.3</span></span><br><span class="line">                                timage = imout[x:x+w,y:y+h]</span><br><span class="line">                                resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA)</span><br><span class="line">                                train_images.append(resized)</span><br><span class="line">                                train_labels.append(<span class="number">0</span>)</span><br><span class="line">                                falsecounter += <span class="number">1</span></span><br><span class="line">                        <span class="keyword">else</span> :</span><br><span class="line">                            bflag = <span class="number">1</span>             <span class="comment">#to ensure we have collected all negative examples</span></span><br><span class="line">                    <span class="keyword">if</span> fflag == <span class="number">1</span> <span class="keyword">and</span> bflag == <span class="number">1</span>:</span><br><span class="line">                        <span class="built_in">print</span>(<span class="string">&quot;inside&quot;</span>)</span><br><span class="line">                        flag = <span class="number">1</span>        <span class="comment"># to signal the complition of data extaction from a particular image</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;error in &quot;</span>+filename)</span><br><span class="line">        <span class="keyword">continue</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># conversion of train data into arrays for further training</span></span><br><span class="line">X_new = np.array(train_images)</span><br><span class="line">Y_new = np.array(train_labels)</span><br></pre></td></tr></table></figure>






<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为方便下次不用重新处理输入的训练数据，在这里将X_new,Y_new进行保存</span></span><br><span class="line">np.save(<span class="string">&#x27;save_X_new&#x27;</span>,X_new)</span><br><span class="line">np.save(<span class="string">&#x27;save_Y_new&#x27;</span>,Y_new)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 读取保存的数据X_new,Y_new</span></span><br><span class="line">X_new = np.load(<span class="string">&#x27;save_X_new.npy&#x27;</span>)</span><br><span class="line">Y_new = np.load(<span class="string">&#x27;save_Y_new.npy&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 这里因为colab提供的显存不够，只有15g，加载全部数据进去会爆显存，所以只截取一部分样本来进行训练，即X_new_subset 、Y_new_subset </span></span><br><span class="line">total_nums = <span class="built_in">len</span>(Y_new)</span><br><span class="line"><span class="built_in">print</span>(total_nums)</span><br></pre></td></tr></table></figure>

<p>30229</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从训练数据中随机选择 10000 个样本</span></span><br><span class="line">num_samples = <span class="number">5000</span></span><br><span class="line">random_indices = np.random.choice(<span class="built_in">len</span>(X_new), num_samples, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用随机选择的索引来获取样本</span></span><br><span class="line">X_new_subset = X_new[random_indices]</span><br><span class="line">Y_new_subset = Y_new[random_indices]</span><br></pre></td></tr></table></figure>

<h1 id="预训练（使用VGG16模型创建一个迁移学习模型）"><a href="#预训练（使用VGG16模型创建一个迁移学习模型）" class="headerlink" title="预训练（使用VGG16模型创建一个迁移学习模型）"></a>预训练（使用VGG16模型创建一个迁移学习模型）</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> optimizers</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用 VGG16 模型来创建一个迁移学习模型</span></span><br><span class="line">vgg = tf.keras.applications.vgg16.VGG16(include_top=<span class="literal">True</span>, weights=<span class="string">&#x27;imagenet&#x27;</span>, input_tensor=<span class="literal">None</span>, input_shape=<span class="literal">None</span>, pooling=<span class="literal">None</span>, classes=<span class="number">1000</span>)</span><br><span class="line"><span class="comment"># 将 VGG16 模型的大部分层设为不可训练，保留最后两层的可训练性</span></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> vgg.layers[:-<span class="number">2</span>]:</span><br><span class="line">  layer.trainable = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 获取 VGG16 模型中名为 &#x27;fc2&#x27; 的层，并获取该层的输出</span></span><br><span class="line">x = vgg.get_layer(<span class="string">&#x27;fc2&#x27;</span>)</span><br><span class="line">last_output =  x.output</span><br><span class="line"><span class="comment"># 在 VGG16 模型的 &#x27;fc2&#x27; 层之后添加了一个新的全连接层，这个全连接层只有一个单元，使用 sigmoid 激活函数来输出二元分类的概率</span></span><br><span class="line">x = tf.keras.layers.Dense(<span class="number">1</span>,activation = <span class="string">&#x27;sigmoid&#x27;</span>)(last_output)</span><br><span class="line"><span class="comment"># 创建一个新的模型，该模型接受 VGG16 的输入，并输出通过添加新层后的结果</span></span><br><span class="line">model = tf.keras.Model(vgg.<span class="built_in">input</span>,x)</span><br><span class="line"><span class="comment"># 编译模型，使用 Adam 优化器，二元交叉熵作为损失函数进行训练，并监控模型的精度（accuracy）指标</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer = <span class="string">&quot;adam&quot;</span>,</span><br><span class="line">              loss = <span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              metrics = [<span class="string">&#x27;acc&#x27;</span>])</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 保存一下这个模型文件</span></span><br><span class="line">model.save(<span class="string">&#x27;my_model_vgg16.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>&#x2F;usr&#x2F;local&#x2F;lib&#x2F;python3.10&#x2F;dist-packages&#x2F;keras&#x2F;src&#x2F;engine&#x2F;training.py:3103: UserWarning: You are saving your model as an HDF5 file via <code>model.save()</code>. This file format is considered legacy. We recommend using instead the native Keras format, e.g. <code>model.save(&#39;my_model.keras&#39;)</code>.   saving_api.save_model(</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看模型结构并进行训练</span></span><br><span class="line">model.summary()</span><br><span class="line">model.fit(X_new_subset,Y_new_subset,batch_size = <span class="number">32</span>,epochs = <span class="number">3</span>, verbose = <span class="number">1</span>,validation_split=<span class="number">.05</span>,shuffle = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;model&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 224, 224, 3)]     0         
                                                                 
 block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      
                                                                 
 block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     
                                                                 
 block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         
                                                                 
 block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     
                                                                 
 block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    
                                                                 
 block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         
                                                                 
 block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    
                                                                 
 block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    
                                                                 
 block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    
                                                                 
 block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         
                                                                 
 block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   
                                                                 
 block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   
                                                                 
 block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   
                                                                 
 block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         
                                                                 
 block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         
                                                                 
 flatten (Flatten)           (None, 25088)             0         
                                                                 
 fc1 (Dense)                 (None, 4096)              102764544 
                                                                 
 fc2 (Dense)                 (None, 4096)              16781312  
                                                                 
 dense (Dense)               (None, 1)                 4097      
                                                                 
=================================================================
Total params: 134264641 (512.18 MB)
Trainable params: 16785409 (64.03 MB)
Non-trainable params: 117479232 (448.15 MB)
_________________________________________________________________
Epoch 1/3
149/149 [==============================] - 43s 214ms/step - loss: 1.4586 - acc: 0.7680 - val_loss: 0.3230 - val_acc: 0.8880
Epoch 2/3
149/149 [==============================] - 19s 129ms/step - loss: 0.3880 - acc: 0.8215 - val_loss: 0.3339 - val_acc: 0.8560
Epoch 3/3
149/149 [==============================] - 20s 131ms/step - loss: 0.3464 - acc: 0.8495 - val_loss: 0.3104 - val_acc: 0.8760

&lt;keras.src.callbacks.History at 0x7a67e60b2140&gt;
</code></pre>
<h1 id="创建带有SVM的新网络"><a href="#创建带有SVM的新网络" class="headerlink" title="创建带有SVM的新网络"></a>创建带有SVM的新网络</h1><h2 id="创建供SVM使用的数据集"><a href="#创建供SVM使用的数据集" class="headerlink" title="创建供SVM使用的数据集"></a>创建供SVM使用的数据集</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">svm_image = [];</span><br><span class="line">svm_label = [];</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建SVM数据集采用了和训练数据集不同的iou标准</span></span><br><span class="line"><span class="keyword">for</span> e,i <span class="keyword">in</span> <span class="built_in">enumerate</span>(os.listdir(annot)):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">if</span> i.startswith(<span class="string">&quot;airplane&quot;</span>):</span><br><span class="line">            <span class="comment"># 提取图像文件名并读取图像</span></span><br><span class="line">            filename = i.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>]+<span class="string">&quot;.jpg&quot;</span></span><br><span class="line">            <span class="built_in">print</span>(e,filename)</span><br><span class="line">            image = cv2.imread(os.path.join(path,filename))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 读取对应的标注文件</span></span><br><span class="line">            df = pd.read_csv(os.path.join(annot,i))</span><br><span class="line">            gtvalues=[]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 解析标注文件中的目标坐标信息</span></span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">                x1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">0</span>])</span><br><span class="line">                y1 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">1</span>])</span><br><span class="line">                x2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">2</span>])</span><br><span class="line">                y2 = <span class="built_in">int</span>(row[<span class="number">1</span>][<span class="number">0</span>].split(<span class="string">&quot; &quot;</span>)[<span class="number">3</span>])</span><br><span class="line">                gtvalues.append(&#123;<span class="string">&quot;x1&quot;</span>:x1,<span class="string">&quot;x2&quot;</span>:x2,<span class="string">&quot;y1&quot;</span>:y1,<span class="string">&quot;y2&quot;</span>:y2&#125;)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># 从图像中截取目标区域并调整大小，作为正样本(ground_truth对应的图像区域，作为正样本)</span></span><br><span class="line">                timage = image[x1:x2,y1:y2]</span><br><span class="line">                resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA)</span><br><span class="line">                svm_image.append(resized)</span><br><span class="line">                svm_label.append([<span class="number">0</span>,<span class="number">1</span>])<span class="comment"># 正样本标签 [0, 1]</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 执行选择性搜索算法获取区域建议</span></span><br><span class="line">            ss.setBaseImage(image)</span><br><span class="line">            ss.switchToSelectiveSearchFast()</span><br><span class="line">            ssresults = ss.process()</span><br><span class="line">            imout = image.copy()</span><br><span class="line">            counter = <span class="number">0</span></span><br><span class="line">            falsecounter = <span class="number">0</span></span><br><span class="line">            flag = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">             <span class="comment"># 遍历选择性搜索结果以构建负样本</span></span><br><span class="line">            <span class="keyword">for</span> e,result <span class="keyword">in</span> <span class="built_in">enumerate</span>(ssresults):</span><br><span class="line">                <span class="keyword">if</span> e &lt; <span class="number">2000</span> <span class="keyword">and</span> flag == <span class="number">0</span>:</span><br><span class="line">                    <span class="keyword">for</span> gtval <span class="keyword">in</span> gtvalues:</span><br><span class="line">                        x,y,w,h = result</span><br><span class="line">                        iou = get_iou(gtval,&#123;<span class="string">&quot;x1&quot;</span>:x,<span class="string">&quot;x2&quot;</span>:x+w,<span class="string">&quot;y1&quot;</span>:y,<span class="string">&quot;y2&quot;</span>:y+h&#125;)</span><br><span class="line"></span><br><span class="line">                        <span class="comment"># 添加满足条件的负样本</span></span><br><span class="line">                        <span class="keyword">if</span> falsecounter &lt;<span class="number">5</span>:</span><br><span class="line">                            <span class="keyword">if</span> iou &lt; <span class="number">0.3</span>:</span><br><span class="line">                                timage = imout[x:x+w,y:y+h]</span><br><span class="line">                                resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA)</span><br><span class="line">                                svm_image.append(resized)</span><br><span class="line">                                svm_label.append([<span class="number">1</span>,<span class="number">0</span>]) <span class="comment"># 负样本标签 [1, 0]</span></span><br><span class="line">                                falsecounter += <span class="number">1</span></span><br><span class="line">                        <span class="keyword">else</span> :</span><br><span class="line">                            flag = <span class="number">1</span> <span class="comment"># 达到负样本数量上限</span></span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(e)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;error in &quot;</span>+filename)</span><br><span class="line">        <span class="keyword">continue</span></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为防止RAM不够，这里把svm_image、svm_label也只选取一部分</span></span><br><span class="line">X_svm = np.array(svm_image)</span><br><span class="line">Y_svm = np.array(svm_label)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为方便下次不用重新处理输入的训练数据，在这里将X_new,Y_new进行保存</span></span><br><span class="line">np.save(<span class="string">&#x27;save_X_svm&#x27;</span>,X_svm)</span><br><span class="line">np.save(<span class="string">&#x27;save_Y_svm&#x27;</span>,Y_svm)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">total_nums_svm = <span class="built_in">len</span>(Y_svm)</span><br><span class="line"><span class="built_in">print</span>(total_nums_svm)</span><br></pre></td></tr></table></figure>

<p>7750</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">X_svm = np.load(<span class="string">&#x27;save_X_svm.npy&#x27;</span>)</span><br><span class="line">Y_svm = np.load(<span class="string">&#x27;save_Y_svm.npy&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从训练数据中随机选择 2000 个样本</span></span><br><span class="line">num_samples = <span class="number">2000</span></span><br><span class="line">random_indices = np.random.choice(<span class="built_in">len</span>(X_svm), num_samples, replace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用随机选择的索引来获取样本</span></span><br><span class="line">X_svm_subset = X_svm[random_indices]</span><br><span class="line">Y_svm_subset = Y_svm[random_indices]</span><br></pre></td></tr></table></figure>

<h2 id="SVM模型结构"><a href="#SVM模型结构" class="headerlink" title="SVM模型结构"></a>SVM模型结构</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从现有模型中获取 &#x27;fc2&#x27; 层的输出</span></span><br><span class="line">x = model.get_layer(<span class="string">&#x27;fc2&#x27;</span>).output</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加一个具有2个单元的全连接层，没有激活函数</span></span><br><span class="line">Y = tf.keras.layers.Dense(<span class="number">2</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个新的模型，该模型接收现有模型的输入，并输出新添加的全连接层的结果</span></span><br><span class="line">final_model = tf.keras.Model(model.<span class="built_in">input</span>, Y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译新模型</span></span><br><span class="line">final_model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;hinge&#x27;</span>,  <span class="comment"># 使用hinge loss损失函数</span></span><br><span class="line">                    optimizer=<span class="string">&#x27;adam&#x27;</span>,  <span class="comment"># 优化器为 Adam</span></span><br><span class="line">                    metrics=[<span class="string">&#x27;accuracy&#x27;</span>])  <span class="comment"># 监控模型的准确度指标</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出新模型的概要信息</span></span><br><span class="line">final_model.summary()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载预训练模型的权重</span></span><br><span class="line"><span class="comment"># final_model.load_weights(&#x27;my_model_weights.h5&#x27;)</span></span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;model_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 224, 224, 3)]     0         
                                                                 
 block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      
                                                                 
 block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     
                                                                 
 block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         
                                                                 
 block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     
                                                                 
 block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    
                                                                 
 block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         
                                                                 
 block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    
                                                                 
 block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    
                                                                 
 block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    
                                                                 
 block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         
                                                                 
 block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   
                                                                 
 block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   
                                                                 
 block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   
                                                                 
 block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         
                                                                 
 block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   
                                                                 
 block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         
                                                                 
 flatten (Flatten)           (None, 25088)             0         
                                                                 
 fc1 (Dense)                 (None, 4096)              102764544 
                                                                 
 fc2 (Dense)                 (None, 4096)              16781312  
                                                                 
 dense_1 (Dense)             (None, 2)                 8194      
                                                                 
=================================================================
Total params: 134268738 (512.19 MB)
Trainable params: 16789506 (64.05 MB)
Non-trainable params: 117479232 (448.15 MB)
_________________________________________________________________
</code></pre>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用 SVM 数据集对最终模型进行训练，训练过程中的结果将存储在 hist_final 中</span></span><br><span class="line">hist_final = final_model.fit(</span><br><span class="line">    X_svm_subset,  <span class="comment"># SVM 数据集中的图像数据</span></span><br><span class="line">    Y_svm_subset,  <span class="comment"># SVM 数据集中的标签数据</span></span><br><span class="line">    batch_size=<span class="number">32</span>,        <span class="comment"># 批处理大小</span></span><br><span class="line">    epochs=<span class="number">20</span>,            <span class="comment"># 迭代次数</span></span><br><span class="line">    verbose=<span class="number">1</span>,            <span class="comment"># 训练过程中输出日志的详细程度（1为详细输出，0为不输出）</span></span><br><span class="line">    shuffle=<span class="literal">True</span>,         <span class="comment"># 在每个 epoch 开始时是否对数据进行洗牌</span></span><br><span class="line">    validation_split=<span class="number">0.05</span>  <span class="comment"># 验证集的拆分比例，这里设置为 0.05 表示将 5% 的数据作为验证集</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
60/60 [==============================] - 17s 217ms/step - loss: 0.7543 - accuracy: 0.6689 - val_loss: 0.7870 - val_accuracy: 0.6100
Epoch 2/20
60/60 [==============================] - 8s 128ms/step - loss: 0.5756 - accuracy: 0.7463 - val_loss: 0.6612 - val_accuracy: 0.7200
Epoch 3/20
60/60 [==============================] - 8s 134ms/step - loss: 0.4762 - accuracy: 0.7905 - val_loss: 0.6471 - val_accuracy: 0.7300
Epoch 4/20
60/60 [==============================] - 8s 132ms/step - loss: 0.4303 - accuracy: 0.8232 - val_loss: 0.7102 - val_accuracy: 0.6900
Epoch 5/20
60/60 [==============================] - 8s 131ms/step - loss: 0.4178 - accuracy: 0.8200 - val_loss: 0.6434 - val_accuracy: 0.7000
Epoch 6/20
60/60 [==============================] - 8s 136ms/step - loss: 0.3378 - accuracy: 0.8558 - val_loss: 0.7106 - val_accuracy: 0.7000
Epoch 7/20
60/60 [==============================] - 8s 135ms/step - loss: 0.3321 - accuracy: 0.8647 - val_loss: 0.6975 - val_accuracy: 0.7400
Epoch 8/20
60/60 [==============================] - 8s 130ms/step - loss: 0.3007 - accuracy: 0.8737 - val_loss: 0.7403 - val_accuracy: 0.7500
Epoch 9/20
60/60 [==============================] - 8s 138ms/step - loss: 0.2735 - accuracy: 0.8858 - val_loss: 0.8128 - val_accuracy: 0.7100
Epoch 10/20
60/60 [==============================] - 8s 133ms/step - loss: 0.2241 - accuracy: 0.9153 - val_loss: 0.9183 - val_accuracy: 0.6900
Epoch 11/20
60/60 [==============================] - 8s 141ms/step - loss: 0.2732 - accuracy: 0.8916 - val_loss: 0.7814 - val_accuracy: 0.7100
Epoch 12/20
60/60 [==============================] - 8s 142ms/step - loss: 0.2009 - accuracy: 0.9163 - val_loss: 0.8467 - val_accuracy: 0.7100
Epoch 13/20
60/60 [==============================] - 8s 140ms/step - loss: 0.2214 - accuracy: 0.9126 - val_loss: 0.7389 - val_accuracy: 0.7500
Epoch 14/20
60/60 [==============================] - 9s 144ms/step - loss: 0.1761 - accuracy: 0.9268 - val_loss: 0.8726 - val_accuracy: 0.7300
Epoch 15/20
60/60 [==============================] - 9s 142ms/step - loss: 0.1645 - accuracy: 0.9295 - val_loss: 0.7956 - val_accuracy: 0.7400
Epoch 16/20
60/60 [==============================] - 9s 142ms/step - loss: 0.1385 - accuracy: 0.9453 - val_loss: 0.7979 - val_accuracy: 0.7200
Epoch 17/20
60/60 [==============================] - 8s 138ms/step - loss: 0.1303 - accuracy: 0.9495 - val_loss: 0.8370 - val_accuracy: 0.7700
Epoch 18/20
60/60 [==============================] - 8s 139ms/step - loss: 0.1469 - accuracy: 0.9426 - val_loss: 0.7578 - val_accuracy: 0.7900
Epoch 19/20
60/60 [==============================] - 9s 143ms/step - loss: 0.1020 - accuracy: 0.9611 - val_loss: 0.7946 - val_accuracy: 0.7600
Epoch 20/20
60/60 [==============================] - 9s 147ms/step - loss: 0.1020 - accuracy: 0.9632 - val_loss: 0.8619 - val_accuracy: 0.7500
</code></pre>
<h2 id="绘制损失变化曲线"><a href="#绘制损失变化曲线" class="headerlink" title="绘制损失变化曲线"></a>绘制损失变化曲线</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绘制模型训练过程中的损失变化曲线</span></span><br><span class="line">plt.plot(hist_final.history[<span class="string">&#x27;loss&#x27;</span>])        <span class="comment"># 训练集的损失</span></span><br><span class="line">plt.plot(hist_final.history[<span class="string">&#x27;val_loss&#x27;</span>])    <span class="comment"># 验证集的损失</span></span><br><span class="line">plt.title(<span class="string">&quot;model loss&quot;</span>)                     <span class="comment"># 图像标题</span></span><br><span class="line">plt.ylabel(<span class="string">&quot;Loss&quot;</span>)                          <span class="comment"># y 轴标签为损失</span></span><br><span class="line">plt.xlabel(<span class="string">&quot;Epoch&quot;</span>)                         <span class="comment"># x 轴标签为 epoch</span></span><br><span class="line">plt.legend([<span class="string">&quot;Loss&quot;</span>, <span class="string">&quot;Validation Loss&quot;</span>])     <span class="comment"># 添加图例，分别对应训练集和验证集的损失</span></span><br><span class="line">plt.show()                                  <span class="comment"># 显示图像</span></span><br><span class="line"></span><br><span class="line">plt.savefig(<span class="string">&#x27;chart_loss.png&#x27;</span>)               <span class="comment"># 保存图像为文件（在 plt.show() 之后保存是无效的，应该放在 plt.show() 之前）</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYT8S.png" alt="OKYT8S.png"></p>
<p>​    </p>
<Figure size 640x480 with 0 Axes>


<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">###########  it&#x27;s time for test a image    ##########</span></span><br><span class="line">image = cv2.imread(os.path.join(path,<span class="string">&#x27;airplane_020.jpg&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ss.setBaseImage(image) <span class="comment"># 设置选择性搜索算法的基础图像为读取的图像</span></span><br><span class="line">ss.switchToSelectiveSearchFast() <span class="comment"># 使用选择性搜索算法的快速模式</span></span><br><span class="line">ssresults = ss.process() <span class="comment"># 对基础图像执行选择性搜索，获取区域建议</span></span><br><span class="line"></span><br><span class="line">imOut = image.copy() <span class="comment"># 创建图像的副本，用于绘制矩形框</span></span><br><span class="line">boxes = [] <span class="comment"># 存储被判断为飞机区域的边界框信息</span></span><br><span class="line">count = <span class="number">0</span> <span class="comment"># 计数器：记录被判断为飞机区域的数量</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对选择性搜索结果的前 50 个区域建议进行处理</span></span><br><span class="line"><span class="keyword">for</span> e,result <span class="keyword">in</span> <span class="built_in">enumerate</span>(ssresults):</span><br><span class="line">  <span class="keyword">if</span> e &lt; <span class="number">50</span>:</span><br><span class="line">    x,y,w,h = result</span><br><span class="line"></span><br><span class="line">    timage = imout[x:x+w,y:y+h] <span class="comment"># 从原始图像中获取当前建议区域的图像部分</span></span><br><span class="line">    resized = cv2.resize(timage, (<span class="number">224</span>,<span class="number">224</span>), interpolation = cv2.INTER_AREA) <span class="comment"># 调整图像大小为模型的输入尺寸</span></span><br><span class="line">    resized = np.expand_dims(resized,axis = <span class="number">0</span>) <span class="comment"># 将图像扩展一个维度以适应模型输入的要求</span></span><br><span class="line">    out = final_model.predict(resized)  <span class="comment"># 使用最终的模型对该区域进行预测，得到输出结果</span></span><br><span class="line">    <span class="built_in">print</span>(e,out)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(out[<span class="number">0</span>][<span class="number">0</span>]&lt;out[<span class="number">0</span>][<span class="number">1</span>]): <span class="comment"># 如果模型判断该区域可能包含飞机</span></span><br><span class="line">      boxes.append([x,y,w,h]) <span class="comment"># 将边界框信息添加到列表中，并增加计数器</span></span><br><span class="line">      count+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对被判断为飞机区域的边界框进行处理</span></span><br><span class="line"><span class="keyword">for</span> box <span class="keyword">in</span> boxes:</span><br><span class="line">    x, y, w, h = box</span><br><span class="line">    <span class="built_in">print</span>(x,y,w,h)</span><br><span class="line"><span class="comment">#     imOut = imOut[x:x+w,y:y+h]</span></span><br><span class="line">    <span class="comment"># 在原始图像上绘制矩形框，以突出显示这些被判断为飞机的区域</span></span><br><span class="line">    cv2.rectangle(imOut, (x, y), (x+w, y+h), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">0</span>), <span class="number">1</span>, cv2.LINE_AA)</span><br><span class="line"></span><br><span class="line">plt.imshow(imOut)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>1/1 [==============================] - 1s 1s/step
0 [[ 2.551831  -2.6361141]]
1/1 [==============================] - 0s 31ms/step
1 [[ 1.2116516 -1.1462703]]
1/1 [==============================] - 0s 43ms/step
2 [[ 3.1247723 -3.0577419]]
1/1 [==============================] - 0s 38ms/step
3 [[ 0.3094477  -0.35184118]]
1/1 [==============================] - 0s 33ms/step
4 [[ 16.334412 -16.097301]]
1/1 [==============================] - 0s 36ms/step
5 [[-1.9055386  1.8246138]]
1/1 [==============================] - 0s 46ms/step
6 [[ 3.849068 -3.596069]]
1/1 [==============================] - 0s 35ms/step
7 [[-4.3343387  4.457566 ]]
1/1 [==============================] - 0s 28ms/step
8 [[ 2.1157243 -2.0935826]]
1/1 [==============================] - 0s 37ms/step
9 [[ 1.1227907 -1.0547544]]
1/1 [==============================] - 0s 32ms/step
10 [[ 3.028215  -3.0655315]]
1/1 [==============================] - 0s 35ms/step
11 [[-3.4406524  3.4818974]]
1/1 [==============================] - 0s 36ms/step
12 [[-3.3148727  3.2502732]]
1/1 [==============================] - 0s 69ms/step
13 [[-1.7705667  1.8401496]]
1/1 [==============================] - 0s 119ms/step
14 [[ 17.1168   -17.020542]]
1/1 [==============================] - 0s 31ms/step
15 [[-0.54532474  0.49859324]]
1/1 [==============================] - 0s 39ms/step
16 [[ 1.3955598 -1.4487445]]
1/1 [==============================] - 0s 39ms/step
17 [[-0.9255678  0.7681236]]
1/1 [==============================] - 0s 34ms/step
18 [[-1.0967708  1.0601681]]
1/1 [==============================] - 0s 35ms/step
19 [[ 1.6157322 -1.5883387]]
1/1 [==============================] - 0s 19ms/step
20 [[ 6.222667 -6.078978]]
1/1 [==============================] - 0s 22ms/step
21 [[ 1.9781907 -1.9643315]]
1/1 [==============================] - 0s 21ms/step
22 [[ 2.6352754 -2.6751401]]
1/1 [==============================] - 0s 22ms/step
23 [[-0.6199166  0.6234232]]
1/1 [==============================] - 0s 26ms/step
24 [[ 0.56931984 -0.52301127]]
1/1 [==============================] - 0s 19ms/step
25 [[-4.092036   4.0529504]]
1/1 [==============================] - 0s 20ms/step
26 [[-1.1211745  1.1134607]]
1/1 [==============================] - 0s 20ms/step
27 [[ 1.5422791 -1.504165 ]]
1/1 [==============================] - 0s 20ms/step
28 [[ 0.9709082 -1.1293985]]
1/1 [==============================] - 0s 22ms/step
29 [[ 6.2005806 -6.223065 ]]
1/1 [==============================] - 0s 19ms/step
30 [[ 0.7283702  -0.67930716]]
1/1 [==============================] - 0s 20ms/step
31 [[ 3.7712991 -3.7369084]]
1/1 [==============================] - 0s 20ms/step
32 [[ 1.7139057 -1.7024881]]
1/1 [==============================] - 0s 21ms/step
33 [[ 12.521779 -12.554838]]
1/1 [==============================] - 0s 24ms/step
34 [[ 3.4832761 -3.3890066]]
1/1 [==============================] - 0s 23ms/step
35 [[ 1.2881904 -1.3030462]]
1/1 [==============================] - 0s 31ms/step
36 [[ 1.3349662 -1.2856408]]
1/1 [==============================] - 0s 20ms/step
37 [[ 0.29870683 -0.25320527]]
1/1 [==============================] - 0s 20ms/step
38 [[-1.2835077  1.3210849]]
1/1 [==============================] - 0s 19ms/step
39 [[ 1.3556112 -1.3576012]]
1/1 [==============================] - 0s 20ms/step
40 [[ 5.945995  -5.7617545]]
1/1 [==============================] - 0s 20ms/step
41 [[ 4.5127177 -4.54366  ]]
1/1 [==============================] - 0s 19ms/step
42 [[ 1.2226268 -1.2334687]]
1/1 [==============================] - 0s 19ms/step
43 [[ 2.2175348 -2.1676831]]
1/1 [==============================] - 0s 20ms/step
44 [[ 5.3103013 -5.1500263]]
1/1 [==============================] - 0s 22ms/step
45 [[ 1.7600315 -1.8218967]]
1/1 [==============================] - 0s 20ms/step
46 [[ 3.2599857 -2.9830909]]
1/1 [==============================] - 0s 19ms/step
47 [[-1.2734337  1.2411362]]
1/1 [==============================] - 0s 21ms/step
48 [[ 10.405064 -10.193722]]
1/1 [==============================] - 0s 20ms/step
49 [[-1.247491   1.2709295]]
145 129 35 31
0 71 98 70
176 148 64 43
49 91 49 22
0 71 77 70
199 148 38 29
174 130 21 27
19 95 58 45
111 142 27 23
120 127 32 33
0 74 48 53
120 143 33 19
29 149 36 40
111 117 34 46
</code></pre>
<p><img src="https://ooo.0x0.ooo/2023/12/29/OKYWxN.png" alt="OKYWxN.png"></p>
<blockquote>
<p>最后的测试效果没有很好，可能因为使用的训练数据过少，如果显存足够可以不用截取训练集的子集来进行训练，效果应该会提高。</p>
</blockquote>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>代码复现</tag>
        <tag>RCNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Django初学教程（一）</title>
    <url>/2024/01/03/Django%E5%88%9D%E5%AD%A6%E6%95%99%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89/</url>
    <content><![CDATA[<h1 id="创建项目"><a href="#创建项目" class="headerlink" title="创建项目"></a>创建项目</h1><ol>
<li>创建虚拟环境</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n testDjango python=3.8</span><br><span class="line">conda activate testDjango</span><br><span class="line">pip install Django # 注意这里Django首字母大写</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>创建项目</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd D:\PythonCode</span><br><span class="line">django-admin startproject mysite</span><br></pre></td></tr></table></figure>

<span id="more"></span>

<p>创建成功的项目结构为：</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysite/</span><br><span class="line">    manage.py</span><br><span class="line">    mysite/</span><br><span class="line">        __init__.py</span><br><span class="line">        settings.py</span><br><span class="line">        urls.py</span><br><span class="line">        asgi.py</span><br><span class="line">        wsgi.py</span><br></pre></td></tr></table></figure>
</blockquote>
<p>启动服务器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd mysite</span><br><span class="line">python manage.py runserver</span><br></pre></td></tr></table></figure>

<h1 id="创建应用"><a href="#创建应用" class="headerlink" title="创建应用"></a>创建应用</h1><p>项目&#x3D;（一个及以上的）应用程序 + 配置</p>
<h2 id="创建应用-1"><a href="#创建应用-1" class="headerlink" title="创建应用"></a>创建应用</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 项目名称为&quot;polls&quot;</span><br><span class="line">python manage.py startapp polls</span><br></pre></td></tr></table></figure>

<p>创建成功的应用结构为：</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">polls/</span><br><span class="line">    __init__.py</span><br><span class="line">    admin.py</span><br><span class="line">    apps.py</span><br><span class="line">    migrations/</span><br><span class="line">        __init__.py</span><br><span class="line">    models.py</span><br><span class="line">    tests.py</span><br><span class="line">    views.py</span><br></pre></td></tr></table></figure>
</blockquote>
<h2 id="创建首页"><a href="#创建首页" class="headerlink" title="创建首页"></a>创建首页</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改polls/views.py，创建index view</span><br><span class="line"></span><br><span class="line">from django.http import HttpResponse</span><br><span class="line"></span><br><span class="line">def index(request):</span><br><span class="line">    return HttpResponse(&quot;Hello, world. You&#x27;re at the polls index.&quot;)</span><br></pre></td></tr></table></figure>

<h2 id="配置url"><a href="#配置url" class="headerlink" title="配置url"></a>配置url</h2><h3 id="应用的url配置文件"><a href="#应用的url配置文件" class="headerlink" title="应用的url配置文件"></a>应用的url配置文件</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 新增polls/urls.py, 用于配置应用&quot;polls&quot;下的url</span><br><span class="line"></span><br><span class="line">from django.urls import path</span><br><span class="line"></span><br><span class="line">from . import views</span><br><span class="line"></span><br><span class="line"># 设置应用程序命名空间</span><br><span class="line"># 在真正的 Django 项目中，可能有五个、十个、二十个或更多应用程序。Django 如何区分它们之间的 URL 名称？——即将命名空间app_name = &quot;polls&quot;添加到 URLconf 中</span><br><span class="line"></span><br><span class="line">app_name = &quot;polls&quot;</span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(&quot;&quot;, views.index, name=&quot;index&quot;),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<h3 id="项目的url配置文件"><a href="#项目的url配置文件" class="headerlink" title="项目的url配置文件"></a>项目的url配置文件</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改mysite/urls.py，将应用&quot;polls&quot;下的urls.py引入</span><br><span class="line"></span><br><span class="line">from django.contrib import admin</span><br><span class="line">from django.urls import include, path</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    path(&quot;polls/&quot;, include(&quot;polls.urls&quot;)),</span><br><span class="line">    path(&quot;admin/&quot;, admin.site.urls),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>启动服务器：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py runserver</span><br></pre></td></tr></table></figure>

<h1 id="连接Database"><a href="#连接Database" class="headerlink" title="连接Database"></a>连接Database</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在项目的settings.py(即mysite/settings.py)中修改数据库配置</span><br><span class="line"></span><br><span class="line"># 修改数据库配置——更改为mysql数据库</span><br><span class="line">DATABASES = &#123;</span><br><span class="line">    &#x27;default&#x27;: &#123;</span><br><span class="line">        &#x27;ENGINE&#x27;: &#x27;django.db.backends.mysql&#x27;,</span><br><span class="line">        &#x27;NAME&#x27;: &#x27;db_test&#x27;,</span><br><span class="line">        &quot;USER&quot;: &quot;root&quot;,</span><br><span class="line">        &quot;PASSWORD&quot;: &quot;123456xjy&quot;,</span><br><span class="line">        &quot;HOST&quot;: &quot;127.0.0.1&quot;,</span><br><span class="line">        &quot;PORT&quot;: &quot;3306&quot;,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 首次连接mysql数据库需要在虚拟环境导入以下2个包</span><br><span class="line">pip install pymysql</span><br><span class="line">pip install mysqlclient</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 执行数据迁移——将&quot;mysite/settings.py&quot;中INSTALLED_APPS对应的数据表都创建出来（创建到上述的&quot;db_test&quot;数据库中）</span><br><span class="line">python manage.py migrate</span><br></pre></td></tr></table></figure>

<h1 id="建立Model"><a href="#建立Model" class="headerlink" title="建立Model"></a>建立Model</h1><h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><ul>
<li>Change your models (in <code>models.py</code>).</li>
<li>Run <code>python manage.py makemigrations</code>to create migrations for those changes</li>
<li>Run <code>python manage.py migrate</code>to apply those changes to the database.</li>
</ul>
<h2 id="Change-your-models"><a href="#Change-your-models" class="headerlink" title="Change your models"></a>Change your models</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改polls/models.py，创建类</span><br><span class="line"> </span><br><span class="line">from django.db import models</span><br><span class="line"></span><br><span class="line">class Question(models.Model):</span><br><span class="line">    question_text = models.CharField(max_length=200)</span><br><span class="line">    pub_date = models.DateTimeField(&quot;date published&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Choice(models.Model):</span><br><span class="line">    question = models.ForeignKey(Question, on_delete=models.CASCADE)</span><br><span class="line">    choice_text = models.CharField(max_length=200)</span><br><span class="line">    votes = models.IntegerField(default=0)</span><br></pre></td></tr></table></figure>

<h2 id="make-migrations"><a href="#make-migrations" class="headerlink" title="make migrations"></a>make migrations</h2><ol>
<li>将应用”polls”放到项目的setting.py（即mysite&#x2F;settings.py）的INSTALLED_APPS中</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改mysite/settings.py，增加一行&quot;polls.apps.PollsConfig&quot;,</span><br><span class="line"></span><br><span class="line">INSTALLED_APPS = [</span><br><span class="line">    &quot;polls.apps.PollsConfig&quot;,</span><br><span class="line">    &quot;django.contrib.admin&quot;,</span><br><span class="line">    &quot;django.contrib.auth&quot;,</span><br><span class="line">    &quot;django.contrib.contenttypes&quot;,</span><br><span class="line">    &quot;django.contrib.sessions&quot;,</span><br><span class="line">    &quot;django.contrib.messages&quot;,</span><br><span class="line">    &quot;django.contrib.staticfiles&quot;,</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>make migrations</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py makemigrations polls</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>migrate</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 运行以下代码，即可将models.py中新创建的类Question和类Choice，在数据库中创建出对应的数据表</span><br><span class="line">python manage.py migrate</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>进入Python环境</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py shell</span><br></pre></td></tr></table></figure>

<p>We’re using this instead of simply typing “python”, because <code>manage.py</code> sets the <a href="https://docs.djangoproject.com/en/4.2/topics/settings/#envvar-DJANGO_SETTINGS_MODULE"><code>DJANGO_SETTINGS_MODULE</code></a> environment variable, which gives Django the Python import path to your <code>mysite/settings.py</code> file.</p>
<h1 id="管理后台"><a href="#管理后台" class="headerlink" title="管理后台"></a>管理后台</h1><ol>
<li>创建超级管理员</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py createsuperuser</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>运行服务器</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python manage.py runserver</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>将自定义的类注册到管理后台</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改polls/admin.py，将新注册的类Question注册到管理后台</span><br><span class="line"></span><br><span class="line">from django.contrib import admin</span><br><span class="line">from .models import Question</span><br><span class="line"></span><br><span class="line">admin.site.register(Question)</span><br></pre></td></tr></table></figure>

<h1 id="增加Views"><a href="#增加Views" class="headerlink" title="增加Views"></a>增加Views</h1><ol>
<li>新增视图</li>
</ol>
<p>每一个View就干两件事中的一件：要么返回一个HttpResponse，要么返回一个Exception（如Http404）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 在polls/views.py新增以下函数（视图）</span><br><span class="line"># 以下均为虚拟实现</span><br><span class="line"></span><br><span class="line">def detail(request, question_id):</span><br><span class="line">    return HttpResponse(&quot;You&#x27;re looking at question %s.&quot; % question_id)</span><br><span class="line"></span><br><span class="line">def results(request, question_id):</span><br><span class="line">    response = &quot;You&#x27;re looking at the results of question %s.&quot;</span><br><span class="line">    return HttpResponse(response % question_id)</span><br><span class="line"></span><br><span class="line">def vote(request, question_id):</span><br><span class="line">    return HttpResponse(&quot;You&#x27;re voting on question %s.&quot; % question_id)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>配置应用url</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 将新增的view写入pools/urls.py</span><br><span class="line"></span><br><span class="line">from django.urls import path</span><br><span class="line"></span><br><span class="line">from . import views</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    # ex: /polls/</span><br><span class="line">    path(&quot;&quot;, views.index, name=&quot;index&quot;),</span><br><span class="line">    # ex: /polls/5/</span><br><span class="line">    path(&quot;&lt;int:question_id&gt;/&quot;, views.detail, name=&quot;detail&quot;),</span><br><span class="line">    # ex: /polls/5/results/</span><br><span class="line">    path(&quot;&lt;int:question_id&gt;/results/&quot;, views.results, name=&quot;results&quot;),</span><br><span class="line">    # ex: /polls/5/vote/</span><br><span class="line">    path(&quot;&lt;int:question_id&gt;/vote/&quot;, views.vote, name=&quot;vote&quot;),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>用户访问视图的运行流程</li>
</ol>
<p>请求页面”&#x2F;polls&#x2F;6&#x2F;“&#x3D;&gt;加载mysite.urls&#x3D;&gt;找到变量”polls&#x2F;“命名的urlpatterns，即<code>path(&quot;polls/&quot;, include(&quot;polls.urls&quot;))</code>&#x3D;&gt;去掉”polls&#x2F;“，剩余”6&#x2F;“&#x3D;&gt;把剩余的”6&#x2F;“发送给”<code>polls.urls</code>“ URLconf&#x3D;&gt;匹配到了<code>path(&quot;&lt;int:question_id&gt;/&quot;, views.detail, name=&quot;detail&quot;)</code>&#x3D;&gt;导致调用了<code>detail()</code> 视图(<code>views.py中的detail()</code>)，具体调用如<code>detail(request=&lt;HttpRequest object&gt;, question_id=34)</code></p>
<h1 id="修改Views"><a href="#修改Views" class="headerlink" title="修改Views"></a>修改Views</h1><h2 id="index-view"><a href="#index-view" class="headerlink" title="index view"></a>index view</h2><p>上述增加视图中的视图使用了虚拟实现，并没有从数据库中读取记录，或完成其他有实际意义的任务，因此在这一板块将编写实际执行某些操作的视图。</p>
<ol>
<li>修改视图(index view)</li>
</ol>
<p>法1：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># polls/views.py</span><br><span class="line"># 修改index view (index函数)，使用模板(利用HttpResponse和loader)，读取数据库数据</span><br><span class="line"># 加载调用的模板 polls/index.html并向其传递context。context是将模板变量名称映射到 Python 对象的字典。</span><br><span class="line">from django.http import HttpResponse</span><br><span class="line">from django.template import loader</span><br><span class="line"></span><br><span class="line">from .models import Question</span><br><span class="line"></span><br><span class="line">def index(request):</span><br><span class="line">    latest_question_list = Question.objects.order_by(&quot;-pub_date&quot;)[:5]</span><br><span class="line">    template = loader.get_template(&quot;polls/index.html&quot;)</span><br><span class="line">    context = &#123;</span><br><span class="line">        &quot;latest_question_list&quot;: latest_question_list,</span><br><span class="line">    &#125;</span><br><span class="line">    return HttpResponse(template.render(context, request))</span><br></pre></td></tr></table></figure>

<p>法2：</p>
<p>利用render()函数代替HttpResponse和loader，简化代码</p>
<p><code>render()</code>函数第一个参数是请求对象，第二个参数是模板名称，第三个参数是可选的字典。它返回一个<code>HttpResponse</code>对象，这是一个使用给定context的模板对象。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># polls/views.py</span><br><span class="line"></span><br><span class="line">from django.shortcuts import render</span><br><span class="line"></span><br><span class="line">from .models import Question</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def index(request):</span><br><span class="line">    latest_question_list = Question.objects.order_by(&quot;-pub_date&quot;)[:5]</span><br><span class="line">    context = &#123;&quot;latest_question_list&quot;: latest_question_list&#125;</span><br><span class="line">    return render(request, &quot;polls/index.html&quot;, context)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>创建模板(index.html)</li>
</ol>
<p>如果页面的设计硬编码在视图中，那么当我们想要更改页面的外观时，必须编辑此 Python 代码（即views.py中的函数）。因此我们使用Django的模板系统，通过创建模板，使得页面设计与Python代码分离。</p>
<p>在应用的目录下创建templates目录（即polls&#x2F;templates&#x2F;），Django会默认在这个目录下寻找模板。</p>
<p>创建好模板文件后的目录结构如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 这里还在templates目录下创建了一个polls子目录，在子目录下才放置了模板文件index.html</span><br><span class="line"># 这里新建的polls子目录起到划分命名空间的作用。因为如果在不同的应用程序中具有相同名称的模板，Django 将无法区分它们，所以需要设置命名空间。</span><br><span class="line"></span><br><span class="line">polls/</span><br><span class="line">    __init__.py</span><br><span class="line">    admin.py</span><br><span class="line">    models.py</span><br><span class="line">    views.py</span><br><span class="line">    templates</span><br><span class="line">    	polls</span><br><span class="line">    		index.html</span><br></pre></td></tr></table></figure>

<p>index.html的文件内容如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># polls/templates/polls/index.html</span><br><span class="line"></span><br><span class="line">&#123;% if latest_question_list %&#125;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">    &#123;% for question in latest_question_list %&#125;</span><br><span class="line">        &lt;li&gt;&lt;a href=&quot;/polls/&#123;&#123; question.id &#125;&#125;/&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">    &lt;/ul&gt;</span><br><span class="line">&#123;% else %&#125;</span><br><span class="line">    &lt;p&gt;No polls are available.&lt;/p&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>移除模板文件中的硬编码URL</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 修改前</span><br><span class="line">&lt;li&gt;&lt;a href=&quot;/polls/&#123;&#123; question.id &#125;&#125;/&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt;</span><br><span class="line"></span><br><span class="line"># 修改后</span><br><span class="line">&lt;li&gt;&lt;a href=&quot;&#123;% url &#x27;detail&#x27; question.id %&#125;&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt;</span><br><span class="line"></span><br><span class="line"># 修改原因：在polls/urls.py中，views.py的detail()函数路径被注册为</span><br><span class="line">path(&quot;&lt;int:question_id&gt;/&quot;, views.detail, name=&quot;detail&quot;),其中name属性为&quot;detail&quot;</span><br><span class="line"></span><br><span class="line"># 继续修改：在polls/urls.py中设置应用程序命名空间(app_name = &quot;polls&quot;)后,继续修改为指向命名空间的详细视图</span><br><span class="line">&lt;li&gt;&lt;a href=&quot;&#123;% url &#x27;polls:detail&#x27; question.id %&#125;&quot;&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/a&gt;&lt;/li&gt;</span><br></pre></td></tr></table></figure>

<h2 id="detail-view"><a href="#detail-view" class="headerlink" title="detail view"></a>detail view</h2><ol>
<li>修改视图(detail view)</li>
</ol>
<p>使用get方法特别容易产生404错误，因此产生了一个快捷方式，即使用<code>get_object_or_404()</code>来进行查询。<code>get_object_or_404()</code>第一个参数是a Django model，第二个参数是任意数量的关键词参数。如果查询对象存在，则返回该模型对象；如果对象不存在，则返回Http404。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># polls/views.py</span><br><span class="line"></span><br><span class="line">from django.shortcuts import get_object_or_404, render</span><br><span class="line"></span><br><span class="line">from .models import Question</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def detail(request, question_id):</span><br><span class="line">    question = get_object_or_404(Question, pk=question_id)</span><br><span class="line">    return render(request, &quot;polls/detail.html&quot;, &#123;&quot;question&quot;: question&#125;)</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>创建模板(detail.html)</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;form action=&quot;&#123;% url &#x27;polls:vote&#x27; question.id %&#125;&quot; method=&quot;post&quot;&gt;</span><br><span class="line">&#123;% csrf_token %&#125;</span><br><span class="line">&lt;fieldset&gt;</span><br><span class="line">    &lt;legend&gt;&lt;h1&gt;&#123;&#123; question.question_text &#125;&#125;&lt;/h1&gt;&lt;/legend&gt;</span><br><span class="line">    &#123;% if error_message %&#125;&lt;p&gt;&lt;strong&gt;&#123;&#123; error_message &#125;&#125;&lt;/strong&gt;&lt;/p&gt;&#123;% endif %&#125;</span><br><span class="line">    &#123;% for choice in question.choice_set.all %&#125;</span><br><span class="line">        &lt;input type=&quot;radio&quot; name=&quot;choice&quot; id=&quot;choice&#123;&#123; forloop.counter &#125;&#125;&quot; value=&quot;&#123;&#123; choice.id &#125;&#125;&quot;&gt;</span><br><span class="line">        &lt;label for=&quot;choice&#123;&#123; forloop.counter &#125;&#125;&quot;&gt;&#123;&#123; choice.choice_text &#125;&#125;&lt;/label&gt;&lt;br&gt;</span><br><span class="line">    &#123;% endfor %&#125;</span><br><span class="line">&lt;/fieldset&gt;</span><br><span class="line">&lt;input type=&quot;submit&quot; value=&quot;Vote&quot;&gt;</span><br><span class="line">&lt;/form&gt;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>2中的vote()函数还需要具体实现</li>
</ol>
<p>后续内容可以参考官方文档<a href="https://docs.djangoproject.com/en/5.0/intro/tutorial04/">https://docs.djangoproject.com/en/5.0/intro/tutorial04/</a></p>
]]></content>
      <categories>
        <category>开发技能</category>
      </categories>
      <tags>
        <tag>Django</tag>
      </tags>
  </entry>
</search>
